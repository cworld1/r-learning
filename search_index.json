[["index.html", "R-Learning Chapter 1 Welcome 1.1 项目介绍 1.2 项目运行 1.3 贡献 1.4 鸣谢 1.5 License", " R-Learning CWorld 2022-05-29 Chapter 1 Welcome 这是关于 CWorld 学习 R 语言的一些笔记和代码。目前已开源：Github R-Learning 1.1 项目介绍 本项目使用 bookdown 构建，包含 gitbook、epub_book 和 pdf_book 三种构建成品。 实际学习上，我们更推荐将项目打包下载，或使用 git clone 到本地方便随时运行它们的任意一部分，而不是反复使用复制和粘贴。本笔记的 R 笔记源码针对大纲进行了优化，使用支持更友好的编辑器，很大程度上方便读者理清节点关系与数据生成始末。这里推荐使用 RStudio 或 Visual Studio Code，但理论上应该也有让你阅读更愉快的编辑器，在此不做敷述。 1.2 项目运行 首先请保证自己已经有了 R 本地环境，并把 RScript 加入了全局变量。 安装运行代码需要的包： Rscript -e &#39;install.packages(c(&quot;tidyverse&quot;, &quot;nycflights13&quot;, &quot;hexbin&quot;, &quot;gapminder&quot;, &quot;Lahman&quot;))&#39; 安装构建本书需要的包（如果你需要的话）： Rscript -e &#39;install.packages(c(&quot;markdownr&quot;, &quot;bookdown&quot;))&#39; Rscript -e &#39;tinytex::install_tinytex()&#39; 开始构建（如果你需要的话）： set -ev cd book Rscript -e &quot;bookdown::render_book(&#39;index.Rmd&#39;, &#39;bookdown::gitbook&#39;)&quot; 1.3 贡献 由于作者只是个正在浅学 R 的初学者，所以笔记难免存在明显纰漏，还请读者们多多海涵。此外，也欢迎诸位使用 PR 或 Issues 来改善它们。 1.4 鸣谢 一些电子教材对作者学习上帮助颇多，在此对这些教材的原作者深表感谢。读者若对此项目的笔记抱有疑惑，也可以仔细阅读以下的教材以作弥补。 R for Data Science R for Data Science: Exercise Solutions Modern Data Science with R 1.5 License The MIT License. "],["introduction.html", "Chapter 2 Introduction 2.1 数据科学 2.2 一些准备 2.3 更多学习途径 2.4 初识 R", " Chapter 2 Introduction 2.1 数据科学 data-science.png 首先我们需要导入数据。然后对其进行整理。理解数据的核心就是转换、可视化数据和建立模型。通信是最后的步骤，理解的数据最终很可能走向分享他人。 2.2 一些准备 2.2.1 安装 R 要下载 R，需要前往 CRAN，即 cromprehensive R archive network。CRAN 由分布在世界各地的一组镜像服务器组成，用于分发 R 和 R 的拓展包。不要试图选择看起来地点离你很近的镜像，而是使用 云镜像，它会自动为你找出答案。 2.2.2 安装编辑器 RStudio 是一个用于 R 编程的集成开发环境或 IDE。从 http://www.rstudio.com/download 下载并安装它。 2.2.3 相关包 我们可以使用一行代码安装完整的 tidyverse： install.packages(&quot;tidyverse&quot;) 在我们自己的计算机上，在控制台中键入该行代码，然后按 Enter 运行它。R 将从 CRAN 下载软件包并将其安装到我们的计算机上。如果我们在安装时遇到问题，请确保我们已连接到互联网，并且 https://cloud.r-project.org/ 未被防火墙或代理阻止。 在本项目笔记中，我们将使用来自 tidyverse 之外的三个数据包： install.packages(c(&quot;nycflights13&quot;, &quot;gapminder&quot;, &quot;Lahman&quot;)) 这些软件包提供了有关航空公司航班、世界发展和棒球的数据，我们将用这些数据来说明关键的数据科学理念。 2.3 更多学习途径 R for Data Science R for Data Science: Exercise Solutions 2.4 初识 R 我们就从 HelloWorld 开始吧： print(&quot;hello world!&quot;) ## [1] &quot;hello world!&quot; R 里有一些约定俗成的代码形式。如： # 函数后面带括号 sum(c(1, 2)) # 对象直接书写 iris # 不加载包直接调用 dplyr::mutate(iris) # mutate() 函数 nycflights13::flights # flights 数据集 一些基础功能后面可能不会再反复提到，但它们通常很有用： library(tidyverse) # 加载之前安装的包 tidyverse_update() # 更新 tidyverse 包内的附带包 dput(mtcars) # 查看数据集（如 mtcars）的更多信息 sessionInfo(c(&quot;tidyverse&quot;)) # 查看本地 R 及相关信息 "],["explore-intro.html", "Chapter 3 Introduction 3.1 基本数据形式和函数 3.2 学习 R 自带的画图功能 3.3 更高级的数据形式", " Chapter 3 Introduction 尽快掌握数据探索的基本工具是探究语言的第一要义。数据探索的目标是生成许多有前途的潜在信息，便于以后更深入地探索它们。 data-science-explore 可视化是 R 编程的重要部分：制作优雅且信息丰富的绘图，以帮助理解数据。学习 ggplot2 绘图的基本结构，将数据转换为绘图。 在数据转换中，使用关键谓词允许我们选择重要变量、筛选出关键观察结果、创建新变量和计算摘要。 建模是探索过程的重要组成部分，但这并不是当下能够弄清的，它会在以后的学习中逐渐深入。 在工作流中：“基础知识”、“工作流：脚本” 和 “工作流：项目”，你将学习编写和组织 R 代码的良好实践。 以下为附加内容，因为已知资料上貌似没有提到。 3.1 基本数据形式和函数 3.1.1 向量、矩阵与列表 创建已知或未知的空向量用于存储一系列数据（如整数、小数、字符串）。 x &lt;- vector() # 创建空向量 y &lt;- c(1, 2) # 手动赋值 # 在 R 中，我们可以使用 “:” 来创建序列填充 z &lt;- c(1:3) # 这里其实等价于 1, 2, 3 矩阵有点像我们学的表格，这种数据结构很类似于其它语言中的二维数组。注意使用 t() 可以行列互换。 Matrix_transpose rownames &lt;- c(&quot;row1&quot;, &quot;row2&quot;, &quot;row3&quot;, &quot;row4&quot;) colnames &lt;- c(&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;) m &lt;- matrix( data = c(3:14), # nrow = 4, # 设置行数。如果不知道数据有多少其实可以不设置 ncol = 3, # 设置列宽 byrow = TRUE, # 设置为 TRUE 即按行排列，反之则按列排 dimnames = list(rownames, colnames) # 设置行和列的标题，默认为 NULL ) m #&gt; col1 col2 col3 #&gt; row1 3 4 5 #&gt; row2 6 7 8 #&gt; row3 9 10 11 #&gt; row4 12 13 14 t(m) #&gt; row1 row2 row3 row4 #&gt; col1 3 6 9 12 #&gt; col2 4 7 10 13 #&gt; col3 5 8 11 14 列表使用 list() 创建。一个列表里可以随意放置向量里能放置的所有元素，甚至是一个向量、一个矩阵。 list_data &lt;- list( &quot;google&quot;, matrix(c(1, 2, 3, 4, 5, 6), nrow = 2), 123.1, c(1:5) ) # 读取元素 list_data[[1]] # 注意中括号应该用两层来获取对应元素。但如果只用一层，R 会自动识别并修正 names(list_data) &lt;- c(&quot;Sites&quot;, &quot;Numbers&quot;, &quot;Lists&quot;) # 使用 names() 来赋值名称 list_data$Sites # 有名称后可以用 $xx 来读取对应的列元素 # 添加 / 更新元素 list_data[5] &lt;- &quot;新元素&quot; # 删除元素 list_data[4] &lt;- NULL # 合并 / 转换列表 num_list &lt;- list(1, 2) merged_list &lt;- c(num_list, list_data) # 合并 unlist(num_list) # 转换列表为向量 3.1.2 基本函数 数据集如下： age &lt;- c(10, 12, 14, 6, 8, 18) weight &lt;- c(100, 110, 120, 80, 90, 140) 数学中一些常用的计算函数 5 %% 3 # 求余数 #&gt; [1] 2 5 %/% 3 # 求模 #&gt; [1] 1 mean(age) # 求平均值 #&gt; [1] 11.33333 sd(age) # 求标准差 #&gt; [1] 4.320494 cor(age, weight) # 求相关度，数值在 -1 到 1，其中 1 是绝对正相关，0 是完全不相关，-1 是绝对负相关 #&gt; [1] 1 lm(age ~ weight) # 求两者构成的回归直线斜率（注意波浪号连接） #&gt; #&gt; Call: #&gt; lm(formula = age ~ weight) #&gt; #&gt; Coefficients: #&gt; (Intercept) weight #&gt; -10.0 0.2 3.2 学习 R 自带的画图功能 在 R 里画图非常简单。以上面的 age 和 weight 为例： # 注意在 R 里面，相对路径的基层路径是由工作区设定的 getwd() # 获取当前工作区路径 setwd(&quot;D:/Project/R-Project/&quot;) # 设置工作区路径 png(&quot;./source/mygraph.png&quot;) # 设置好后就可以存储到理想位置 plot(age, weight) # 绘制散点图 abline(lm(age ~ weight)) # 绘制回归直线 title(&quot;年龄 - 体重图&quot;) # 添加 # 添加标题 dev.off() # 结束画图并保存 实际运行生成的图： mygraph 3.3 更高级的数据形式 dataframe 是一系列向量数据的集合： data.frame( a = c(1:3), b = c(6:8) ) #&gt; a b #&gt; 1 1 6 #&gt; 2 2 7 #&gt; 3 3 8 tibble 与 dataframe 非常相似，甚至是使用 dataframe 储存的。tibble 是 tidyverse 系列的专用数据集格式。它的优点是干净、方便数据处理。 library(tidyverse) #&gt; -- Attaching packages ------------------------------------------------------------------------------------------------------------------------- tidyverse 1.3.1 -- #&gt; v ggplot2 3.3.5 v purrr 0.3.4 #&gt; v tibble 3.1.6 v dplyr 1.0.8 #&gt; v tidyr 1.2.0 v stringr 1.4.0 #&gt; v readr 2.1.2 v forcats 0.5.1 #&gt; -- Conflicts ---------------------------------------------------------------------------------------------------------------------------- tidyverse_conflicts() -- #&gt; x dplyr::filter() masks stats::filter() #&gt; x dplyr::lag() masks stats::lag() tribble( ~sex, ~response, &quot;male&quot;, 1, &quot;female&quot;, 2, &quot;male&quot;, 1 ) #&gt; # A tibble: 3 x 2 #&gt; sex response #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 male 1 #&gt; 2 female 2 #&gt; 3 male 1 "],["explore.html", "Chapter 4 Data visualisation 4.1 初识 ggplot 4.2 美学映射 4.3 修改样式 4.4 多组画图 4.5 叠加与参数 4.6 其他常见图 4.7 坐标系相关 4.8 绘制 diamonds 数据分析图 4.9 研究 mpgcars 数据集", " Chapter 4 Data visualisation library(tidyverse) # 方便使用其中的 ggplot2 4.1 初识 ggplot view(mpg) # 使用 view() 函数可以方便观察对应数据集 head(mpg) # 可以在控制台打印数据集头部信息（前十行） #&gt; # A tibble: 6 x 11 #&gt; manufacturer model displ year cyl trans drv cty hwy fl class #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compa~ #&gt; 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compa~ #&gt; 3 audi a4 2 2008 4 manual(m6) f 20 31 p compa~ #&gt; 4 audi a4 2 2008 4 auto(av) f 21 30 p compa~ #&gt; 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compa~ #&gt; 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compa~ 列 displ：汽车的发动机尺寸，以升为单位。 列 hwy：汽车在高速公路上的燃油效率，以英里 / 加仑（mpg）为单位 ggplot(data = mpg) + # 统一设置想要处理的数据集 # 绘制 point，mapping 属性用来设置相关的 x 轴和 y 轴参数 geom_point(mapping = aes(x = displ, y = hwy)) 4.2 美学映射 使用颜色映射： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class)) 使用大小映射（不建议）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, size = class)) #&gt; Warning: Using size for a discrete variable is not advised. 使用形状映射（注意最多只支持 6 种）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, shape = class)) #&gt; Warning: The shape palette can deal with a maximum of 6 discrete values because #&gt; more than 6 becomes difficult to discriminate; you have 7. Consider #&gt; specifying shapes manually if you must have them. #&gt; Warning: Removed 62 rows containing missing values (geom_point). 使用透明度映射（不建议）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, alpha = class)) #&gt; Warning: Using alpha for a discrete variable is not advised. 4.3 修改样式 例如颜色： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;) 支持参数：color，shape，fill，stroke（点的粗细），linetype 等。同时，样式参数支持变量。注意 shape 填写时是填写数字，有 21 种。 R 有 25 个内置形状，这些形状由数字标识。有一些看似重复的：例如，0、15 和 22 都是正方形。不同之处在于“颜色”和“填充”美学的相互作用。空心形状（0–14）具有由“颜色”确定的边框;固体形状（15–20）填充有“颜色”;填充的形状（21–24）具有“颜色”边框，并用“填充”填充填充。 4.4 多组画图 简单分组（分片）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~class, nrow = 3) # 以 class 分类，三列，不限制行 自定义条件分组： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ cyl) # 以 drv 为 x 轴，cyl 为 y 轴 4.5 叠加与参数 mapping 为默认接收内容，可以省略： ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy)) + geom_smooth(aes(x = displ, y = hwy)) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 其中 mapping 写在基本配置项中，方便绘图自动调用 ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth() #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 绘图时使用自定义 data 覆盖默认 data 配置（filter 为筛选数据）： ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(color = &quot;blue&quot;) + geom_smooth(data = filter(mpg, class == &quot;subcompact&quot;)) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 4.6 其他常见图 4.6.1 回归曲线图 回归曲线有它专门的配置项，其中 show legend 用于控制现实图例显示与否，se 控制自信指数（半透明带）显示与否： ggplot(data = mpg) + geom_smooth( mapping = aes(x = displ, y = hwy, color = drv), show.legend = FALSE, se = FALSE ) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 4.6.2 条形图 ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, colour = cut)) # colour 为描边颜色 ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = cut)) # fill 为填充颜色 但如果 fill 使用的是其他变量，会导致不同数据重叠遮挡 ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) 解决方案 1：降低透明度 ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + geom_bar(alpha = 1 / 5, position = &quot;identity&quot;) 解决方案 2：直接改为 colour 样式，并将 fill 设置为 NA ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + geom_bar(fill = NA, position = &quot;identity&quot;) 解决方案 3：position 改用 fill 为频率图（方便观察比例） ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + geom_bar(position = &quot;fill&quot;) 解决方案 4：position 改用 dodge 为分柱图 ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + geom_bar(position = &quot;dodge&quot;) 4.6.3 Summary 线条信息图 这种图不太常用，因为 boxplot 图拥有它的所有特性，甚至做得更好： ggplot(data = diamonds) + stat_summary( mapping = aes(x = cut, y = depth), fun.max = max, # 上限最大值 fun.min = min, # 下限为最小值 fun.y = mean # 标点为平均数 ) #&gt; Warning: `fun.y` is deprecated. Use `fun` instead. 4.7 坐标系相关 对调坐标轴： ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() + coord_flip() 根据相关图像限制图形的纵横比例： nz &lt;- map_data(&quot;nz&quot;) # 从 map_data 里调用某国的地图 ggplot(nz, aes(long, lat, group = group)) + geom_polygon(fill = &quot;white&quot;, colour = &quot;black&quot;) + coord_quickmap() # 这里会使图表以正确的横纵比显示，防止图像拉伸扭曲 极坐标化： bar &lt;- ggplot(data = diamonds) + geom_bar( mapping = aes(x = cut, fill = cut), show.legend = FALSE, width = 1 ) + theme(aspect.ratio = 1) + labs(x = NULL, y = NULL) + coord_polar() # 设置为极坐标（有点像圆饼图） 4.8 绘制 diamonds 数据分析图 原题目：Recreate the R code necessary to generate the following graphs. 建立列表，绘制好 6 张图并装配进去： p &lt;- list() p[[1]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_point() + geom_smooth(se = FALSE) # 注意包含回归曲线 p[[2]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_smooth(mapping = aes(group = drv), se = FALSE) + # 以 drv 分组作出多条回归线 geom_point() p[[3]] &lt;- ggplot(mpg, aes(x = displ, y = hwy, colour = drv)) + # 全局以 drv 分类添加着色 geom_point() + geom_smooth(se = FALSE) p[[4]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = drv)) + geom_smooth(se = FALSE) # 如果只要总的回归线，就不要把 colour 变量对 smooth 进行应用 p[[5]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = drv)) + geom_smooth(aes(linetype = drv), se = FALSE) # 与以颜色分组类似，这里只是改用线条样式 p[[6]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(size = 4, color = &quot;white&quot;) + geom_point(aes(colour = drv)) # 这里是两幅非常相似的图重叠的效果。注意后画的图优先显示 随即使用布局逐张展示： library(grid) # 引用一下布局包 grid.newpage() # 新建布局包 pushViewport(viewport(layout = grid.layout(3, 2))) # 设置 2x3 布局 print(p[[1]], vp = viewport(layout.pos.row = 1, layout.pos.col = 1)) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[2]], vp = viewport(layout.pos.row = 1, layout.pos.col = 2)) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[3]], vp = viewport(layout.pos.row = 2, layout.pos.col = 1)) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[4]], vp = viewport(layout.pos.row = 2, layout.pos.col = 2)) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[5]], vp = viewport(layout.pos.row = 3, layout.pos.col = 1)) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[6]], vp = viewport(layout.pos.row = 3, layout.pos.col = 2)) 4.9 研究 mpgcars 数据集 仔细观察数据集会发现 displ 和 hwy 是经过四舍五入的，在实际图表上很多点会产生重叠： ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(alpha = 1 / 5) 对 position 添加 jitter 值可以手动添加 “数据噪点”，从而更好地看到数据全貌（尽管会改变数值导致图表不那么准确）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), position = &quot;jitter&quot;) "],["workflow-basics.html", "Chapter 5 Workflow: basics", " Chapter 5 Workflow: basics 在 R 里，你甚至能当计算器： 1 / 200 * 30 #&gt; [1] 0.15 (59 + 73 + 2) / 3 #&gt; [1] 44.66667 sin(pi / 2) #&gt; [1] 1 注意赋值语句应当用 “&lt;-”： x &lt;- 3 * 4 b &lt;- x “=” 用于定义函数所指定的参数。虽然错误的书写不会导致报错，但对于代码的阅读量影响颇大。 命名上，R 一般使用字母开头，字符只能使用 “.” 和 “_”： i_use_snake_case # 推荐的命名法则 otherPeopleUseCamelCase some.people.use.periods 此外，R 允许在赋值语句打括号用于返回赋值内容。这与 C 语言非常类似： (y &lt;- seq(1, 10, length.out = 5)) # 返回一个向量，元素均匀地分布从 1 到 10，共 5 个 #&gt; [1] 1.00 3.25 5.50 7.75 10.00 "],["transform.html", "Chapter 6 Data transformation 6.1 查看 flights 数据集 6.2 过滤 filter() 6.3 排列 arange() 6.4 选择 select() 6.5 重命名 rename() 6.6 添加新变量 mutate() 与 transmute() 6.7 分组摘要 summarise() 6.8 其他处理数据功能 6.9 分析 flights 数据集", " Chapter 6 Data transformation 可视化是生成可以直接观察的数据展示形式的重要工具，但我们却很少能以所需的正确形式获取数据。因此，我们通常需要创建一些新的变量或摘要，或是纯粹地只想重命名变量或对观测值重新排序。 library(nycflights13) library(tidyverse) 6.1 查看 flights 数据集 在后面的案例中，我们将持续关注来自 nycflights13 的数据集 flights。 它包含 2013 年从纽约市出发的共 336,776 个航班。 flights #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 列名称下字母缩写代表该列的数据类型： - int：整数 - dbl：双精度或实数 - chr：字符向量或字符串 - dttm：日期时间（日期 + 时间） 此外还有： - lgl：仅包含逻辑词（TRUE / FALSE） - fctr：因子（factor），表示具有固定可能值的分类变量 - date：日期 tidyverse 还附带了一些神奇的功能，如 filter、arrange、select、rename、mutate 和 summarise 等。下面我们将逐个学习它们。 6.2 过滤 filter() # 筛选月份为 1，天数为 1 的 filter(flights, month == 1, day == 1) #&gt; # A tibble: 842 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; # ... with 832 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 筛选月份为 12 或者天数为 25 的（圣诞节） filter(flights, month == 12 &amp; day == 25) #&gt; # A tibble: 719 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 12 25 456 500 -4 649 651 #&gt; 2 2013 12 25 524 515 9 805 814 #&gt; 3 2013 12 25 542 540 2 832 850 #&gt; 4 2013 12 25 546 550 -4 1022 1027 #&gt; 5 2013 12 25 556 600 -4 730 745 #&gt; 6 2013 12 25 557 600 -3 743 752 #&gt; 7 2013 12 25 557 600 -3 818 831 #&gt; 8 2013 12 25 559 600 -1 855 856 #&gt; 9 2013 12 25 559 600 -1 849 855 #&gt; 10 2013 12 25 600 600 0 850 846 #&gt; # ... with 709 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 筛选出月份为12，天数为 11 或者 12 的 filter(flights, month == 12, day == 11 | day == 12) #&gt; # A tibble: 1,922 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 12 11 459 500 -1 651 651 #&gt; 2 2013 12 11 517 515 2 825 814 #&gt; 3 2013 12 11 542 545 -3 841 832 #&gt; 4 2013 12 11 544 540 4 838 850 #&gt; 5 2013 12 11 544 550 -6 1021 1027 #&gt; 6 2013 12 11 552 600 -8 927 915 #&gt; 7 2013 12 11 552 600 -8 712 717 #&gt; 8 2013 12 11 553 600 -7 644 701 #&gt; 9 2013 12 11 554 600 -6 753 755 #&gt; 10 2013 12 11 554 600 -6 656 659 #&gt; # ... with 1,912 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 筛选出月份为12，天数为 10 或者 11 或者 12 的 filter(flights, month == 12, day %in% c(10, 11, 12)) # 注意 “包含于” 表示的方法 #&gt; # A tibble: 2,865 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 12 10 7 2359 8 451 445 #&gt; 2 2013 12 10 7 2359 8 446 437 #&gt; 3 2013 12 10 11 2245 86 119 2353 #&gt; 4 2013 12 10 211 2359 132 651 440 #&gt; 5 2013 12 10 457 500 -3 701 651 #&gt; 6 2013 12 10 528 515 13 830 814 #&gt; 7 2013 12 10 543 545 -2 907 832 #&gt; 8 2013 12 10 548 550 -2 1022 1027 #&gt; 9 2013 12 10 549 540 9 854 850 #&gt; 10 2013 12 10 551 600 -9 920 856 #&gt; # ... with 2,855 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 添加函数参数 na.rm = TRUE 来剔除数据，is.na 来判断是否为 NA（这是通用的） filter(flights, month == 1, na.rm = TRUE) #&gt; # A tibble: 27,004 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; # ... with 26,994 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 6.2.1 比较 对于比较大小，我们有 &gt;、&gt;=、&lt;、&lt;=、!= 和 ==。注意这里的等于用了两个等于符号表示（这与很多语言保持一致）。如果写成了一个，R 通常会 “机智地” 提醒你： filter(flights, month = 1) #&gt; Error in `filter()`: #&gt; ! We detected a named input. #&gt; i This usually means that you&#39;ve used `=` instead of `==`. #&gt; i Did you mean `month == 1`? #&gt; Backtrace: #&gt; 1. dplyr::filter(flights, month = 1) #&gt; 2. dplyr:::filter.data.frame(flights, month = 1) 注意：在比较数据时你可能会遇到浮点数，导致结果可能不符合常理： sqrt(2)^2 == 2 #&gt; [1] FALSE 1 / 49 * 49 == 1 #&gt; [1] FALSE 请使用 near() 函数解决这个问题： near(sqrt(2)^2, 2) #&gt; [1] TRUE near(1 / 49 * 49, 1) #&gt; [1] TRUE 6.2.2 逻辑运算符 R 提供了逻辑运算符 &amp;、| 和 nor()，在变量前加感叹号表示相反。 完整的布尔运算集。“x”是左边的圆圈，“y”是右边的圆圈，阴影区域显示每个操作员选择的部分。 6.2.3 缺失值 R 在数据缺失时会用 NA 表示。但注意它并不是单纯地表示 0。小心在比较时它会传染！ NA &gt; 5 #&gt; [1] NA 10 == NA #&gt; [1] NA NA + 10 #&gt; [1] NA NA / 2 #&gt; [1] NA NA == NA #&gt; [1] NA 我们需要人性地代入进去看待这个问题。这里有个很好的范例： # Let x be Mary&#39;s age. We don&#39;t know how old she is. x &lt;- NA # Let y be John&#39;s age. We don&#39;t know how old he is. y &lt;- NA # Are John and Mary the same age? x == y #&gt; [1] NA # We don&#39;t know! 6.3 排列 arange() # 按照年月日排序 arrange(flights, year, month, day) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 反向排序。注意无论正反向，NA 值都总是被排到末尾： arrange(flights, desc(dep_delay)) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 9 641 900 1301 1242 1530 #&gt; 2 2013 6 15 1432 1935 1137 1607 2120 #&gt; 3 2013 1 10 1121 1635 1126 1239 1810 #&gt; 4 2013 9 20 1139 1845 1014 1457 2210 #&gt; 5 2013 7 22 845 1600 1005 1044 1815 #&gt; 6 2013 4 10 1100 1900 960 1342 2211 #&gt; 7 2013 3 17 2321 810 911 135 1020 #&gt; 8 2013 6 27 959 1900 899 1236 2226 #&gt; 9 2013 7 22 2257 759 898 121 1026 #&gt; 10 2013 12 5 756 1700 896 1058 2020 #&gt; # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 6.4 选择 select() 注意一些方便的匹配规则： starts_with(\"abc\")：匹配以 “abc” 开头的名称。 ends_with(\"xyz\")：匹配以 “xyz” 结尾的名称。 contains(\"ijk\")：匹配包含 “ijk” 的名称。 matches(\"(.)\\\\1\")：选择与正则表达式匹配的变量。 num_range(\"x\", 1:3)：匹配 x1、x2和 x3。 # 选出年月日 select(flights, year, month, day) #&gt; # A tibble: 336,776 x 3 #&gt; year month day #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 #&gt; 2 2013 1 1 #&gt; 3 2013 1 1 #&gt; 4 2013 1 1 #&gt; 5 2013 1 1 #&gt; 6 2013 1 1 #&gt; 7 2013 1 1 #&gt; 8 2013 1 1 #&gt; 9 2013 1 1 #&gt; 10 2013 1 1 #&gt; # ... with 336,766 more rows select(flights, year:day) #&gt; # A tibble: 336,776 x 3 #&gt; year month day #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 #&gt; 2 2013 1 1 #&gt; 3 2013 1 1 #&gt; 4 2013 1 1 #&gt; 5 2013 1 1 #&gt; 6 2013 1 1 #&gt; 7 2013 1 1 #&gt; 8 2013 1 1 #&gt; 9 2013 1 1 #&gt; 10 2013 1 1 #&gt; # ... with 336,766 more rows # 选出除年月日以及 flight 的所有列 select(flights, -c(year:day, flight)) # 有时 c 可以省略掉 #&gt; # A tibble: 336,776 x 15 #&gt; dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 517 515 2 830 819 11 UA #&gt; 2 533 529 4 850 830 20 UA #&gt; 3 542 540 2 923 850 33 AA #&gt; 4 544 545 -1 1004 1022 -18 B6 #&gt; 5 554 600 -6 812 837 -25 DL #&gt; 6 554 558 -4 740 728 12 UA #&gt; 7 555 600 -5 913 854 19 B6 #&gt; 8 557 600 -3 709 723 -14 EV #&gt; 9 557 600 -3 838 846 -8 B6 #&gt; 10 558 600 -2 753 745 8 AA #&gt; # ... with 336,766 more rows, and 8 more variables: tailnum &lt;chr&gt;, #&gt; # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, #&gt; # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 选出结尾为 delay 相关的列 select(flights, ends_with(&quot;delay&quot;)) #&gt; # A tibble: 336,776 x 2 #&gt; dep_delay arr_delay #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 11 #&gt; 2 4 20 #&gt; 3 2 33 #&gt; 4 -1 -18 #&gt; 5 -6 -25 #&gt; 6 -4 12 #&gt; 7 -5 19 #&gt; 8 -3 -14 #&gt; 9 -3 -8 #&gt; 10 -2 8 #&gt; # ... with 336,766 more rows # 选出开头为 sched 相关的列 select(flights, starts_with(&quot;sched&quot;)) #&gt; # A tibble: 336,776 x 2 #&gt; sched_dep_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 515 819 #&gt; 2 529 830 #&gt; 3 540 850 #&gt; 4 545 1022 #&gt; 5 600 837 #&gt; 6 558 728 #&gt; 7 600 854 #&gt; 8 600 723 #&gt; 9 600 846 #&gt; 10 600 745 #&gt; # ... with 336,766 more rows # 选出包含 sched 相关的列 select(flights, contains(&quot;sched&quot;)) #&gt; # A tibble: 336,776 x 2 #&gt; sched_dep_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 515 819 #&gt; 2 529 830 #&gt; 3 540 850 #&gt; 4 545 1022 #&gt; 5 600 837 #&gt; 6 558 728 #&gt; 7 600 854 #&gt; 8 600 723 #&gt; 9 600 846 #&gt; 10 600 745 #&gt; # ... with 336,766 more rows # 选出的数据不包含带 sched的列，此外其他都包含 select(flights, -contains(&quot;sched&quot;), everything()) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time dep_delay arr_time arr_delay carrier flight #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 2 830 11 UA 1545 #&gt; 2 2013 1 1 533 4 850 20 UA 1714 #&gt; 3 2013 1 1 542 2 923 33 AA 1141 #&gt; 4 2013 1 1 544 -1 1004 -18 B6 725 #&gt; 5 2013 1 1 554 -6 812 -25 DL 461 #&gt; 6 2013 1 1 554 -4 740 12 UA 1696 #&gt; 7 2013 1 1 555 -5 913 19 B6 507 #&gt; 8 2013 1 1 557 -3 709 -14 EV 5708 #&gt; 9 2013 1 1 557 -3 838 -8 B6 79 #&gt; 10 2013 1 1 558 -2 753 8 AA 301 #&gt; # ... with 336,766 more rows, and 10 more variables: tailnum &lt;chr&gt;, #&gt; # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, #&gt; # minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, sched_dep_time &lt;int&gt;, sched_arr_time &lt;int&gt; 6.5 重命名 rename() 一般用得很少，但有时很刚需。其实它是 select() 的变体： rename(flights, tail_num = tailnum) 6.6 添加新变量 mutate() 与 transmute() # 生成优化版的 flights 数据集 flights_sml &lt;- select(flights, year:day, ends_with(&quot;delay&quot;), distance, air_time) mutate( flights_sml, gain = dep_delay - arr_delay, speed_min = distance / air_time, # 计算出的新数据 speed_sec = speed_min * 60 # 从刚生成的数据中套新数据 ) #&gt; # A tibble: 336,776 x 10 #&gt; year month day dep_delay arr_delay distance air_time gain speed_min #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 2 11 1400 227 -9 6.17 #&gt; 2 2013 1 1 4 20 1416 227 -16 6.24 #&gt; 3 2013 1 1 2 33 1089 160 -31 6.81 #&gt; 4 2013 1 1 -1 -18 1576 183 17 8.61 #&gt; 5 2013 1 1 -6 -25 762 116 19 6.57 #&gt; 6 2013 1 1 -4 12 719 150 -16 4.79 #&gt; 7 2013 1 1 -5 19 1065 158 -24 6.74 #&gt; 8 2013 1 1 -3 -14 229 53 11 4.32 #&gt; 9 2013 1 1 -3 -8 944 140 5 6.74 #&gt; 10 2013 1 1 -2 8 733 138 -10 5.31 #&gt; # ... with 336,766 more rows, and 1 more variable: speed_sec &lt;dbl&gt; # 生成数据中不包含旧数据，应该使用 transmute transmute( flights_sml, gain = dep_delay - arr_delay, speed_min = distance / air_time, # 计算出的新数据 speed_sec = speed_min * 60 # 从刚生成的数据中套新数据 ) #&gt; # A tibble: 336,776 x 3 #&gt; gain speed_min speed_sec #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -9 6.17 370. #&gt; 2 -16 6.24 374. #&gt; 3 -31 6.81 408. #&gt; 4 17 8.61 517. #&gt; 5 19 6.57 394. #&gt; 6 -16 4.79 288. #&gt; 7 -24 6.74 404. #&gt; 8 11 4.32 259. #&gt; 9 5 6.74 405. #&gt; 10 -10 5.31 319. #&gt; # ... with 336,766 more rows 6.7 分组摘要 summarise() 注意关注管道符号：%&gt;% # x %&gt;% f(y) 即为 f(x, y) msleep %&gt;% count(order, sort = TRUE) # 上面的等同于下面的 count(msleep, order, sort = T) 注意单纯的 summarize 并没有太大的用处： summarise( flights, delay = mean(dep_delay, na.rm = TRUE) # mean，取均值，na.rm 忽略空值 ) #&gt; # A tibble: 1 x 1 #&gt; delay #&gt; &lt;dbl&gt; #&gt; 1 12.6 所以我们一般配合 group_by 使用： by_day &lt;- group_by(flights, year, month, day) # 分组细节到年月日 summarise( by_day, delay = mean(dep_delay, na.rm = TRUE) # 组内的 [delay] 标签追加，按照算法分组返回值 ) #&gt; `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the #&gt; `.groups` argument. #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day delay #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 11.5 #&gt; 2 2013 1 2 13.9 #&gt; 3 2013 1 3 11.0 #&gt; 4 2013 1 4 8.95 #&gt; 5 2013 1 5 5.73 #&gt; 6 2013 1 6 7.15 #&gt; 7 2013 1 7 5.42 #&gt; 8 2013 1 8 2.55 #&gt; 9 2013 1 9 2.28 #&gt; 10 2013 1 10 2.84 #&gt; # ... with 355 more rows # 使用管道符 &quot;%&gt;%&quot; 精简代码 group_by(flights, year, month, day) %&gt;% summarise(delay = mean(dep_delay, na.rm = TRUE)) #&gt; `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the #&gt; `.groups` argument. #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day delay #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 11.5 #&gt; 2 2013 1 2 13.9 #&gt; 3 2013 1 3 11.0 #&gt; 4 2013 1 4 8.95 #&gt; 5 2013 1 5 5.73 #&gt; 6 2013 1 6 7.15 #&gt; 7 2013 1 7 5.42 #&gt; 8 2013 1 8 2.55 #&gt; 9 2013 1 9 2.28 #&gt; 10 2013 1 10 2.84 #&gt; # ... with 355 more rows 6.8 其他处理数据功能 算术运算符：+ - * /。它们可以用于向量，会自动帮你做一个 for 循环。 模算术：%/% 求模、 %% 求余。 Log：log()、log2()、log10()，即求对数。这些会在未来建模时常常用到。 偏移量：lag() 值前导、lead() 值滞后，用于将向量的值前导或滞后。如： (x &lt;- 1:10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 lag(x) #&gt; [1] NA 1 2 3 4 5 6 7 8 9 lead(x) #&gt; [1] 2 3 4 5 6 7 8 9 10 NA 累积和滚动聚合：cumsum() 总和、cumprod() 乘积、cummin() 最小值、cummax() 最大值、cummean() 均值。此外 dplyr 也提供累积手段。如果我们需要滚动聚合（即在滚动窗口上计算的总和），请尝试 RcppRoll 包。 (x &lt;- (1:10)) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 cumsum(x) #&gt; [1] 1 3 6 10 15 21 28 36 45 55 cummean(x) #&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.9 分析 flights 数据集 6.9.1 计算目的地相关的图 by_dest &lt;- group_by(flights, dest) # 以 dest 分组 delay &lt;- summarise( by_dest, count = n(), # 计算组内数据数量 dist = mean(distance, na.rm = TRUE), # 计算每组内的 distance 平均值 arr_delay = mean(arr_delay, na.rm = TRUE), # 同理，到达时间 ) # 精简得到想要的数据 delay &lt;- filter(delay, count &gt; 20, dest != &quot;HNL&quot;) # 到达数大于20次，目的地不为 HNL # 尝试画图 ggplot( data = delay, mapping = aes(x = dist, y = arr_delay) # 确定 data 和 mapping 的默认数据 ) + geom_point( aes(size = count), # 添加新的特殊数据 size（此处 mapping 为默认值，可省略声明） alpha = 1 / 3 # 透明度固定 ) + geom_smooth(se = FALSE) # 绘制平滑曲线 #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 6.9.2 获取热门目的地及有关数据 pop_dests &lt;- group_by(flights, dest) %&gt;% filter(n() &gt; 365) %&gt;% distinct(dest) # 筛选只要指定的列 head(pop_dests, 10) # 只展示前十 #&gt; # A tibble: 10 x 1 #&gt; # Groups: dest [10] #&gt; dest #&gt; &lt;chr&gt; #&gt; 1 IAH #&gt; 2 MIA #&gt; 3 BQN #&gt; 4 ATL #&gt; 5 ORD #&gt; 6 FLL #&gt; 7 IAD #&gt; 8 MCO #&gt; 9 PBI #&gt; 10 TPA 6.9.3 绘制飞机延误时长分布图 delays &lt;- flights %&gt;% # 获得处理后的数据 filter(!is.na(dep_delay), !is.na(arr_delay)) %&gt;% # 去除空 NA 数据 group_by(tailnum) %&gt;% # 按航班分组 summarise( # 获取平均值并产生包含 group_by 列和计算的新列 delay = mean(arr_delay, na.rm = TRUE), # 由于之前过滤过了，此处的 na.rm 可以去掉 n = n() # 统计数量，方便绘制直方图 ) delays %&gt;% filter(n &gt; 25) %&gt;% # 数量很小时往往会对数据产生较大影响。这里过滤掉它们 ggplot(mapping = aes(x = n, y = delay)) + geom_point(alpha = 1 / 10) 6.9.4 计算每天最早和最晚的航班 flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) %&gt;% group_by(year, month, day) %&gt;% summarise( first = min(dep_time), last = max(dep_time) ) #&gt; `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the #&gt; `.groups` argument. #&gt; # A tibble: 365 x 5 #&gt; # Groups: year, month [12] #&gt; year month day first last #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 2356 #&gt; 2 2013 1 2 42 2354 #&gt; 3 2013 1 3 32 2349 #&gt; 4 2013 1 4 25 2358 #&gt; 5 2013 1 5 14 2357 #&gt; 6 2013 1 6 16 2355 #&gt; 7 2013 1 7 49 2359 #&gt; 8 2013 1 8 454 2351 #&gt; 9 2013 1 9 2 2252 #&gt; 10 2013 1 10 3 2320 #&gt; # ... with 355 more rows "],["workflow-scripts.html", "Chapter 7 Workflow: scripts 7.1 运行代码 7.2 RStudio 诊断 7.3 使用 Visual studio code 编写 R", " Chapter 7 Workflow: scripts 到目前为止，我们一直在使用 Console 控制台来运行代码。但当我们创建更复杂的 ggplot2 图和 dplyr 管道时，我们会发现它很快就会变得狭窄。为了给自己更多的工作空间，使用脚本编辑器是个好主意。 通过单击 “文件” 菜单，然后选择 “新建文件” ，然后选择 “R 脚本”，或使用键盘快捷键 Cmd/Ctrl + Shift + N 将其打开。现在，我们将看到四个窗格： rstudio-editor 7.1 运行代码 脚本编辑器也是构建复杂的 ggplot2 图或长序列 dplyr 操作的好地方。一个最重要的快捷键：Cmd / Ctrl + Enter。这将在控制台中执行当前 R 表达式。选中代码时执行选中部分，否则它将自动执行光标所在的那一小段代码，然后自动将光标挪到下一段。 除了逐个表达式运行之外，快捷键：Cmd/Ctrl + Shift + S 用于执行整个当前文件。 7.2 RStudio 诊断 脚本编辑器还将在侧边栏中用红色波浪线和红色的错误图标突出显示语法错误： rstudio-diagnostic 将鼠标悬停在对应代码上以查看问题所在： rstudio-diagnostic-tip RStudio 还会让你了解潜在的问题： rstudio-diagnostic-warn 7.3 使用 Visual studio code 编写 R 这是激动人心的 —— 这款号称 “21 世纪最伟大的编辑器” 的通用代码编辑器成功让 R 运作起来了。但我们说，事情往往伴随着代价。在 VSCode 上，你可能需要一些基础去调整好它。它需要的核心是 Radian – A 21 century R console。 合理地使用 VScode，能提高我们的工作效率。而且控制台历史记录、查询、工作区与变量管理、智能装包、强大的帮助系统、缩进与格式化代码等功能它都不曾欠缺。相信聪明的读者应该有着更聪慧的头脑，在选择方面做出更为理智的决定吧。 "],["exploratory-data-analysis.html", "Chapter 8 Exploratory Data Analysis 8.1 绘图分析 diamonds 数据集 8.2 绘图统计 flights 数据集 8.3 绘图统计 diamonds 数据集", " Chapter 8 Exploratory Data Analysis 系统地可视化和转换探索数据，我们称为探索性数据分析或简称 EDA。EDA 是一个迭代循环，包括： 生成有关数据的问题。 通过可视化、转换和建模数据来搜索答案。 使用学到的知识来完善问题本身或生成新的问题。 此外请关注以下数据： 变量：可以测量的数量、质量或属性。 值：测量变量时变量的状态。变量的值可能因测量值而异。 观测值：在相似条件下进行的一组测量，将包含多个值，每个值都与不同的变量相关联。有时也叫数据点。 表格数据：一组值，每个值都与一个变量和一个观测值相关联。 library(tidyverse) 8.1 绘图分析 diamonds 数据集 8.1.1 可视化分布 分类变量的分布一般用条形图，如：统计各种品质钻石的数量并绘图 ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut)) 如果想要数据的话也可以用 dplyr::count() 统计。但事实上，所有 count() 能做的，group_by + summarise 都能： diamonds %&gt;% count(cut_width(carat, 0.5)) # cut_width() 将数据切片分组。注意新的列名叫 cut #&gt; # A tibble: 11 x 2 #&gt; `cut_width(carat, 0.5)` n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 [-0.25,0.25] 785 #&gt; 2 (0.25,0.75] 29498 #&gt; 3 (0.75,1.25] 15977 #&gt; 4 (1.25,1.75] 5313 #&gt; 5 (1.75,2.25] 2002 #&gt; 6 (2.25,2.75] 322 #&gt; 7 (2.75,3.25] 32 #&gt; 8 (3.25,3.75] 5 #&gt; 9 (3.75,4.25] 4 #&gt; 10 (4.25,4.75] 1 #&gt; 11 (4.75,5.25] 1 8.1.2 绘制频率直方图 直方图一般用来检查连续变量的分布，如：统计各种克拉数的数量并绘图 ggplot(data = diamonds) + geom_histogram( mapping = aes(x = carat), binwidth = 0.3 # 将宽度容纳（区间）增加至指定宽度 ) geom_histogram() 生成的是柱形图，但如果你想要叠加多个数据的话，更推荐能生成线条图的 geom_freqpoly()： ggplot(data = diamonds, mapping = aes(x = carat, colour = cut)) + geom_freqpoly(binwidth = 0.1) 想要数据的话使用 dplyr::count() 和 ggplot2::cut_width() 计算： diamonds %&gt;% count(cut_width(carat, 0.5)) #&gt; # A tibble: 11 x 2 #&gt; `cut_width(carat, 0.5)` n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 [-0.25,0.25] 785 #&gt; 2 (0.25,0.75] 29498 #&gt; 3 (0.75,1.25] 15977 #&gt; 4 (1.25,1.75] 5313 #&gt; 5 (1.75,2.25] 2002 #&gt; 6 (2.25,2.75] 322 #&gt; 7 (2.75,3.25] 32 #&gt; 8 (3.25,3.75] 5 #&gt; 9 (3.75,4.25] 4 #&gt; 10 (4.25,4.75] 1 #&gt; 11 (4.75,5.25] 1 8.1.3 异常数据（杂质） 异常值是超出正常范围的观察值。产生原因有时只是单纯的数据输入错误，但同样也很可能表明着新的重要科学。 例如这里用 y 列做研究： ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) 你会发现它们大多收缩成一团，而一些可疑的值明显影响了整个数据。 为了看到那些不寻常发值，我们使用 coord_cartesian() 将区别放大化： ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + coord_cartesian(ylim = c(0, 50)) # 将 y 轴放大化直到区间 0 ~ 50 当然这个函数也是有 xlim 参数的，同理。 有 3 个与众不同的值出现了！分别为 0、30、60。我们把它们提取出来： unusual &lt;- diamonds %&gt;% filter(y &lt; 3 | y &gt; 20) %&gt;% select(price, x, y, z) %&gt;% arrange(y) %&gt;% print() #&gt; # A tibble: 9 x 4 #&gt; price x y z #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 5139 0 0 0 #&gt; 2 6381 0 0 0 #&gt; 3 12800 0 0 0 #&gt; 4 15686 0 0 0 #&gt; 5 18034 0 0 0 #&gt; 6 2130 0 0 0 #&gt; 7 2130 0 0 0 #&gt; 8 2075 5.15 31.8 5.12 #&gt; 9 12210 8.09 58.9 8.06 这些值带着明显的伦理问题和常理性错误。而我们也最好是在没有异常值的情况下进行分析。如果它们对结果的影响很小，并且我们尚且无法弄清楚它们存在的原因，那么用缺失的值（NA）替换它们是合理的。但如果它们对我们的结果有实质性影响，则不应当无缘无故地放弃它们。 我们需要找出导致它们的原因（如数据输入错误），并合理地处理这些异常数据。 8.1.4 处理异常数据 法一：删除含异常值的整行 diamonds_new &lt;- diamonds %&gt;% filter(between(y, 3, 20)) # 新建数据集过滤掉杂质 法二：将异常值替换为 NA （推荐） diamonds_new &lt;- diamonds %&gt;% # 非常类似于 C 语言中的 xx?xx:xx 。如果 y 在 3 到 20 间则保持，否则返回 NA # 此外 dplyr::case_when() 有着近乎相同的功能 mutate(y = ifelse(y &gt; 3 &amp; y &lt; 20, y, NA)) 但事实上，如果数据含有 NA，ggplot 绘图会发出警告并将相应数据剔除不会展示出来： ggplot(data = diamonds_new, mapping = aes(x = x, y = y)) + geom_point() #&gt; Warning: Removed 9 rows containing missing values (geom_point). 我们应该手动移除带 NA 的无效数据： ggplot(data = diamonds_new, mapping = aes(x = x, y = y)) + geom_point(na.rm = TRUE) 8.2 绘图统计 flights 数据集 nycflights13::flights %&gt;% mutate( cancelled = is.na(dep_time), # 如果数据是 NA 就表示航班取消了 sched_hour = sched_dep_time %/% 100, # 国际计时除 100 商得到小时 sched_min = sched_dep_time %% 100, # 国际计时除 100 取余得到分钟 sched_dep_time = sched_hour + sched_min / 60 # 按照我们习惯转换成正常的分钟数 ) %&gt;% # freqpoly 非常适合折线图效果。对应的柱状图是 histogram # binwidth 通常会用来描述线或柱的精度。精度不足的部分会用平均值模糊化替代 ggplot(mapping = aes(sched_dep_time)) + geom_freqpoly(mapping = aes(color = cancelled), binwidth = 1 / 4) 但这样的图表并不友好，因为未取消的航班比取消的多得多而不方便观察分析细节。 8.3 绘图统计 diamonds 数据集 8.3.1 连续变量多类绘图 8.3.1.1 频率多边形 正如前面的频率多边形那样，我们通常需要观察按不同类别的连续变量的分布直方图。所以我们采用频率多边形来展示： ggplot(data = diamonds, mapping = aes(x = price)) + geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) 但不同类别之间的数据差异依然相对明显，一些相对 “小得多” 的类别的形状难以被观察到。使用柱状图可以明显看到各个种类计数差异巨大： ggplot(diamonds) + geom_bar(mapping = aes(x = cut)) 因此我们需要修改 y 轴的内容。我们将不显示计数，而是显示密度（使其标准化），以便每个频率多边形围成的面积正好为 1： ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) 实际结果令人震惊！品质最差钻石却有着最高的平均价格！（UC：明天来上班）这个图中有很多有趣的现象，我们将在后面的学习中继续做深度挖掘。 8.3.1.2 箱形图（箱线图） 箱线图是一种在统计学家中流行的值分布的视觉速记。其元素组成包括： 盒子中间：中位数 盒子两头：25% 和 75%，也称为四分位距（两头距离长度称作 IQR） 盒子两头延伸的细线：从盒子两头算起不超过 IQR 的 1.5 倍的最小和最大值 盒子两头远处的点：超过 IQR 的 1.5 倍的异常值 img ggplot(data = diamonds, mapping = aes(x = cut, y = price)) + geom_boxplot() 箱线图的信息展示会比频率多边形要紧凑得多，更利于我们比较。它支持了一个违反直觉的发现，即质量更好的钻石明显更便宜！ 8.3.2 关于变量排序 reorder() 像 cut 这样的变量可能还有一个较好的默认排序，但事实上我们遇到的很多数据集可能没有这么好，需要重新排序。reorder() 可以帮你做到。如 mpg 数据集的 class： ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() 为了使趋势更容易看到，我们可以根据 hwy 的“值” 重新排序： ggplot(data = mpg) + geom_boxplot(mapping = aes( # reorder 排序，对 class 根据对应的 hwy 值进行排序, median 用来确认函数是否具有返回值 x = reorder(class, hwy, FUN = median), y = hwy )) + coord_flip() # xy 轴交换，方便展示长变量名 8.3.3 两个分类变量 8.3.3.1 交点图 查看颜色与质量的关系： ggplot(data = diamonds_new) + # geom_count 用来通过显示点的大小展示数据大小（次数、频率） geom_count(mapping = aes(x = color, y = cut)) 8.3.3.2 色砖图 diamonds_new %&gt;% count(color, cut) %&gt;% # 这里只能手动计数，但不需要 group_by ggplot(mapping = aes(x = color, y = cut)) + # 注意这里的 color 只是边框颜色 geom_tile(mapping = aes(fill = n), color = &quot;grey50&quot;) 注意仅求数据可以用 count() 实现： diamonds %&gt;% count(color, cut) 8.3.4 两个连续变量 8.3.4.1 二维装箱 可视化两个连续变量之间协变量的一种好方法就是使用绘制散点图。如查看质量与价格的关系： ggplot(data = diamonds) + geom_point(mapping = aes(x = carat, y = price)) 散点图的点开始过度绘制，并密集堆积成均匀黑色的区域（如上所述）。一种解决方法是增加透明度： ggplot(data = diamonds_new) + geom_point(mapping = aes(x = carat, y = price), alpha = 1 / 100) # 对于非常大的数据集，使用透明度可能具有挑战性。一种解决方案是使用二维装箱 # 通过方形小色块（类似平均值效果）来模糊数据 ggplot(data = diamonds_new) + geom_bin2d(mapping = aes(x = carat, y = price)) # 或者使用六边形小块（需要安装包 hexbin） #* install.packages(&quot;hexbin&quot;) ggplot(data = diamonds_new) + geom_hex(mapping = aes(x = carat, y = price)) 8.3.4.2 箱线图装箱 另一种选择是将一个连续变量装箱，使其像分类变量一样工作。所以我们使用 cut_width 分组： ggplot(data = diamonds_new, mapping = aes(x = carat, y = price)) + # cut_width 是 ggplot 包的函数，用来切片配合分组，将前者以后者数值划分 geom_boxplot(mapping = aes(group = cut_width(carat, 0.3))) 或者在每个条柱中显示大致相同的点数。我们使用 cut_number() 分组： ggplot(data = diamonds_new, mapping = aes(x = carat, y = price)) + geom_boxplot(mapping = aes(group = cut_number(carat, 20))) "],["workflow-projects.html", "Chapter 9 Workflow: projects 9.1 运行环境 9.2 工作区 9.3 路径与目录 9.4 RStudio 项目", " Chapter 9 Workflow: projects 9.1 运行环境 使用 R 脚本（和数据文件），可以重新创建环境。从环境中重新创建 R 脚本要困难得多！你要么必须从内存中重新键入大量代码，要么必须仔细挖掘你的 R 脚本执行历史记录。 为了培养这种行为，我强烈建议我们将 RStudio 设置为不要在会话之间保留我们的工作区记录： rstudio-workspace 有一对很棒的键盘快捷键可以协同工作，以确保我们在编辑器中存储了代码的重要部分： Cmd/Ctrl + Shift + F10 重新启动 RStudio。 Cmd/Ctrl + Shift + S 重新运行当前脚本。 9.2 工作区 工作区目录对 R 的文件路径处理上非常重要。这是 R 查找你所要求加载文件和保存执行文件的位置。RStudio 在控制台顶部会显示当前的工作目录： rstudio-wd 使用 getwd() 命令在 R 控制台中打印出来： getwd() #&gt; [1] &quot;D:/Project/R-Project/book&quot; 作为 R 用户，可以让你的任何奇怪的目录成为 R 的工作目录。我们应该很快将要分析的项目组织到目录中，并且在处理项目时，将 R 的工作目录设置为与之关联的目录。 使用 setwd() 从控制台中设置工作目录（不推荐）： setwd(&quot;/path/to/my/CoolProject&quot;) 9.3 路径与目录 路径和目录有点复杂，因为Mac/Linux 和 Windows 两者不太一样： Mac 和 Linux 使用斜杠 “/”，Windows 使用反斜杠 “”。R 可以使用任何一种类型（无论我们当前使用的是什么平台），但在路径中要单个反斜杠，我们需要键入两个反斜杠去等效，所以建议始终使用正斜杠路径，如：plots/diamonds.pdf 绝对路径看起来都不同。在 Windows 中，它们以驱动器号 + 冒号 + 两个反斜杠开头，如 C:\\\\servername；而在 Mac / Linux 中，它们以斜杠开头，如 /users/hadley。所以建议不使用绝对路径，以保证代码的兼容性和可共享性。 ~ 指向的地方也不太相同。它本是通往主目录的便捷方式，但 Windows 并没有这种概念，因此 R 中它指向文档目录。 9.4 RStudio 项目 一个普遍明智的做法是，将与项目关联的所有文件保存在一起，包括输入数据、R 脚本、分析结果和数字。 单击 文件 &gt; 新建项目 来创建它： rstudio-project-1 rstudio-project-2 rstudio-project-3 以后保存文件应该使用如下方式： library(tidyverse) ggplot(diamonds, aes(carat, price)) + geom_hex() ggsave(&quot;diamonds.pdf&quot;) write_csv(diamonds, &quot;diamonds.csv&quot;) "],["wrangle-intro.html", "Chapter 10 Introduction", " Chapter 10 Introduction 数据扭结，以合适的形式将数据导入 R 用于可视化和建模。数据整理非常重要：没有它，你就无法处理自己的数据！数据整理有三个主要部分： data-science-wrangle 在 tibbles 中，你将了解到贯穿全全笔记中使用的 dataframe 的变体：tibble。你将了解它们与常规数据框的不同之处，以及如何 “手动” 构建它们。 在数据导入中，你将了解如何将数据从磁盘获取到 R 中。我们将重点介绍纯文本的矩阵格式，但会为你提供指向有助于处理其他类型的数据的包的指南。 在整洁的数据中，你将了解整洁的数据，这是一种存储数据的一种约定俗成的方式，使转换、可视化和建模更加容易。你将学习基本原则，以及如何将数据转换为整洁的形式。 数据扭结还包括数据转换。接下来我们将重点介绍实践中常用的三种特定类型数据的新技能： 关系数据将为你提供用于处理多个相互关联的数据集的工具。 字符串工具将携手正则表达式，这是一种用于操作字符串的强大工具。 因子是 R 如何存储分类数据的。一般被用于当变量具有一组固定的可能值，或者当你希望使用字符串的非字母排序。 日期和时间工具将为你提供处理日期和日期时间的关键工具。 "],["tibbles.html", "Chapter 11 Tibbles 11.1 创建 tibble 11.2 tibbles VS. data.frame 11.3 tibble 的转换", " Chapter 11 Tibbles 就像我们之前提到的那样，我们常常使用来自 tidyverse 的 tibbles，而不是 R 传统的 data.frame。Tibbles 是一种比 R 自带的 dataframe 更人性化更方便的数据集存储形式。 library(tidyverse) 11.1 创建 tibble 11.1.1 as_tibble() 我们使用 as_tibble() 来转化原有的 dataframe： as_tibble(iris) #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; 7 4.6 3.4 1.4 0.3 setosa #&gt; 8 5 3.4 1.5 0.2 setosa #&gt; 9 4.4 2.9 1.4 0.2 setosa #&gt; 10 4.9 3.1 1.5 0.1 setosa #&gt; # ... with 140 more rows 11.1.2 tibble() 或者使用 tibble() 直接创建： tibble( x = 1:5, y = 1, z = x^2 + y ) #&gt; # A tibble: 5 x 3 #&gt; x y z #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 2 #&gt; 2 2 1 5 #&gt; 3 3 1 10 #&gt; 4 4 1 17 #&gt; 5 5 1 26 11.1.3 tribble() 这种方法真的优雅很多！就像你在书写 markdown 一样 ~ tribble( ~x, ~y, ~z, #--|--|--- &quot;a&quot;, 2, 3.6, &quot;b&quot;, 1, 8.5 ) #&gt; # A tibble: 2 x 3 #&gt; x y z #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a 2 3.6 #&gt; 2 b 1 8.5 将符号或数字放在开头虽然墙裂不推荐，但 tibble 也不会报错： tb &lt;- tibble( `:)` = &quot;smile&quot;, # 注意使用 `` 来囊括 ` ` = &quot;space&quot;, `2000` = &quot;number&quot; ) tb #&gt; # A tibble: 1 x 3 #&gt; `:)` ` ` `2000` #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 smile space number 11.2 tibbles VS. data.frame 11.2.1 控制台打印方面 tibble( a = lubridate::now() + runif(1e3) * 86400, b = lubridate::today() + runif(1e3) * 30, c = 1:1e3, d = runif(1e3), e = sample(letters, 1e3, replace = TRUE) ) #&gt; # A tibble: 1,000 x 5 #&gt; a b c d e #&gt; &lt;dttm&gt; &lt;date&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 2022-05-29 20:36:38 2022-06-16 1 0.381 w #&gt; 2 2022-05-29 02:25:38 2022-06-16 2 0.177 f #&gt; 3 2022-05-29 02:24:24 2022-06-05 3 0.773 v #&gt; 4 2022-05-29 15:20:57 2022-06-22 4 0.230 v #&gt; 5 2022-05-29 12:51:27 2022-06-17 5 0.484 t #&gt; 6 2022-05-29 14:54:41 2022-06-13 6 0.533 b #&gt; 7 2022-05-29 13:37:38 2022-06-09 7 0.616 q #&gt; 8 2022-05-30 01:05:39 2022-05-29 8 0.933 m #&gt; 9 2022-05-29 11:19:15 2022-06-06 9 0.855 x #&gt; 10 2022-05-29 07:22:40 2022-05-31 10 0.876 j #&gt; # ... with 990 more rows tibble 对于太多的数据，只会显示前十行，不会让你的控制台被内容淹没；同时会显示每一列的数据类型。这得益于 str() 函数。 tibble 还完美兼容 print() 函数： nycflights13::flights %&gt;% print(n = 10, width = Inf) # Inf 表示无限，即所有指定内容（前十行）都打印 #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; arr_delay carrier flight tailnum origin dest air_time distance hour minute #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 11 UA 1545 N14228 EWR IAH 227 1400 5 15 #&gt; 2 20 UA 1714 N24211 LGA IAH 227 1416 5 29 #&gt; 3 33 AA 1141 N619AA JFK MIA 160 1089 5 40 #&gt; 4 -18 B6 725 N804JB JFK BQN 183 1576 5 45 #&gt; 5 -25 DL 461 N668DN LGA ATL 116 762 6 0 #&gt; 6 12 UA 1696 N39463 EWR ORD 150 719 5 58 #&gt; 7 19 B6 507 N516JB EWR FLL 158 1065 6 0 #&gt; 8 -14 EV 5708 N829AS LGA IAD 53 229 6 0 #&gt; 9 -8 B6 79 N593JB JFK MCO 140 944 6 0 #&gt; 10 8 AA 301 N3ALAA LGA ORD 138 733 6 0 #&gt; time_hour #&gt; &lt;dttm&gt; #&gt; 1 2013-01-01 05:00:00 #&gt; 2 2013-01-01 05:00:00 #&gt; 3 2013-01-01 05:00:00 #&gt; 4 2013-01-01 05:00:00 #&gt; 5 2013-01-01 06:00:00 #&gt; 6 2013-01-01 05:00:00 #&gt; 7 2013-01-01 06:00:00 #&gt; 8 2013-01-01 06:00:00 #&gt; 9 2013-01-01 06:00:00 #&gt; 10 2013-01-01 06:00:00 #&gt; # ... with 336,766 more rows 查看数据的另一种办法是使用 view() 函数，会更直观地显示在你的编辑器上。 nycflights13::flights %&gt;% head(10) %&gt;% view() # 请不要尝试展示太多数据！小心的的电脑炸掉（ 11.2.2 读取子元素方面 元数据建立如下： df &lt;- tibble( x = runif(5), y = rnorm(5) ) 按名字读取: df$x #&gt; [1] 0.8921433 0.8627795 0.9768724 0.8933510 0.5142061 df[[&quot;x&quot;]] #&gt; [1] 0.8921433 0.8627795 0.9768724 0.8933510 0.5142061 按序列位置读取： df[[1]] #&gt; [1] 0.8921433 0.8627795 0.9768724 0.8933510 0.5142061 但如果使用管道符的话，我们需要使用 “.”： df %&gt;% .$x #&gt; [1] 0.8921433 0.8627795 0.9768724 0.8933510 0.5142061 df %&gt;% .[[&quot;x&quot;]] #&gt; [1] 0.8921433 0.8627795 0.9768724 0.8933510 0.5142061 11.3 tibble 的转换 上面提到使用 as_tibble() 将 data.frame 转换为 tibble，而 as.data.frame() 函数则是将 tibble 转化为 data.frame： class(as.data.frame(tb)) # class() 函数用于检查数据格式 #&gt; [1] &quot;data.frame&quot; "],["data-import.html", "Chapter 12 Data import 12.1 简单读取文件 12.2 解析向量 12.3 数字类型 12.4 字符类型 12.5 因子类型 12.6 日期时间类型 12.7 解析文件 12.8 写入数据", " Chapter 12 Data import library(tidyverse) 12.1 简单读取文件 文件特征 函数 适用条件 符号分隔 read_csv() 逗号分隔 符号分隔 read_csv2() 分号分隔（常见于用作小数位的国家） 符号分隔 read_tsv() 制表符分隔 符号分隔 read_delim() 任何符号分隔 固定宽度 read_fwf() 固定宽度 固定宽度 fwf_widths() 宽度指定字段 固定宽度 fwf_positions() 位置指定字段 固定宽度 read_table() 固定宽度文件的常见变体，且列用空格分隔 日志 read_log() Apache 风格的日志文件 此外 webreadr 基于 read_log() 构建，并提供更多有用的工具。这些函数都有类似的语法：一旦我们掌握了一个，我们可以轻松地使用其他功能。 csv 文件是最常见的数据存储形式之一。我们将重点关注 read_csv()，其首个参数最为重要，即要读取的文件的路径。 read_csv() 会给出相当丰富的信息，包括行列数、分隔符、各列的数据格式（自动识别）等： heights &lt;- read_csv(&quot;./source/heights.csv&quot;) #&gt; Rows: 1192 Columns: 6 #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; Delimiter: &quot;,&quot; #&gt; chr (2): sex, race #&gt; dbl (4): earn, height, ed, age #&gt; #&gt; i Use `spec()` to retrieve the full column specification for this data. #&gt; i Specify the column types or set `show_col_types = FALSE` to quiet this message. 对于内联表格我们同样可以这样处理： read_csv(&quot;a,b,c 1,2,3 4,5,6&quot;) #&gt; Rows: 2 Columns: 3 #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; Delimiter: &quot;,&quot; #&gt; dbl (3): a, b, c #&gt; #&gt; i Use `spec()` to retrieve the full column specification for this data. #&gt; i Specify the column types or set `show_col_types = FALSE` to quiet this message. #&gt; # A tibble: 2 x 3 #&gt; a b c #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2 3 #&gt; 2 4 5 6 如果内容的开头有一些不需要的数据，我们可以跳过开头的内容： read_csv(&quot;The first line of metadata The second line of metadata x,y,z 1,2,3&quot;, skip = 2) #&gt; Rows: 1 Columns: 3 #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; Delimiter: &quot;,&quot; #&gt; dbl (3): x, y, z #&gt; #&gt; i Use `spec()` to retrieve the full column specification for this data. #&gt; i Specify the column types or set `show_col_types = FALSE` to quiet this message. #&gt; # A tibble: 1 x 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2 3 或者直接跳过以指定字符开头的行（如以 “#” 开头） read_csv(&quot;# A comment I want to skip x,y,z 1,2,3&quot;, comment = &quot;#&quot;) #&gt; Rows: 1 Columns: 3 #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; Delimiter: &quot;,&quot; #&gt; dbl (3): x, y, z #&gt; #&gt; i Use `spec()` to retrieve the full column specification for this data. #&gt; i Specify the column types or set `show_col_types = FALSE` to quiet this message. #&gt; # A tibble: 1 x 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2 3 有时导入的数据可能没有表头！忽略掉表头，R 会为你加上 “X1”、“X2”… read_csv(&quot;1,2,3\\n4,5,6&quot;, col_names = FALSE) #&gt; Rows: 2 Columns: 3 #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; Delimiter: &quot;,&quot; #&gt; dbl (3): X1, X2, X3 #&gt; #&gt; i Use `spec()` to retrieve the full column specification for this data. #&gt; i Specify the column types or set `show_col_types = FALSE` to quiet this message. #&gt; # A tibble: 2 x 3 #&gt; X1 X2 X3 #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2 3 #&gt; 2 4 5 6 或者手动加表头： read_csv(&quot;1,2,3\\n4,5,6&quot;, col_names = c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;)) #&gt; Rows: 2 Columns: 3 #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; Delimiter: &quot;,&quot; #&gt; dbl (3): x, y, z #&gt; #&gt; i Use `spec()` to retrieve the full column specification for this data. #&gt; i Specify the column types or set `show_col_types = FALSE` to quiet this message. #&gt; # A tibble: 2 x 3 #&gt; x y z #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2 3 #&gt; 2 4 5 6 不只是表头，有时数据也会缺失。对 NA 值的数进行符号标记即可： read_csv(&quot;a,b,c\\n1,2,.&quot;, na = &quot;.&quot;) #&gt; Rows: 1 Columns: 3 #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; Delimiter: &quot;,&quot; #&gt; dbl (2): a, b #&gt; lgl (1): c #&gt; #&gt; i Use `spec()` to retrieve the full column specification for this data. #&gt; i Specify the column types or set `show_col_types = FALSE` to quiet this message. #&gt; # A tibble: 1 x 3 #&gt; a b c #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; #&gt; 1 1 2 NA 12.2 解析向量 在深入了解阅读器如何从磁盘读取文件之前，我们需要先了解 parse_*() 函数。对这些函数传入字符串向量，可以得到数据类型更专一合理的向量，如逻辑、整数或日期： str(parse_logical(c(&quot;TRUE&quot;, &quot;FALSE&quot;, &quot;NA&quot;))) # str() 用于显示 R 对象的内部结构 #&gt; logi [1:3] TRUE FALSE NA str(parse_integer(c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;))) #&gt; int [1:3] 1 2 3 str(parse_date(c(&quot;2010-01-01&quot;, &quot;1979-10-14&quot;))) #&gt; Date[1:2], format: &quot;2010-01-01&quot; &quot;1979-10-14&quot; 我们也可以设置缺省值： parse_integer(c(&quot;1&quot;, &quot;231&quot;, &quot;.&quot;, &quot;456&quot;), na = &quot;.&quot;) #&gt; [1] 1 231 NA 456 解析失败会提示相关警示： x &lt;- parse_integer(c(&quot;123&quot;, &quot;345&quot;, &quot;abc&quot;, &quot;123.45&quot;)) #&gt; Warning: 2 parsing failures. #&gt; row col expected actual #&gt; 3 -- an integer abc #&gt; 4 -- no trailing characters 123.45 之后的读取也会报错： x #&gt; [1] 123 345 NA NA #&gt; attr(,&quot;problems&quot;) #&gt; # A tibble: 2 x 4 #&gt; row col expected actual #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 NA an integer abc #&gt; 2 4 NA no trailing characters 123.45 和提示的一样，我们可以使用 problems() 函数显示错误根源： problems(x) #&gt; # A tibble: 2 x 4 #&gt; row col expected actual #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 NA an integer abc #&gt; 2 4 NA no trailing characters 123.45 12.3 数字类型 不同国家地区使用的分隔符、习惯等都不相同。所以这里有 locale 参数用来处理。如： 小数点标识符（decimal_mark）： parse_double(&quot;1.23&quot;) #&gt; [1] 1.23 parse_double(&quot;1,23&quot;, locale = locale(decimal_mark = &quot;,&quot;)) # 改用 “,” 识别 #&gt; [1] 1.23 数字前后非数字字符： parse_number(&quot;$100&quot;) #&gt; [1] 100 parse_number(&quot;20%&quot;) #&gt; [1] 20 parse_number(&quot;It cost $123.45&quot;) #&gt; [1] 123.45 位数标记（grouping_mark）： parse_number(&quot;$123,456,789&quot;) #&gt; [1] 123456789 parse_number(&quot;123.456.789&quot;, locale = locale(grouping_mark = &quot;.&quot;)) # 常见于欧洲 #&gt; [1] 123456789 parse_number(&quot;123&#39;456&#39;789&quot;, locale = locale(grouping_mark = &quot;&#39;&quot;)) # 常见于瑞士 #&gt; [1] 123456789 12.4 字符类型 貌似 parse_character() 是只会返回输入的无用函数。但事实上，我们有多种方式来表示同一字符串。要了解 R 中如何表示字符串的细节，我们可以使用 charToRaw() 获得字符串的底层表示： charToRaw(&quot;Hadley&quot;) #&gt; [1] 48 61 64 6c 65 79 像这样，从十六进制数字到字符的映射的编码称为 ASCII，也是美国信息交换标准代码。但英语以外的编码就非常复杂了，用不同编码读取数据，他们将完全不同。 如今我们有一个通用标准：UTF-8。UTF-8几乎可以编码当今人类使用的每个字符，以及许多额外的符号。 但旧的非通用标准有时也是需要的： (x1 &lt;- &quot;El Ni\\xf1o was particularly bad this year&quot;) #&gt; [1] &quot;El Ni駉 was particularly bad this year&quot; (x2 &lt;- &quot;\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd&quot;) #&gt; [1] &quot;偙傫偵偪偼&quot; 使用 encoding 来转译它们的编码： parse_character(x1, locale = locale(encoding = &quot;Latin1&quot;)) #&gt; [1] &quot;El Ni&lt;U+00F1&gt;o was particularly bad this year&quot; parse_character(x2, locale = locale(encoding = &quot;Shift-JIS&quot;)) #&gt; [1] &quot;こんにちは&quot; 有时我们并不知道它是什么类型的编码！所幸的是，guess_encodeing() 会帮助我们尝试： guess_encoding(charToRaw(x1)) #&gt; # A tibble: 2 x 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 ISO-8859-1 0.46 #&gt; 2 ISO-8859-9 0.23 guess_encoding(charToRaw(x2)) #&gt; # A tibble: 1 x 2 #&gt; encoding confidence #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 KOI8-R 0.42 12.5 因子类型 R 使用因子来表示具有一组已知可能值的分类变量。给 parse_factor() 一个已知 levels 的向量，以便在出现意外值时生成警告： fruit &lt;- c(&quot;apple&quot;, &quot;banana&quot;) parse_factor(c(&quot;apple&quot;, &quot;banana&quot;, &quot;bananana&quot;), levels = fruit) #&gt; Warning: 1 parsing failure. #&gt; row col expected actual #&gt; 3 -- value in level set bananana #&gt; [1] apple banana &lt;NA&gt; #&gt; attr(,&quot;problems&quot;) #&gt; # A tibble: 1 x 4 #&gt; row col expected actual #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 NA value in level set bananana #&gt; Levels: apple banana 12.6 日期时间类型 我们可以根据想要的日期（自1970-01-01以来的天数）、日期时间（自1970-01-01年以来的秒数）或时间（自午夜以来的秒数），在三个解析器之间进行选择。当在没有任何其他参数的情况下调用时： parse_datetime() 根据 ISO8601 国际标准转换日期时间： parse_datetime(&quot;2010-10-01T2010&quot;) #&gt; [1] &quot;2010-10-01 20:10:00 UTC&quot; # If time is omitted, it will be set to midnight parse_datetime(&quot;20101010&quot;) #&gt; [1] &quot;2010-10-10 UTC&quot; parse_date() 用于转换四位数年份，使用 “-” 或 “/” 都可（但没有分隔符则会报错）： parse_date(&quot;2010-10-01&quot;) #&gt; [1] &quot;2010-10-01&quot; parse_time() 用于转换时分秒（秒和上下午可选）： library(hms) # R 不自带，我们需要调用 hms 包（tidyverse 的 readr 包也有） parse_time(&quot;01:10 am&quot;) #&gt; 01:10:00 parse_time(&quot;20:10:01&quot;) #&gt; 20:10:01 此外日期时间字符串形式可以自己制定： 类型 表示符 备注 示例 年 %Y 4位数字 年 %y 2位数字 00-69 -&gt; 2000-2069 月 %m 2位数字 月 %b 缩写 Jan 月 %B 全称 一月 日 %d 2位数字 日 %e optional leading space 时 %H 0-23小时 时 %I 0-12小时，与 %p 捆绑使用 上下午 %p AM/PM 分 %M 分钟 秒 %S 整数秒 秒 %OS 真正意义的秒 时区 %Z 时区（名称） America/Chicago 标准时区 %z 以 UTC 标准时区做偏移量 +0800 非数字 %. 跳过一个非数字字符 非数字 %* 跳过任意数量的非数字 例如： parse_date(&quot;01/02/15&quot;, &quot;%m/%d/%y&quot;) #&gt; [1] &quot;2015-01-02&quot; parse_date(&quot;01/02/15&quot;, &quot;%d/%m/%y&quot;) #&gt; [1] &quot;2015-02-01&quot; parse_date(&quot;01/02/15&quot;, &quot;%y/%m/%d&quot;) #&gt; [1] &quot;2001-02-15&quot; 如果将 %b 或 %B 与非英语的月份名称一起使用，则需要将 lang 参数设置为 locale()。使用函数 date_names_langs() 查看内置语言列表，或者使用 date_names() 自定义。 parse_date(&quot;1 janvier 2015&quot;, &quot;%d %B %Y&quot;, locale = locale(&quot;fr&quot;)) #&gt; [1] &quot;2015-01-01&quot; 12.7 解析文件 12.7.1 自动匹配 readr 一般读取前 1000 行，并使用一些 “启发式” 的方法（保持适度保守）来确定每列的类型。其中 guess_parser() 返回字符向量的最佳类型猜测，而 parse_guess() 返回用该类型解析的内容： guess_parser(&quot;2010-10-01&quot;) #&gt; [1] &quot;date&quot; guess_parser(&quot;15:01&quot;) #&gt; [1] &quot;time&quot; guess_parser(c(&quot;TRUE&quot;, &quot;FALSE&quot;)) #&gt; [1] &quot;logical&quot; guess_parser(c(&quot;1&quot;, &quot;5&quot;, &quot;9&quot;)) #&gt; [1] &quot;double&quot; guess_parser(c(&quot;12,352,561&quot;)) #&gt; [1] &quot;number&quot; str(parse_guess(&quot;2010-10-10&quot;)) #&gt; Date[1:1], format: &quot;2010-10-10&quot; 这种 “启发式” 尝试以下每种类型，并在找到满足匹配项时停止： - 逻辑值：仅包含 “F”、“T”、“FALSE” 或 “TRUE”。 - 整数：仅包含数字字符（可能还有 “-”）。 - 小数：仅包含有效的小数（可能还有 4.5e-5 等数字）。 - 数字：包含有效的小数类型（可能还有分组标记）。 - 时间：与默认的 time_format 匹配。 - 日期：与默认的 date_format 匹配。 - 日期时间：任何满足 ISO8601 格式的日期时间。如果这些规则都不适用，那么该列将保持字符串向量。 12.7.2 自动匹配遇到的问题 在学习这里的时候发现问题已经无法复现。此处已经不再报错 challenge &lt;- read_csv(readr_example(&quot;challenge.csv&quot;)) #&gt; ── Column specification ─────────────────────────────────────────── #&gt; cols( #&gt; x = col_double(), #&gt; y = col_logical() #&gt; ) #&gt; Warning: 1000 parsing failures. #&gt; row col expected actual file #&gt; 1001 y 1/0/T/F/TRUE/FALSE 2015-01-16 &#39;/Users/runner/work/_temp/… #&gt; 1002 y 1/0/T/F/TRUE/FALSE 2018-05-18 &#39;/Users/runner/work/_temp/… #&gt; 1003 y 1/0/T/F/TRUE/FALSE 2015-09-05 &#39;/Users/runner/work/_temp/… #&gt; 1004 y 1/0/T/F/TRUE/FALSE 2012-11-28 &#39;/Users/runner/work/_temp/… #&gt; 1005 y 1/0/T/F/TRUE/FALSE 2020-01-13 &#39;/Users/runner/work/_temp/… #&gt; .... ... .................. .......... .........................… #&gt; See problems(...) for more details. 我们决定对错误进行定位： problems(challenge) #&gt; # A tibble: 1,000 x 5 #&gt; row col expected actual file #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1001 y 1/0/T/F/TRUE/F… 2015-01… &#39;/Users/runner/work/_temp/… #&gt; 2 1002 y 1/0/T/F/TRUE/F… 2018-05… &#39;/Users/runner/work/_temp/… #&gt; 3 1003 y 1/0/T/F/TRUE/F… 2015-09… &#39;/Users/runner/work/_temp/… #&gt; 4 1004 y 1/0/T/F/TRUE/F… 2012-11… &#39;/Users/runner/work/_temp/… #&gt; 5 1005 y 1/0/T/F/TRUE/F… 2020-01… &#39;/Users/runner/work/_temp/… #&gt; 6 1006 y 1/0/T/F/TRUE/F… 2016-04… &#39;/Users/runner/work/_temp/… #&gt; # … with 994 more rows 嗯…怎么看了跟没看似的。tail() 函数用来查看表头或表尾： tail(challenge) #&gt; # A tibble: 6 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;lgl&gt; #&gt; 1 0.805 NA #&gt; 2 0.164 NA #&gt; 3 0.472 NA #&gt; 4 0.718 NA #&gt; 5 0.270 NA #&gt; 6 0.608 NA 这表明我们需要手动对数据进行解析： challenge &lt;- read_csv( readr_example(&quot;challenge.csv&quot;), col_types = cols( # 对列类型进行手动声明 x = col_double(), # 第一列为 x，小数类型 y = col_logical() # 第二列为 y，逻辑值类型 ) ) #&gt; Warning: One or more parsing issues, see `problems()` for details challenge &lt;- read_csv( readr_example(&quot;challenge.csv&quot;), col_types = cols( x = col_double(), y = col_date() ) ) tail(challenge) #&gt; # A tibble: 6 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;date&gt; #&gt; 1 0.805 2019-11-21 #&gt; 2 0.164 2018-03-29 #&gt; 3 0.472 2014-08-04 #&gt; 4 0.718 2015-08-16 #&gt; 5 0.270 2020-02-04 #&gt; 6 0.608 2019-01-06 col_types 是有必要的，这至少能确保它生成的数据更为可靠一些。 12.7.3 其他的匹配解决策略 上面提到的自动解析出错只是因为默认的 1000 行不够用而已。哪怕只是多解析一行： challenge2 &lt;- read_csv(readr_example(&quot;challenge.csv&quot;), guess_max = 1001) #&gt; Rows: 2000 Columns: 2 #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; Delimiter: &quot;,&quot; #&gt; dbl (1): x #&gt; date (1): y #&gt; #&gt; i Use `spec()` to retrieve the full column specification for this data. #&gt; i Specify the column types or set `show_col_types = FALSE` to quiet this message. challenge2 #&gt; # A tibble: 2,000 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;date&gt; #&gt; 1 404 NA #&gt; 2 4172 NA #&gt; 3 3004 NA #&gt; 4 787 NA #&gt; 5 37 NA #&gt; 6 2332 NA #&gt; 7 2489 NA #&gt; 8 1449 NA #&gt; 9 3665 NA #&gt; 10 3863 NA #&gt; # ... with 1,990 more rows 你看。问题解决了呢。 另外一种思路是将向量声明为默认字符类型向量，这可能使你的定位更容易一些： challenge2 &lt;- read_csv(readr_example(&quot;challenge.csv&quot;), col_types = cols(.default = col_character()) ) 这里用简单的数据集演示 type_convert() 的效果： df &lt;- tribble( ~x, ~y, &quot;1&quot;, &quot;1.21&quot;, &quot;2&quot;, &quot;2.32&quot;, &quot;3&quot;, &quot;4.56&quot; ) df #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 1.21 #&gt; 2 2 2.32 #&gt; 3 3 4.56 type_convert(df) #&gt; #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; cols( #&gt; x = col_double(), #&gt; y = col_double() #&gt; ) #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1.21 #&gt; 2 2 2.32 #&gt; 3 3 4.56 可以看到 “启发性” 转换到底转换成了什么类型。 12.8 写入数据 12.8.1 csv 格式 write_csv(challenge, &quot;./source/challenge.csv&quot;) 很简单，不是吗？小心事情还没结束。你看，数据类型就这么丢了： challenge #&gt; # A tibble: 2,000 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;date&gt; #&gt; 1 404 NA #&gt; 2 4172 NA #&gt; 3 3004 NA #&gt; 4 787 NA #&gt; 5 37 NA #&gt; 6 2332 NA #&gt; 7 2489 NA #&gt; 8 1449 NA #&gt; 9 3665 NA #&gt; 10 3863 NA #&gt; # ... with 1,990 more rows write_csv(challenge, &quot;./source/challenge-2.csv&quot;) read_csv(&quot;./source/challenge-2.csv&quot;) #&gt; Rows: 2000 Columns: 2 #&gt; -- Column specification ------------------------------------------------------------------------------------------------------------------------------------------ #&gt; Delimiter: &quot;,&quot; #&gt; dbl (1): x #&gt; date (1): y #&gt; #&gt; i Use `spec()` to retrieve the full column specification for this data. #&gt; i Specify the column types or set `show_col_types = FALSE` to quiet this message. #&gt; # A tibble: 2,000 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;date&gt; #&gt; 1 404 NA #&gt; 2 4172 NA #&gt; 3 3004 NA #&gt; 4 787 NA #&gt; 5 37 NA #&gt; 6 2332 NA #&gt; 7 2489 NA #&gt; 8 1449 NA #&gt; 9 3665 NA #&gt; 10 3863 NA #&gt; # ... with 1,990 more rows 12.8.2 rds 格式 为了解决这个问题，我们提出了新的函数：write_rds() 和 read_rds() 基于 R 的基本函数 readRDS() 和 saveRDS()。注意这些数据会以被 R 称为 RDS 格式的自定义二进制格式存储数据： write_rds(challenge, &quot;./source/challenge.rds&quot;) read_rds(&quot;./source/challenge.rds&quot;) #&gt; # A tibble: 2,000 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;date&gt; #&gt; 1 404 NA #&gt; 2 4172 NA #&gt; 3 3004 NA #&gt; 4 787 NA #&gt; 5 37 NA #&gt; 6 2332 NA #&gt; 7 2489 NA #&gt; 8 1449 NA #&gt; 9 3665 NA #&gt; 10 3863 NA #&gt; # ... with 1,990 more rows 表现非常好，但 rds 格式不流行也不通用。 12.8.3 feather 格式 feather 包也实现了一种快速的二进制文件格式，可以跨编程语言共享： library(feather) #&gt; Warning: 程辑包&#39;feather&#39;是用R版本4.1.3 来建造的 write_feather(challenge, &quot;./source/challenge.feather&quot;) read_feather(&quot;./source/challenge.feather&quot;) #&gt; # A tibble: 2,000 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;date&gt; #&gt; 1 404 NA #&gt; 2 4172 NA #&gt; 3 3004 NA #&gt; 4 787 NA #&gt; 5 37 NA #&gt; 6 2332 NA #&gt; 7 2489 NA #&gt; 8 1449 NA #&gt; 9 3665 NA #&gt; 10 3863 NA #&gt; # ... with 1,990 more rows 12.8.4 其他格式 其他的一些常见格式也支持。事实上所有已知格式，在社区包的帮助下，通常都能解决。下面是一些常见格式： haven：读取 SPSS、Stata 和 SAS 文件。 readxl：读取 excel 文件（包括.xls和.xlsx）。 DBI：DBI 和一些特定数据库的后端（如 RMySQL、RSQLite、RPostgreSQL 等）。 "],["tidy-data.html", "Chapter 13 Tidy data 13.1 对 table1 数据分析 13.2 对 table2 数据整理 13.3 对 table3 数据整理 13.4 对 table4a &amp; table4b 数据整理 13.5 对 table5 数据整理 13.6 对 stocks 和 treatment 的缺失数据处理 13.7 对 who 数据整理", " Chapter 13 Tidy data 一个好的数据集应该：变量在列中，观察结果在行中，值储存在单元格中；不整洁的数据，我们可以用 tidyr 包中的 pivot_longer() 和 pivot_wider() 辅助修正 library(tidyverse) 13.1 对 table1 数据分析 table1 数据集中 cases 为增长人数（单位：万）。这份数据展现得很不错，我们可以轻松绘制想要的图像。 table1 #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 ggplot(table1, aes(year, cases)) + geom_line(aes(group = country, colour = country)) + geom_point(aes(colour = country)) 13.2 对 table2 数据整理 行中不应该出现将 cases 和 population 放在一起的现象。它们应该作为筛选变量，方便后续对 “新增” “目前总人数” 这个两个变量进行分析，即 type 拆分为列，count 跟随到新列： table2 #&gt; # A tibble: 12 x 4 #&gt; country year type count #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 cases 745 #&gt; 2 Afghanistan 1999 population 19987071 #&gt; 3 Afghanistan 2000 cases 2666 #&gt; 4 Afghanistan 2000 population 20595360 #&gt; 5 Brazil 1999 cases 37737 #&gt; 6 Brazil 1999 population 172006362 #&gt; 7 Brazil 2000 cases 80488 #&gt; 8 Brazil 2000 population 174504898 #&gt; 9 China 1999 cases 212258 #&gt; 10 China 1999 population 1272915272 #&gt; 11 China 2000 cases 213766 #&gt; 12 China 2000 population 1280428583 table2 %&gt;% pivot_wider(names_from = type, values_from = count) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 13.3 对 table3 数据整理 行中不应该出现将 cases 和 population 放在一起的现象，需要手动拆分： table3 #&gt; # A tibble: 6 x 3 #&gt; country year rate #&gt; * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745/19987071 #&gt; 2 Afghanistan 2000 2666/20595360 #&gt; 3 Brazil 1999 37737/172006362 #&gt; 4 Brazil 2000 80488/174504898 #&gt; 5 China 1999 212258/1272915272 #&gt; 6 China 2000 213766/1280428583 # 默认情况下，将在看到非字母数字字符（即不是数字或字母的字符）的位置拆分值 table3 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;)) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 # convert 可以自动将数据的格式进行转化。如这里的 cases 和 population 都应该是 int 类型数据 table3 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), convert = TRUE) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 # 分隔符也可以手动设置 table3 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 # 设置为数字表示分割位置，如这里分割为世纪 + 两位数年 table3 %&gt;% separate(year, into = c(&quot;century&quot;, &quot;year&quot;), sep = 2) #&gt; # A tibble: 6 x 4 #&gt; country century year rate #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 19 99 745/19987071 #&gt; 2 Afghanistan 20 00 2666/20595360 #&gt; 3 Brazil 19 99 37737/172006362 #&gt; 4 Brazil 20 00 80488/174504898 #&gt; 5 China 19 99 212258/1272915272 #&gt; 6 China 20 00 213766/1280428583 13.4 对 table4a &amp; table4b 数据整理 列中不应该出现将 1999 和 2000 分开的现象。它们应该作为筛选变量，方便后续对 “年份” 这个总变量进行分析，即旧变量合并为 year，值合并为 cases： table4a_new &lt;- table4a %&gt;% pivot_longer( c(`1999`, `2000`), # 指定修改列。注意这里变量是以数字开头，所以有必要用 `` 引用（当然数字开头是不规范的） names_to = &quot;year&quot;, # 上述变量名汇总到 year 上 values_to = &quot;cases&quot; # 上述对应数值汇总到 cases 上 ) table4b_new &lt;- table4b %&gt;% pivot_longer( c(`1999`, `2000`), names_to = &quot;year&quot;, values_to = &quot;population&quot; ) # 最后合并两个表的数据内容 #* dplyr::left_join() left_join(table4a_new, table4b_new) #&gt; Joining, by = c(&quot;country&quot;, &quot;year&quot;) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 13.5 对 table5 数据整理 我们需要手动拆分 cases 和 population 同时要将年份数据进行合并： table5 %&gt;% # 注意如果不声明 sep，默认加间隔符号 “_”！ unite(year_4cs, century, year, sep = &quot;&quot;, na.rm = TRUE) %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;) #&gt; # A tibble: 6 x 4 #&gt; country year_4cs cases population #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 13.6 对 stocks 和 treatment 的缺失数据处理 stocks &lt;- tibble( year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016), qtr = c(1, 2, 3, 4, 2, 3, 4), return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66) ) new_stocks &lt;- stocks %&gt;% # 拆分成按年作列 pivot_wider(names_from = year, values_from = return) %&gt;% # 重新整理回去。注意表格是怎么整理的 pivot_longer( cols = c(`2015`, `2016`), names_to = &quot;year&quot;, values_to = &quot;return&quot;, values_drop_na = TRUE # 这会对含 NA 的数据行剔除隐藏 ) %&gt;% print() #&gt; # A tibble: 6 x 3 #&gt; qtr year return #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 2015 1.88 #&gt; 2 2 2015 0.59 #&gt; 3 2 2016 0.92 #&gt; 4 3 2015 0.35 #&gt; 5 3 2016 0.17 #&gt; 6 4 2016 2.66 new_stocks %&gt;% complete(year, qtr) # 这会把所有隐藏的 NA 数据重新找回 #&gt; # A tibble: 8 x 3 #&gt; year qtr return #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2015 1 1.88 #&gt; 2 2015 2 0.59 #&gt; 3 2015 3 0.35 #&gt; 4 2015 4 NA #&gt; 5 2016 1 NA #&gt; 6 2016 2 0.92 #&gt; 7 2016 3 0.17 #&gt; 8 2016 4 2.66 treatment &lt;- tribble( ~person, ~treatment, ~response, &quot;Derrick Whitmore&quot;, 1, 7, NA, 2, 10, NA, 3, 9, &quot;Katherine Burke&quot;, 1, 4 ) treatment %&gt;% fill(person) # 对 treatment 的 person 列进行补全处理，碰到 NA 时会将 NA 改为上一个不是 NA 的数据 #&gt; # A tibble: 4 x 3 #&gt; person treatment response #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Derrick Whitmore 1 7 #&gt; 2 Derrick Whitmore 2 10 #&gt; 3 Derrick Whitmore 3 9 #&gt; 4 Katherine Burke 1 4 13.7 对 who 数据整理 who 是一个流行病统计数据集。 who #&gt; # A tibble: 7,240 x 60 #&gt; country iso2 iso3 year new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544 #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghani~ AF AFG 1980 NA NA NA NA #&gt; 2 Afghani~ AF AFG 1981 NA NA NA NA #&gt; 3 Afghani~ AF AFG 1982 NA NA NA NA #&gt; 4 Afghani~ AF AFG 1983 NA NA NA NA #&gt; 5 Afghani~ AF AFG 1984 NA NA NA NA #&gt; 6 Afghani~ AF AFG 1985 NA NA NA NA #&gt; 7 Afghani~ AF AFG 1986 NA NA NA NA #&gt; 8 Afghani~ AF AFG 1987 NA NA NA NA #&gt; 9 Afghani~ AF AFG 1988 NA NA NA NA #&gt; 10 Afghani~ AF AFG 1989 NA NA NA NA #&gt; # ... with 7,230 more rows, and 52 more variables: new_sp_m4554 &lt;int&gt;, #&gt; # new_sp_m5564 &lt;int&gt;, new_sp_m65 &lt;int&gt;, new_sp_f014 &lt;int&gt;, #&gt; # new_sp_f1524 &lt;int&gt;, new_sp_f2534 &lt;int&gt;, new_sp_f3544 &lt;int&gt;, #&gt; # new_sp_f4554 &lt;int&gt;, new_sp_f5564 &lt;int&gt;, new_sp_f65 &lt;int&gt;, #&gt; # new_sn_m014 &lt;int&gt;, new_sn_m1524 &lt;int&gt;, new_sn_m2534 &lt;int&gt;, #&gt; # new_sn_m3544 &lt;int&gt;, new_sn_m4554 &lt;int&gt;, new_sn_m5564 &lt;int&gt;, #&gt; # new_sn_m65 &lt;int&gt;, new_sn_f014 &lt;int&gt;, new_sn_f1524 &lt;int&gt;, ... who1 &lt;- who %&gt;% pivot_longer( cols = new_sp_m014:newrel_f65, # 将病症的种类转换成变量（key） names_to = &quot;key&quot;, values_to = &quot;cases&quot;, # 将数据转换成 cases 列 values_drop_na = TRUE # 删除 NA 数据 ) who1 #&gt; # A tibble: 76,046 x 6 #&gt; country iso2 iso3 year key cases #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 new_sp_m014 0 #&gt; 2 Afghanistan AF AFG 1997 new_sp_m1524 10 #&gt; 3 Afghanistan AF AFG 1997 new_sp_m2534 6 #&gt; 4 Afghanistan AF AFG 1997 new_sp_m3544 3 #&gt; 5 Afghanistan AF AFG 1997 new_sp_m4554 5 #&gt; 6 Afghanistan AF AFG 1997 new_sp_m5564 2 #&gt; 7 Afghanistan AF AFG 1997 new_sp_m65 0 #&gt; 8 Afghanistan AF AFG 1997 new_sp_f014 5 #&gt; 9 Afghanistan AF AFG 1997 new_sp_f1524 38 #&gt; 10 Afghanistan AF AFG 1997 new_sp_f2534 36 #&gt; # ... with 76,036 more rows count(who1, key, sort = TRUE) # 对不同病症人数统计 #&gt; # A tibble: 56 x 2 #&gt; key n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 new_sp_m4554 3223 #&gt; 2 new_sp_m3544 3219 #&gt; 3 new_sp_m5564 3218 #&gt; 4 new_sp_m1524 3209 #&gt; 5 new_sp_m65 3209 #&gt; 6 new_sp_m2534 3206 #&gt; 7 new_sp_f4554 3204 #&gt; 8 new_sp_f2534 3200 #&gt; 9 new_sp_f3544 3199 #&gt; 10 new_sp_f65 3197 #&gt; # ... with 46 more rows 对病症名称进行分析得知： 前三个字母：是否包含新的或旧的结核病例 中间两个字母：结核病的类型 rel：复发病例 ep：肺外结核病例 sn：无法通过肺涂片诊断的肺结核病例（涂片阴性） sp：可通过肺涂片诊断的肺结核病例（涂片阳性） 第六个字母：结核病患者的性别。其中 m 为男性，f 为女性 最后的数字：年龄组 014：0 ~ 14 岁 1524：15 ~ 24 岁 2534：25 ~ 34 岁 3544：35 ~ 44 岁 4554：45 ~ 54 岁 5564：55 ~ 64岁 65：65 岁或以上 who2 &lt;- who1 %&gt;% # 使用 stringr 的 str_replace 可以进行简单的替换（当然切割时使用位置切割也可以） mutate(key = stringr::str_replace(key, &quot;newrel&quot;, &quot;new_rel&quot;)) %&gt;% # 通过字符串 “_” 分割为是否包含新病例、结核病类型和性别年龄 separate(key, c(&quot;new&quot;, &quot;type&quot;, &quot;sexage&quot;), sep = &quot;_&quot;) %&gt;% # 通过位置继续分割性别和年龄 separate(sexage, c(&quot;sex&quot;, &quot;age&quot;), sep = 1) who2 #&gt; # A tibble: 76,046 x 9 #&gt; country iso2 iso3 year new type sex age cases #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 new sp m 014 0 #&gt; 2 Afghanistan AF AFG 1997 new sp m 1524 10 #&gt; 3 Afghanistan AF AFG 1997 new sp m 2534 6 #&gt; 4 Afghanistan AF AFG 1997 new sp m 3544 3 #&gt; 5 Afghanistan AF AFG 1997 new sp m 4554 5 #&gt; 6 Afghanistan AF AFG 1997 new sp m 5564 2 #&gt; 7 Afghanistan AF AFG 1997 new sp m 65 0 #&gt; 8 Afghanistan AF AFG 1997 new sp f 014 5 #&gt; 9 Afghanistan AF AFG 1997 new sp f 1524 38 #&gt; 10 Afghanistan AF AFG 1997 new sp f 2534 36 #&gt; # ... with 76,036 more rows 深度观察，我们会发现数据还有进一步的优化空间： count(who2, new) # 可以发现这个数据集的 “是否包含新病例” 值其实全部都是 “new”，所以是不必要的数据 #&gt; # A tibble: 1 x 2 #&gt; new n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 new 76046 # 同时 “iso2” 和 “iso3” 是国家缩写，也是不需要的数据 who3 &lt;- who2 %&gt;% select(-new, -iso2, -iso3) who3 #&gt; # A tibble: 76,046 x 6 #&gt; country year type sex age cases #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1997 sp m 014 0 #&gt; 2 Afghanistan 1997 sp m 1524 10 #&gt; 3 Afghanistan 1997 sp m 2534 6 #&gt; 4 Afghanistan 1997 sp m 3544 3 #&gt; 5 Afghanistan 1997 sp m 4554 5 #&gt; 6 Afghanistan 1997 sp m 5564 2 #&gt; 7 Afghanistan 1997 sp m 65 0 #&gt; 8 Afghanistan 1997 sp f 014 5 #&gt; 9 Afghanistan 1997 sp f 1524 38 #&gt; 10 Afghanistan 1997 sp f 2534 36 #&gt; # ... with 76,036 more rows "],["relational-data.html", "Chapter 14 Relational data 14.1 理解合并数据概念 14.2 理解多种数据合并方式 14.3 设置操作 14.4 合并 nycflights 数据并分析", " Chapter 14 Relational data 一对表格之间总是存在定义关系。要处理关系数据，我们需要与一对表一起工作的动词。有三家族动词设计用于处理关系数据： 突变连接，它从另一个数据帧的匹配观测中向一个数据帧添加新变量。 过滤连接，根据它们是否与另一个表中的观察结果匹配，从一个数据帧过滤观测结果。 集合操作，将观察视为集合元素。 library(tidyverse) library(nycflights13) 14.1 理解合并数据概念 14.1.1 类型1：没有重复问题 x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 3, &quot;x3&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 4, &quot;y3&quot; ) 内联（inner-join）：只观察共同包含的数据（交集）。事实上因为会丢掉不匹配的数据，所以不便于分析。 inner_join(x, y, by = &quot;key&quot;) #&gt; # A tibble: 2 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 外联（left-join、right-join、full-join）：共三种连接方式语句。 left_join(x, y, by = &quot;key&quot;) # 左连接，保留左侧丢掉右侧不匹配的数据 #&gt; # A tibble: 3 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 3 x3 &lt;NA&gt; right_join(x, y, by = &quot;key&quot;) # 右连接，保留右侧丢掉左侧不匹配的数据 #&gt; # A tibble: 3 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 4 &lt;NA&gt; y3 full_join(x, y, by = &quot;key&quot;) # 全连接，保留全部数据，哪怕不互相匹配 #&gt; # A tibble: 4 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 3 x3 &lt;NA&gt; #&gt; 4 4 &lt;NA&gt; y3 匹配演算（semi_join、anti_join）：事实上匹配并不会做数据合并，只是把左侧数据做筛选。 semi_join(x, y, by = &quot;key&quot;) # 半连接，对左侧数据筛选出右侧数据能匹配的数据 #&gt; # A tibble: 2 x 2 #&gt; key val_x #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 x1 #&gt; 2 2 x2 anti_join(x, y, by = &quot;key&quot;) # 反连接，对左侧数据排除掉右侧数据能匹配的数据 #&gt; # A tibble: 1 x 2 #&gt; key val_x #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 3 x3 14.1.2 类型2：一边有重复问题 x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 2, &quot;x3&quot;, 1, &quot;x4&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot; ) 事实上下面两种模式结果相同： left_join(x, y, by = &quot;key&quot;) # 左边所有列都从右边寻求 #&gt; # A tibble: 4 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 2 x3 y2 #&gt; 4 1 x4 y1 right_join(x, y, by = &quot;key&quot;) # 右边所有列都从左边寻求（一对多时全保留） #&gt; # A tibble: 4 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 2 x3 y2 #&gt; 4 1 x4 y1 14.1.3 类型3：两边都有重复问题 x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 2, &quot;x3&quot;, 3, &quot;x4&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 2, &quot;y3&quot;, 3, &quot;y4&quot; ) 左边某列对应到右边出现多个结果时会新增列去对应： left_join(x, y, by = &quot;key&quot;) #&gt; # A tibble: 6 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 2 x2 y3 #&gt; 4 2 x3 y2 #&gt; 5 2 x3 y3 #&gt; 6 3 x4 y4 14.2 理解多种数据合并方式 事实上，四大 join 相关依赖包 dplyr，我们也可以用 r 原生自带的 base::merge 实现： dplyr 语句 对应的 merge 语句 解释 inner_join(x, y) merge(x, y) 匹配不上的均不保留 left_join(x, y) merge(x, y, all.x = TRUE) 保留所有的 x right_join(x, y) merge(x, y, all.y = TRUE), 保留所有的 y full_join(x, y) merge(x, y, all.x = TRUE, all.y = TRUE) 保留所有的 x 和 y 14.3 设置操作 intersect、union 和 setdiff 用于对不同表格的差异进行挖掘： df1 &lt;- tribble( ~x, ~y, 1, 1, 2, 1 ) df2 &lt;- tribble( ~x, ~y, 1, 1, 1, 2 ) intersect(df1, df2) # 返回两者共同的数据集 #&gt; # A tibble: 1 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 union(df1, df2) # 合并两个数据集的数据（相同的只做一次记录） #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 #&gt; 2 2 1 #&gt; 3 1 2 setdiff(df1, df2) # 返回前者观察到的后者所没有的差异部分 #&gt; # A tibble: 1 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 1 setdiff(df2, df1) #&gt; # A tibble: 1 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2 14.4 合并 nycflights 数据并分析 仔细观察 nycflights 不难发现，里面包含 airlines、airports、planes 和 weather，以及我们常用的 flights 数据集。 airlines 允许您从其缩写代码中查找完整的运营商名称： airlines #&gt; # A tibble: 16 x 2 #&gt; carrier name #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 9E Endeavor Air Inc. #&gt; 2 AA American Airlines Inc. #&gt; 3 AS Alaska Airlines Inc. #&gt; 4 B6 JetBlue Airways #&gt; 5 DL Delta Air Lines Inc. #&gt; 6 EV ExpressJet Airlines Inc. #&gt; 7 F9 Frontier Airlines Inc. #&gt; 8 FL AirTran Airways Corporation #&gt; 9 HA Hawaiian Airlines Inc. #&gt; 10 MQ Envoy Air #&gt; 11 OO SkyWest Airlines Inc. #&gt; 12 UA United Air Lines Inc. #&gt; 13 US US Airways Inc. #&gt; 14 VX Virgin America #&gt; 15 WN Southwest Airlines Co. #&gt; 16 YV Mesa Airlines Inc. airports 提供有关每个机场的信息，由 faa 机场代码标识： airports #&gt; # A tibble: 1,458 x 8 #&gt; faa name lat lon alt tz dst tzone #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 04G Lansdowne Airport 41.1 -80.6 1044 -5 A America/~ #&gt; 2 06A Moton Field Municipal Airport 32.5 -85.7 264 -6 A America/~ #&gt; 3 06C Schaumburg Regional 42.0 -88.1 801 -6 A America/~ #&gt; 4 06N Randall Airport 41.4 -74.4 523 -5 A America/~ #&gt; 5 09J Jekyll Island Airport 31.1 -81.4 11 -5 A America/~ #&gt; 6 0A9 Elizabethton Municipal Airport 36.4 -82.2 1593 -5 A America/~ #&gt; 7 0G6 Williams County Airport 41.5 -84.5 730 -5 A America/~ #&gt; 8 0G7 Finger Lakes Regional Airport 42.9 -76.8 492 -5 A America/~ #&gt; 9 0P2 Shoestring Aviation Airfield 39.8 -76.6 1000 -5 U America/~ #&gt; 10 0S9 Jefferson County Intl 48.1 -123. 108 -8 A America/~ #&gt; # ... with 1,448 more rows planes 提供有关每个平面的信息，由其 tailnum 标识： planes #&gt; # A tibble: 3,322 x 9 #&gt; tailnum year type manufacturer model engines seats speed engine #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 N10156 2004 Fixed wing multi~ EMBRAER EMB-~ 2 55 NA Turbo~ #&gt; 2 N102UW 1998 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 3 N103US 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 4 N104UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 5 N10575 2002 Fixed wing multi~ EMBRAER EMB-~ 2 55 NA Turbo~ #&gt; 6 N105UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 7 N107US 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 8 N108UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 9 N109UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 10 N110UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; # ... with 3,312 more rows weather 则给出了每个纽约机场每小时的天气： weather #&gt; # A tibble: 26,115 x 15 #&gt; origin year month day hour temp dewp humid wind_dir wind_speed #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 EWR 2013 1 1 1 39.0 26.1 59.4 270 10.4 #&gt; 2 EWR 2013 1 1 2 39.0 27.0 61.6 250 8.06 #&gt; 3 EWR 2013 1 1 3 39.0 28.0 64.4 240 11.5 #&gt; 4 EWR 2013 1 1 4 39.9 28.0 62.2 250 12.7 #&gt; 5 EWR 2013 1 1 5 39.0 28.0 64.4 260 12.7 #&gt; 6 EWR 2013 1 1 6 37.9 28.0 67.2 240 11.5 #&gt; 7 EWR 2013 1 1 7 39.0 28.0 64.4 240 15.0 #&gt; 8 EWR 2013 1 1 8 39.9 28.0 62.2 250 10.4 #&gt; 9 EWR 2013 1 1 9 39.9 28.0 62.2 260 15.0 #&gt; 10 EWR 2013 1 1 10 41 28.0 59.6 260 13.8 #&gt; # ... with 26,105 more rows, and 5 more variables: wind_gust &lt;dbl&gt;, #&gt; # precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;, time_hour &lt;dttm&gt; 它们的关系图如下： relational-nycflights 我们首先对数据集进行精简： flights_smaller &lt;- flights %&gt;% select(year:day, hour, origin, dest, tailnum, carrier) 由于 carrier 没有补全，所以我们决定联合 airlines 数据集进行选择性合并： flights_smaller %&gt;% select(-c(origin, dest)) %&gt;% # 根据别的数据集在右侧补全数据，依据 / 重叠数据为 carrier left_join(airlines, by = &quot;carrier&quot;) #&gt; # A tibble: 336,776 x 7 #&gt; year month day hour tailnum carrier name #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 2013 1 1 5 N14228 UA United Air Lines Inc. #&gt; 2 2013 1 1 5 N24211 UA United Air Lines Inc. #&gt; 3 2013 1 1 5 N619AA AA American Airlines Inc. #&gt; 4 2013 1 1 5 N804JB B6 JetBlue Airways #&gt; 5 2013 1 1 6 N668DN DL Delta Air Lines Inc. #&gt; 6 2013 1 1 5 N39463 UA United Air Lines Inc. #&gt; 7 2013 1 1 6 N516JB B6 JetBlue Airways #&gt; 8 2013 1 1 6 N829AS EV ExpressJet Airlines Inc. #&gt; 9 2013 1 1 6 N593JB B6 JetBlue Airways #&gt; 10 2013 1 1 6 N3ALAA AA American Airlines Inc. #&gt; # ... with 336,766 more rows 当然我们也可以使用 mutate + match 实现同样效果： flights_smaller %&gt;% select(-c(origin, dest)) %&gt;% mutate( # 从 airlines 的 name 向量获取数据，赋值到新列 “name” name = airlines$name[match( # 获取的数据通过 match 控制 # 通过 filghts 的 carrier 匹配数据，返回对应 airlines 的 carrier carrier, airlines$carrier )] ) #&gt; # A tibble: 336,776 x 7 #&gt; year month day hour tailnum carrier name #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 2013 1 1 5 N14228 UA United Air Lines Inc. #&gt; 2 2013 1 1 5 N24211 UA United Air Lines Inc. #&gt; 3 2013 1 1 5 N619AA AA American Airlines Inc. #&gt; 4 2013 1 1 5 N804JB B6 JetBlue Airways #&gt; 5 2013 1 1 6 N668DN DL Delta Air Lines Inc. #&gt; 6 2013 1 1 5 N39463 UA United Air Lines Inc. #&gt; 7 2013 1 1 6 N516JB B6 JetBlue Airways #&gt; 8 2013 1 1 6 N829AS EV ExpressJet Airlines Inc. #&gt; 9 2013 1 1 6 N593JB B6 JetBlue Airways #&gt; 10 2013 1 1 6 N3ALAA AA American Airlines Inc. #&gt; # ... with 336,766 more rows 而如果要与 weather 并接： flights_smaller %&gt;% left_join(weather) # 如果不写 by，则为默认 NULL，会将左边所有列往右边对应一遍，相当于下面代码： #&gt; Joining, by = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;) #&gt; # A tibble: 336,776 x 18 #&gt; year month day hour origin dest tailnum carrier temp dewp humid #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 5 EWR IAH N14228 UA 39.0 28.0 64.4 #&gt; 2 2013 1 1 5 LGA IAH N24211 UA 39.9 25.0 54.8 #&gt; 3 2013 1 1 5 JFK MIA N619AA AA 39.0 27.0 61.6 #&gt; 4 2013 1 1 5 JFK BQN N804JB B6 39.0 27.0 61.6 #&gt; 5 2013 1 1 6 LGA ATL N668DN DL 39.9 25.0 54.8 #&gt; 6 2013 1 1 5 EWR ORD N39463 UA 39.0 28.0 64.4 #&gt; 7 2013 1 1 6 EWR FLL N516JB B6 37.9 28.0 67.2 #&gt; 8 2013 1 1 6 LGA IAD N829AS EV 39.9 25.0 54.8 #&gt; 9 2013 1 1 6 JFK MCO N593JB B6 37.9 27.0 64.3 #&gt; 10 2013 1 1 6 LGA ORD N3ALAA AA 39.9 25.0 54.8 #&gt; # ... with 336,766 more rows, and 7 more variables: wind_dir &lt;dbl&gt;, #&gt; # wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, pressure &lt;dbl&gt;, #&gt; # visib &lt;dbl&gt;, time_hour &lt;dttm&gt; # left_join(weather, by = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;)) 事实上 “by =” 可以省略。如果筛选变量填入了用等于连接的向量，则是左右都指定了列： flights_smaller %&gt;% # flighs_smaller 的 dest 列与 airports 的 faa 列比较、对应和连接 left_join(airports, c(&quot;dest&quot; = &quot;faa&quot;)) #&gt; # A tibble: 336,776 x 15 #&gt; year month day hour origin dest tailnum carrier name lat lon alt #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 5 EWR IAH N14228 UA Georg~ 30.0 -95.3 97 #&gt; 2 2013 1 1 5 LGA IAH N24211 UA Georg~ 30.0 -95.3 97 #&gt; 3 2013 1 1 5 JFK MIA N619AA AA Miami~ 25.8 -80.3 8 #&gt; 4 2013 1 1 5 JFK BQN N804JB B6 &lt;NA&gt; NA NA NA #&gt; 5 2013 1 1 6 LGA ATL N668DN DL Harts~ 33.6 -84.4 1026 #&gt; 6 2013 1 1 5 EWR ORD N39463 UA Chica~ 42.0 -87.9 668 #&gt; 7 2013 1 1 6 EWR FLL N516JB B6 Fort ~ 26.1 -80.2 9 #&gt; 8 2013 1 1 6 LGA IAD N829AS EV Washi~ 38.9 -77.5 313 #&gt; 9 2013 1 1 6 JFK MCO N593JB B6 Orlan~ 28.4 -81.3 96 #&gt; 10 2013 1 1 6 LGA ORD N3ALAA AA Chica~ 42.0 -87.9 668 #&gt; # ... with 336,766 more rows, and 3 more variables: tz &lt;dbl&gt;, dst &lt;chr&gt;, #&gt; # tzone &lt;chr&gt; 分析绘图机场在美国的分布图和到达此处的飞机的延误整体状况： avg_dest_delays &lt;- flights %&gt;% group_by(dest) %&gt;% # 新的列 delay 取值为各目的地的 arr_delay（到达延误）的平均值 summarise(delay = mean(arr_delay, na.rm = TRUE)) %&gt;% # 注意可能存在 NA 值，需要剔除 # 注意向量内左侧数据其实打不打引号都是可以的，但右侧必须打 inner_join(airports, by = c(dest = &quot;faa&quot;)) # 其中 faa 为机场代码 avg_dest_delays #&gt; # A tibble: 101 x 9 #&gt; dest delay name lat lon alt tz dst tzone #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 ABQ 4.38 Albuquerque International S~ 35.0 -107. 5355 -7 A Amer~ #&gt; 2 ACK 4.85 Nantucket Mem 41.3 -70.1 48 -5 A Amer~ #&gt; 3 ALB 14.4 Albany Intl 42.7 -73.8 285 -5 A Amer~ #&gt; 4 ANC -2.5 Ted Stevens Anchorage Intl 61.2 -150. 152 -9 A Amer~ #&gt; 5 ATL 11.3 Hartsfield Jackson Atlanta ~ 33.6 -84.4 1026 -5 A Amer~ #&gt; 6 AUS 6.02 Austin Bergstrom Intl 30.2 -97.7 542 -6 A Amer~ #&gt; 7 AVL 8.00 Asheville Regional Airport 35.4 -82.5 2165 -5 A Amer~ #&gt; 8 BDL 7.05 Bradley Intl 41.9 -72.7 173 -5 A Amer~ #&gt; 9 BGR 8.03 Bangor Intl 44.8 -68.8 192 -5 A Amer~ #&gt; 10 BHM 16.9 Birmingham Intl 33.6 -86.8 644 -6 A Amer~ #&gt; # ... with 91 more rows avg_dest_delays %&gt;% # lat 和 lon 为机场的经度和纬度信息，颜色代表平均延迟时长 ggplot(mapping = aes(lon, lat, colour = delay)) + borders(&quot;state&quot;) + # 这一句话是在加入美国地图背板 geom_point() + # 显示机场位置分布 coord_quickmap() # 保持地图横纵比，防止实际图片拉伸导致的地图变形 分析合并出发地的延误状况： airport_locations &lt;- airports %&gt;% select(faa, lat, lon) flights %&gt;% select(year:day, hour, origin, dest) %&gt;% # 注意这样 origin 和 dest 都由对应的经纬度坐标数据，存在命名冲突 # 实际运行时，运行到下面的 left_join 会发现，dplyr 会自动给旧列名加上 “.x”，新列名 “.y” # left_join( # airport_locations, # by = c(&quot;dest&quot; = &quot;faa&quot;) # ) # 所以我们使用 suffix 覆盖这个默认行为设置的后缀 left_join( airport_locations, by = c(&quot;dest&quot; = &quot;faa&quot;), suffix = c(&quot;_origin&quot;, &quot;_dest&quot;) ) #&gt; # A tibble: 336,776 x 8 #&gt; year month day hour origin dest lat lon #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 5 EWR IAH 30.0 -95.3 #&gt; 2 2013 1 1 5 LGA IAH 30.0 -95.3 #&gt; 3 2013 1 1 5 JFK MIA 25.8 -80.3 #&gt; 4 2013 1 1 5 JFK BQN NA NA #&gt; 5 2013 1 1 6 LGA ATL 33.6 -84.4 #&gt; 6 2013 1 1 5 EWR ORD 42.0 -87.9 #&gt; 7 2013 1 1 6 EWR FLL 26.1 -80.2 #&gt; 8 2013 1 1 6 LGA IAD 38.9 -77.5 #&gt; 9 2013 1 1 6 JFK MCO 28.4 -81.3 #&gt; 10 2013 1 1 6 LGA ORD 42.0 -87.9 #&gt; # ... with 336,766 more rows "],["model-intro.html", "Chapter 15 Introduction 15.1 认知", " Chapter 15 Introduction 现在我们已经配备了强大的编程工具，终于可以回到建模了。 data-science-model 模型的目标是提供数据集的简单低维摘要。理想情况下，该模型将捕获真正的 “信号”（即由感兴趣现象产生的模式），并忽略 “噪声”（即我们不感兴趣的随机变化）。 在模型基础知识中，我们将了解模型如何工作，重点介绍重要的线性模型系列。 在模型构建中，我们将学习如何使用模型在实际数据中提取已知模式。 在许多模型中，我们将学习如何使用许多简单模型来帮助理解复杂的数据集。注意学习时多加结合建模和编程工具。 15.1 认知 传统的来说，建模的重点是推理，或确认假设是正确的。因此我们需要形成两个必要的观念： 每个观测值既可以用于探索，也可以用于确认，而不能两者兼而有之。 我们可以根据需要多次使用观测值进行探索，但只能使用一次进行确认。一旦使用观察结果两次，我们就算已经从确认切换到了探索。 "],["404.html", "404 Not Found", " 404 Not Found 找不到您要找的页面（可能被移动或重命名）。 您可能需要尝试使用搜索功能查找页面的新位置，或使用内容表查找所需的页面。 "]]
