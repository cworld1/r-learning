[["index.html", "R-Learning Chapter 1 Welcome 1.1 项目介绍 1.2 项目运行 1.3 贡献 1.4 鸣谢 1.5 License", " R-Learning CWorld 2022-06-03 Chapter 1 Welcome 这是关于 CWorld 学习 R 语言的一些笔记和代码。目前已开源：Github R-Learning 1.1 项目介绍 本项目使用 bookdown 构建，包含 gitbook、epub_book 和 pdf_book 三种构建成品。 实际学习上，我们更推荐将项目打包下载，或使用 git clone 到本地方便随时运行它们的任意一部分，而不是反复使用复制和粘贴。本笔记的 R 笔记源码针对大纲进行了优化，使用支持更友好的编辑器，很大程度上方便读者理清节点关系与数据生成始末。这里推荐使用 RStudio 或 Visual Studio Code，但理论上应该也有让你阅读更愉快的编辑器，在此不做敷述。 1.2 项目运行 首先请保证自己已经有了 R 本地环境，并把 RScript 加入了全局变量。 安装运行代码需要的包： Rscript -e &#39;install.packages(c(&quot;tidyverse&quot;, &quot;nycflights13&quot;, &quot;hexbin&quot;, &quot;gapminder&quot;, &quot;Lahman&quot;, &quot;maps&quot;, &quot;feather&quot;))&#39; 安装构建本书需要的包（如果你需要的话）： Rscript -e &#39;install.packages(c(&quot;markdownr&quot;, &quot;bookdown&quot;))&#39; Rscript -e &#39;tinytex::install_tinytex()&#39; 开始构建（如果你需要的话）： set -ev cd book Rscript -e &quot;bookdown::render_book(&#39;index.Rmd&#39;, &#39;bookdown::gitbook&#39;)&quot; 1.3 贡献 由于作者只是个正在浅学 R 的初学者，所以笔记难免存在明显纰漏，还请读者们多多海涵。此外，也欢迎诸位使用 PR 或 Issues 来改善它们。 1.4 鸣谢 一些电子教材对作者学习上帮助颇多，在此对这些教材的原作者深表感谢。读者若对此项目的笔记抱有疑惑，也可以仔细阅读以下的教材以作弥补。 R for Data Science R for Data Science: Exercise Solutions Modern Data Science with R 1.5 License The MIT License. "],["introduction.html", "Chapter 2 Introduction 2.1 数据科学 2.2 一些准备 2.3 更多学习途径 2.4 初识 R", " Chapter 2 Introduction 2.1 数据科学 data-science.png 首先我们需要导入数据。然后对其进行整理。理解数据的核心就是转换、可视化数据和建立模型。通信是最后的步骤，理解的数据最终很可能走向分享他人。 2.2 一些准备 2.2.1 安装 R 要下载 R，需要前往 CRAN，即 cromprehensive R archive network。CRAN 由分布在世界各地的一组镜像服务器组成，用于分发 R 和 R 的拓展包。不要试图选择看起来地点离你很近的镜像，而是使用 云镜像，它会自动为你找出答案。 2.2.2 安装编辑器 RStudio 是一个用于 R 编程的集成开发环境或 IDE。从 http://www.rstudio.com/download 下载并安装它。 2.2.3 相关包 我们可以使用一行代码安装完整的 tidyverse： install.packages(&quot;tidyverse&quot;) 在我们自己的计算机上，在控制台中键入该行代码，然后按 Enter 运行它。R 将从 CRAN 下载软件包并将其安装到我们的计算机上。如果我们在安装时遇到问题，请确保我们已连接到互联网，并且 https://cloud.r-project.org/ 未被防火墙或代理阻止。 在本项目笔记中，我们将使用来自 tidyverse 之外的三个数据包： install.packages(c(&quot;nycflights13&quot;, &quot;gapminder&quot;, &quot;Lahman&quot;)) 这些软件包提供了有关航空公司航班、世界发展和棒球的数据，我们将用这些数据来说明关键的数据科学理念。 2.3 更多学习途径 R for Data Science R for Data Science: Exercise Solutions 2.4 初识 R 我们就从 HelloWorld 开始吧： print(&quot;hello world!&quot;) ## [1] &quot;hello world!&quot; R 里有一些约定俗成的代码形式。如： # 函数后面带括号 sum(c(1, 2)) # 对象直接书写 iris # 不加载包直接调用 dplyr::mutate(iris) # mutate() 函数 nycflights13::flights # flights 数据集 一些基础功能后面可能不会再反复提到，但它们通常很有用： library(tidyverse) # 加载之前安装的包 tidyverse_update() # 更新 tidyverse 包内的附带包 dput(mtcars) # 查看数据集（如 mtcars）的更多信息 sessionInfo(c(&quot;tidyverse&quot;)) # 查看本地 R 及相关信息 "],["explore-intro.html", "Chapter 3 Introduction 3.1 基本数据形式和函数 3.2 学习 R 自带的画图功能 3.3 更高级的数据形式", " Chapter 3 Introduction 尽快掌握数据探索的基本工具是探究语言的第一要义。数据探索的目标是生成许多有前途的潜在信息，便于以后更深入地探索它们。 data-science-explore 可视化是 R 编程的重要部分：制作优雅且信息丰富的绘图，以帮助理解数据。学习 ggplot2 绘图的基本结构，将数据转换为绘图。 在数据转换中，使用关键谓词允许我们选择重要变量、筛选出关键观察结果、创建新变量和计算摘要。 建模是探索过程的重要组成部分，但这并不是当下能够弄清的，它会在以后的学习中逐渐深入。 在工作流中：“基础知识”、“工作流：脚本” 和 “工作流：项目”，你将学习编写和组织 R 代码的良好实践。 以下为附加内容，因为已知资料上貌似没有提到。 3.1 基本数据形式和函数 3.1.1 向量、矩阵与列表 创建已知或未知的空向量用于存储一系列数据（如整数、小数、字符串）。 x &lt;- vector() # 创建空向量 y &lt;- c(1, 2) # 手动赋值 # 在 R 中，我们可以使用 “:” 来创建序列填充 z &lt;- c(1:3) # 这里其实等价于 1, 2, 3 矩阵有点像我们学的表格，这种数据结构很类似于其它语言中的二维数组。注意使用 t() 可以行列互换。 Matrix_transpose rownames &lt;- c(&quot;row1&quot;, &quot;row2&quot;, &quot;row3&quot;, &quot;row4&quot;) colnames &lt;- c(&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;) m &lt;- matrix( data = c(3:14), # nrow = 4, # 设置行数。如果不知道数据有多少其实可以不设置 ncol = 3, # 设置列宽 byrow = TRUE, # 设置为 TRUE 即按行排列，反之则按列排 dimnames = list(rownames, colnames) # 设置行和列的标题，默认为 NULL ) m ## col1 col2 col3 ## row1 3 4 5 ## row2 6 7 8 ## row3 9 10 11 ## row4 12 13 14 t(m) ## row1 row2 row3 row4 ## col1 3 6 9 12 ## col2 4 7 10 13 ## col3 5 8 11 14 列表使用 list() 创建。一个列表里可以随意放置向量里能放置的所有元素，甚至是一个向量、一个矩阵。 list_data &lt;- list( &quot;google&quot;, matrix(c(1, 2, 3, 4, 5, 6), nrow = 2), 123.1, c(1:5) ) # 读取元素 list_data[[1]] # 注意中括号应该用两层来获取对应元素。但如果只用一层，R 会自动识别并修正 names(list_data) &lt;- c(&quot;Sites&quot;, &quot;Numbers&quot;, &quot;Lists&quot;) # 使用 names() 来赋值名称 list_data$Sites # 有名称后可以用 $xx 来读取对应的列元素 # 添加 / 更新元素 list_data[5] &lt;- &quot;新元素&quot; # 删除元素 list_data[4] &lt;- NULL # 合并 / 转换列表 num_list &lt;- list(1, 2) merged_list &lt;- c(num_list, list_data) # 合并 unlist(num_list) # 转换列表为向量 3.1.2 基本函数 数据集如下： age &lt;- c(10, 12, 14, 6, 8, 18) weight &lt;- c(100, 110, 120, 80, 90, 140) 数学中一些常用的计算函数 5 %% 3 # 求余数 ## [1] 2 5 %/% 3 # 求模 ## [1] 1 mean(age) # 求平均值 ## [1] 11.33333 sd(age) # 求标准差 ## [1] 4.320494 cor(age, weight) # 求相关度，数值在 -1 到 1，其中 1 是绝对正相关，0 是完全不相关，-1 是绝对负相关 ## [1] 1 lm(age ~ weight) # 求两者构成的回归直线斜率（注意波浪号连接） ## ## Call: ## lm(formula = age ~ weight) ## ## Coefficients: ## (Intercept) weight ## -10.0 0.2 3.2 学习 R 自带的画图功能 在 R 里画图非常简单。以上面的 age 和 weight 为例： # 注意在 R 里面，相对路径的基层路径是由工作区设定的 getwd() # 获取当前工作区路径 setwd(&quot;D:/Project/R-Project/&quot;) # 设置工作区路径 png(&quot;./data/mygraph.png&quot;) # 设置好后就可以存储到理想位置 plot(age, weight) # 绘制散点图 abline(lm(age ~ weight)) # 绘制回归直线 title(&quot;年龄 - 体重图&quot;) # 添加 # 添加 # 添加标题 dev.off() # 结束画图并保存 实际运行生成的图： mygraph 3.3 更高级的数据形式 dataframe 是一系列向量数据的集合： data.frame( a = c(1:3), b = c(6:8) ) ## a b ## 1 1 6 ## 2 2 7 ## 3 3 8 tibble 与 dataframe 非常相似，甚至是使用 dataframe 储存的。tibble 是 tidyverse 系列的专用数据集格式。它的优点是干净、方便数据处理。 library(tidyverse) ## -- Attaching packages ------------------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.6 v dplyr 1.0.8 ## v tidyr 1.2.0 v stringr 1.4.0 ## v readr 2.1.2 v forcats 0.5.1 ## -- Conflicts ---------------------------------------------------- tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() # 你可以跟 data.frame 一样直接加入数组： tibble( sex = c(&quot;male&quot;, &quot;female&quot;, &quot;male&quot;), response = c(1, 2, 1) ) ## # A tibble: 3 x 2 ## sex response ## &lt;chr&gt; &lt;dbl&gt; ## 1 male 1 ## 2 female 2 ## 3 male 1 # 也可以像是正常书写表格那样！ tribble( ~sex, ~response, &quot;male&quot;, 1, &quot;female&quot;, 2, &quot;male&quot;, 1 ) ## # A tibble: 3 x 2 ## sex response ## &lt;chr&gt; &lt;dbl&gt; ## 1 male 1 ## 2 female 2 ## 3 male 1 "],["explore.html", "Chapter 4 Data visualisation 4.1 初识 ggplot 4.2 美学映射 4.3 修改样式 4.4 多组画图 4.5 叠加与参数 4.6 其他常见图 4.7 坐标系相关 4.8 绘制 diamonds 数据分析图 4.9 研究 mpgcars 数据集", " Chapter 4 Data visualisation library(tidyverse) # 方便使用其中的 ggplot2 4.1 初识 ggplot view(mpg) # 使用 view() 函数可以方便观察对应数据集 head(mpg) # 可以在控制台打印数据集头部信息（前十行） ## # A tibble: 6 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compa~ ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compa~ ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compa~ ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compa~ ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compa~ ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compa~ 列 displ：汽车的发动机尺寸，以升为单位。 列 hwy：汽车在高速公路上的燃油效率，以英里 / 加仑（mpg）为单位 ggplot(data = mpg) + # 统一设置想要处理的数据集 # 绘制 point，mapping 属性用来设置相关的 x 轴和 y 轴参数 geom_point(mapping = aes(x = displ, y = hwy)) 4.2 美学映射 使用颜色映射： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class)) 使用大小映射（不建议）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, size = class)) ## Warning: Using size for a discrete variable is not advised. 使用形状映射（注意最多只支持 6 种）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, shape = class)) ## Warning: The shape palette can deal with a maximum of 6 discrete values because ## more than 6 becomes difficult to discriminate; you have 7. Consider ## specifying shapes manually if you must have them. ## Warning: Removed 62 rows containing missing values (geom_point). 使用透明度映射（不建议）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, alpha = class)) ## Warning: Using alpha for a discrete variable is not advised. 4.3 修改样式 例如颜色： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;) 支持参数：color，shape，fill，stroke（点的粗细），linetype 等。同时，样式参数支持变量。注意 shape 填写时是填写数字，有 21 种。 R 有 25 个内置形状，这些形状由数字标识。有一些看似重复的：例如，0、15 和 22 都是正方形。不同之处在于“颜色”和“填充”美学的相互作用。空心形状（0–14）具有由“颜色”确定的边框;固体形状（15–20）填充有“颜色”;填充的形状（21–24）具有“颜色”边框，并用“填充”填充填充。 4.4 多组画图 简单分组（分片）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~class, nrow = 3) # 以 class 分类，三列，不限制行 自定义条件分组： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ cyl) # 以 drv 为 x 轴，cyl 为 y 轴 4.5 叠加与参数 mapping 为默认接收内容，可以省略： ggplot(data = mpg) + geom_point(aes(x = displ, y = hwy)) + geom_smooth(aes(x = displ, y = hwy)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 其中 mapping 写在基本配置项中，方便绘图自动调用 ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 绘图时使用自定义 data 覆盖默认 data 配置（filter 为筛选数据）： ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(color = &quot;blue&quot;) + geom_smooth(data = filter(mpg, class == &quot;subcompact&quot;)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 4.6 其他常见图 4.6.1 回归曲线图 回归曲线有它专门的配置项，其中 show legend 用于控制现实图例显示与否，se 控制自信指数（半透明带）显示与否： ggplot(data = mpg) + geom_smooth( mapping = aes(x = displ, y = hwy, color = drv), show.legend = FALSE, se = FALSE ) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 4.6.2 条形图 ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, colour = cut)) # colour 为描边颜色 ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = cut)) # fill 为填充颜色 但如果 fill 使用的是其他变量，会导致不同数据重叠遮挡 ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) 解决方案 1：降低透明度 ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + geom_bar(alpha = 1 / 5, position = &quot;identity&quot;) 解决方案 2：直接改为 colour 样式，并将 fill 设置为 NA ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + geom_bar(fill = NA, position = &quot;identity&quot;) 解决方案 3：position 改用 fill 为频率图（方便观察比例） ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + geom_bar(position = &quot;fill&quot;) 解决方案 4：position 改用 dodge 为分柱图 ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + geom_bar(position = &quot;dodge&quot;) 4.6.3 Summary 线条信息图 这种图不太常用，因为 boxplot 图拥有它的所有特性，甚至做得更好： ggplot(data = diamonds) + stat_summary( mapping = aes(x = cut, y = depth), fun.max = max, # 上限最大值 fun.min = min, # 下限为最小值 fun.y = mean # 标点为平均数 ) ## Warning: `fun.y` is deprecated. Use `fun` instead. 4.7 坐标系相关 对调坐标轴： ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() + coord_flip() 根据相关图像限制图形的纵横比例： nz &lt;- map_data(&quot;nz&quot;) # 从 map_data 里调用某国的地图 ggplot(nz, aes(long, lat, group = group)) + geom_polygon(fill = &quot;white&quot;, colour = &quot;black&quot;) + coord_quickmap() # 这里会使图表以正确的横纵比显示，防止图像拉伸扭曲 极坐标化： ggplot(data = diamonds) + geom_bar( mapping = aes(x = cut, fill = cut), show.legend = FALSE, # 隐藏图例，原因是 x 轴默认已经带指示了 width = 1 ) + coord_polar() # 设置为极坐标（有点像圆饼图） 4.8 绘制 diamonds 数据分析图 原题目：Recreate the R code necessary to generate the following graphs. 建立列表，绘制好 6 张图并装配进去： p &lt;- list() p[[1]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_point() + geom_smooth(se = FALSE) # 注意包含回归曲线 p[[2]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_smooth(mapping = aes(group = drv), se = FALSE) + # 以 drv 分组作出多条回归线 geom_point() p[[3]] &lt;- ggplot(mpg, aes(x = displ, y = hwy, colour = drv)) + # 全局以 drv 分类添加着色 geom_point() + geom_smooth(se = FALSE) p[[4]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = drv)) + geom_smooth(se = FALSE) # 如果只要总的回归线，就不要把 colour 变量对 smooth 进行应用 p[[5]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(aes(colour = drv)) + geom_smooth(aes(linetype = drv), se = FALSE) # 与以颜色分组类似，这里只是改用线条样式 p[[6]] &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + geom_point(size = 4, color = &quot;white&quot;) + geom_point(aes(colour = drv)) # 这里是两幅非常相似的图重叠的效果。注意后画的图优先显示 随即使用布局逐张展示： library(grid) # 引用一下布局包 grid.newpage() # 新建布局包 pushViewport(viewport(layout = grid.layout(3, 2))) # 设置 2x3 布局 print(p[[1]], vp = viewport(layout.pos.row = 1, layout.pos.col = 1)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[2]], vp = viewport(layout.pos.row = 1, layout.pos.col = 2)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[3]], vp = viewport(layout.pos.row = 2, layout.pos.col = 1)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[4]], vp = viewport(layout.pos.row = 2, layout.pos.col = 2)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[5]], vp = viewport(layout.pos.row = 3, layout.pos.col = 1)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; print(p[[6]], vp = viewport(layout.pos.row = 3, layout.pos.col = 2)) 4.9 研究 mpgcars 数据集 仔细观察数据集会发现 displ 和 hwy 是经过四舍五入的，在实际图表上很多点会产生重叠： ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(alpha = 1 / 5) 对 position 添加 jitter 值可以手动添加 “数据噪点”，从而更好地看到数据全貌（尽管会改变数值导致图表不那么准确）： ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), position = &quot;jitter&quot;) "],["workflow-basics.html", "Chapter 5 Workflow: basics", " Chapter 5 Workflow: basics 在 R 里，你甚至能当计算器： 1 / 200 * 30 ## [1] 0.15 (59 + 73 + 2) / 3 ## [1] 44.66667 sin(pi / 2) ## [1] 1 注意赋值语句应当用 “&lt;-”： x &lt;- 3 * 4 b &lt;- x “=” 用于定义函数所指定的参数。虽然错误的书写不会导致报错，但对于代码的阅读量影响颇大。 命名上，R 一般使用字母开头，字符只能使用 “.” 和 “_”： i_use_snake_case # 推荐的命名法则 otherPeopleUseCamelCase some.people.use.periods 此外，R 允许在赋值语句打括号用于返回赋值内容。这与 C 语言非常类似： (y &lt;- seq(1, 10, length.out = 5)) # 返回一个向量，元素均匀地分布从 1 到 10，共 5 个 ## [1] 1.00 3.25 5.50 7.75 10.00 "],["transform.html", "Chapter 6 Data transformation 6.1 查看 flights 数据集 6.2 过滤 filter() 6.3 排列 arange() 6.4 选择 select() 6.5 重命名 rename() 6.6 添加新变量 mutate() 与 transmute() 6.7 分组摘要 summarise() 6.8 其他处理数据功能 6.9 分析 flights 数据集", " Chapter 6 Data transformation 可视化是生成可以直接观察的数据展示形式的重要工具，但我们却很少能以所需的正确形式获取数据。因此，我们通常需要创建一些新的变量或摘要，或是纯粹地只想重命名变量或对观测值重新排序。 library(nycflights13) library(tidyverse) 6.1 查看 flights 数据集 在后面的案例中，我们将持续关注来自 nycflights13 的数据集 flights。 它包含 2013 年从纽约市出发的共 336,776 个航班。 flights #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 列名称下字母缩写代表该列的数据类型： - int：整数 - dbl：双精度或实数 - chr：字符向量或字符串 - dttm：日期时间（日期 + 时间） 此外还有： - lgl：仅包含逻辑词（TRUE / FALSE） - fctr：因子（factor），表示具有固定可能值的分类变量 - date：日期 tidyverse 还附带了一些神奇的功能，如 filter、arrange、select、rename、mutate 和 summarise 等。下面我们将逐个学习它们。 6.2 过滤 filter() # 筛选月份为 1，天数为 1 的 filter(flights, month == 1, day == 1) #&gt; # A tibble: 842 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; # ... with 832 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 筛选月份为 12 且天数为 25 的（圣诞节） filter(flights, month == 12 &amp; day == 25) #&gt; # A tibble: 719 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 12 25 456 500 -4 649 651 #&gt; 2 2013 12 25 524 515 9 805 814 #&gt; 3 2013 12 25 542 540 2 832 850 #&gt; 4 2013 12 25 546 550 -4 1022 1027 #&gt; 5 2013 12 25 556 600 -4 730 745 #&gt; 6 2013 12 25 557 600 -3 743 752 #&gt; 7 2013 12 25 557 600 -3 818 831 #&gt; 8 2013 12 25 559 600 -1 855 856 #&gt; 9 2013 12 25 559 600 -1 849 855 #&gt; 10 2013 12 25 600 600 0 850 846 #&gt; # ... with 709 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 筛选出月份为12，天数为 11 或者 12 的 filter(flights, month == 12, day == 11 | day == 12) #&gt; # A tibble: 1,922 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 12 11 459 500 -1 651 651 #&gt; 2 2013 12 11 517 515 2 825 814 #&gt; 3 2013 12 11 542 545 -3 841 832 #&gt; 4 2013 12 11 544 540 4 838 850 #&gt; 5 2013 12 11 544 550 -6 1021 1027 #&gt; 6 2013 12 11 552 600 -8 927 915 #&gt; 7 2013 12 11 552 600 -8 712 717 #&gt; 8 2013 12 11 553 600 -7 644 701 #&gt; 9 2013 12 11 554 600 -6 753 755 #&gt; 10 2013 12 11 554 600 -6 656 659 #&gt; # ... with 1,912 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 筛选出月份为12，天数为 10 或者 11 或者 12 的 filter(flights, month == 12, day %in% c(10, 11, 12)) # 注意 “包含于” 表示的方法 #&gt; # A tibble: 2,865 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 12 10 7 2359 8 451 445 #&gt; 2 2013 12 10 7 2359 8 446 437 #&gt; 3 2013 12 10 11 2245 86 119 2353 #&gt; 4 2013 12 10 211 2359 132 651 440 #&gt; 5 2013 12 10 457 500 -3 701 651 #&gt; 6 2013 12 10 528 515 13 830 814 #&gt; 7 2013 12 10 543 545 -2 907 832 #&gt; 8 2013 12 10 548 550 -2 1022 1027 #&gt; 9 2013 12 10 549 540 9 854 850 #&gt; 10 2013 12 10 551 600 -9 920 856 #&gt; # ... with 2,855 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 添加函数参数 na.rm = TRUE 来剔除数据，is.na 来判断是否为 NA（这是通用的） filter(flights, month == 1, na.rm = TRUE) #&gt; # A tibble: 27,004 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; # ... with 26,994 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 6.2.1 比较 对于比较大小，我们有 &gt;、&gt;=、&lt;、&lt;=、!= 和 ==。注意这里的等于用了两个等于符号表示（这与很多语言保持一致）。如果写成了一个，R 通常会 “机智地” 提醒你： filter(flights, month = 1) #&gt; Error in `filter()`: #&gt; ! We detected a named input. #&gt; i This usually means that you&#39;ve used `=` instead of `==`. #&gt; i Did you mean `month == 1`? #&gt; Backtrace: #&gt; 1. dplyr::filter(flights, month = 1) #&gt; 2. dplyr:::filter.data.frame(flights, month = 1) 注意：在比较数据时你可能会遇到浮点数，导致结果可能不符合常理： sqrt(2)^2 == 2 #&gt; [1] FALSE 1 / 49 * 49 == 1 #&gt; [1] FALSE 请使用 near() 函数解决这个问题： near(sqrt(2)^2, 2) #&gt; [1] TRUE near(1 / 49 * 49, 1) #&gt; [1] TRUE 6.2.2 逻辑运算符 R 提供了逻辑运算符 &amp;、| 和 nor()，在变量前加感叹号表示相反。 完整的布尔运算集。“x”是左边的圆圈，“y”是右边的圆圈，阴影区域显示每个操作员选择的部分。 6.2.3 缺失值 R 在数据缺失时会用 NA 表示。但注意它并不是单纯地表示 0。小心在比较时它会传染！ NA &gt; 5 #&gt; [1] NA 10 == NA #&gt; [1] NA NA + 10 #&gt; [1] NA NA / 2 #&gt; [1] NA NA == NA #&gt; [1] NA 我们需要人性地代入进去看待这个问题。这里有个很好的范例： # Let x be Mary&#39;s age. We don&#39;t know how old she is. x &lt;- NA # Let y be John&#39;s age. We don&#39;t know how old he is. y &lt;- NA # Are John and Mary the same age? x == y #&gt; [1] NA # We don&#39;t know! 6.3 排列 arange() # 按照年月日排序 arrange(flights, year, month, day) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 515 2 830 819 #&gt; 2 2013 1 1 533 529 4 850 830 #&gt; 3 2013 1 1 542 540 2 923 850 #&gt; 4 2013 1 1 544 545 -1 1004 1022 #&gt; 5 2013 1 1 554 600 -6 812 837 #&gt; 6 2013 1 1 554 558 -4 740 728 #&gt; 7 2013 1 1 555 600 -5 913 854 #&gt; 8 2013 1 1 557 600 -3 709 723 #&gt; 9 2013 1 1 557 600 -3 838 846 #&gt; 10 2013 1 1 558 600 -2 753 745 #&gt; # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 反向排序。注意无论正反向，NA 值都总是被排到末尾： arrange(flights, desc(dep_delay)) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 9 641 900 1301 1242 1530 #&gt; 2 2013 6 15 1432 1935 1137 1607 2120 #&gt; 3 2013 1 10 1121 1635 1126 1239 1810 #&gt; 4 2013 9 20 1139 1845 1014 1457 2210 #&gt; 5 2013 7 22 845 1600 1005 1044 1815 #&gt; 6 2013 4 10 1100 1900 960 1342 2211 #&gt; 7 2013 3 17 2321 810 911 135 1020 #&gt; 8 2013 6 27 959 1900 899 1236 2226 #&gt; 9 2013 7 22 2257 759 898 121 1026 #&gt; 10 2013 12 5 756 1700 896 1058 2020 #&gt; # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, #&gt; # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, #&gt; # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 6.4 选择 select() 注意一些方便的匹配规则： starts_with(\"abc\")：匹配以 “abc” 开头的名称。 ends_with(\"xyz\")：匹配以 “xyz” 结尾的名称。 contains(\"ijk\")：匹配包含 “ijk” 的名称。 matches(\"(.)\\\\1\")：选择与正则表达式匹配的变量。 num_range(\"x\", 1:3)：匹配 x1、x2和 x3。 # 选出年月日 select(flights, year, month, day) #&gt; # A tibble: 336,776 x 3 #&gt; year month day #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 #&gt; 2 2013 1 1 #&gt; 3 2013 1 1 #&gt; 4 2013 1 1 #&gt; 5 2013 1 1 #&gt; 6 2013 1 1 #&gt; 7 2013 1 1 #&gt; 8 2013 1 1 #&gt; 9 2013 1 1 #&gt; 10 2013 1 1 #&gt; # ... with 336,766 more rows select(flights, year:day) #&gt; # A tibble: 336,776 x 3 #&gt; year month day #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 #&gt; 2 2013 1 1 #&gt; 3 2013 1 1 #&gt; 4 2013 1 1 #&gt; 5 2013 1 1 #&gt; 6 2013 1 1 #&gt; 7 2013 1 1 #&gt; 8 2013 1 1 #&gt; 9 2013 1 1 #&gt; 10 2013 1 1 #&gt; # ... with 336,766 more rows # 选出除年月日以及 flight 的所有列 select(flights, -c(year:day, flight)) # 有时 c 可以省略掉 #&gt; # A tibble: 336,776 x 15 #&gt; dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier #&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 517 515 2 830 819 11 UA #&gt; 2 533 529 4 850 830 20 UA #&gt; 3 542 540 2 923 850 33 AA #&gt; 4 544 545 -1 1004 1022 -18 B6 #&gt; 5 554 600 -6 812 837 -25 DL #&gt; 6 554 558 -4 740 728 12 UA #&gt; 7 555 600 -5 913 854 19 B6 #&gt; 8 557 600 -3 709 723 -14 EV #&gt; 9 557 600 -3 838 846 -8 B6 #&gt; 10 558 600 -2 753 745 8 AA #&gt; # ... with 336,766 more rows, and 8 more variables: tailnum &lt;chr&gt;, #&gt; # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, #&gt; # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # 选出结尾为 delay 相关的列 select(flights, ends_with(&quot;delay&quot;)) #&gt; # A tibble: 336,776 x 2 #&gt; dep_delay arr_delay #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 11 #&gt; 2 4 20 #&gt; 3 2 33 #&gt; 4 -1 -18 #&gt; 5 -6 -25 #&gt; 6 -4 12 #&gt; 7 -5 19 #&gt; 8 -3 -14 #&gt; 9 -3 -8 #&gt; 10 -2 8 #&gt; # ... with 336,766 more rows # 选出开头为 sched 相关的列 select(flights, starts_with(&quot;sched&quot;)) #&gt; # A tibble: 336,776 x 2 #&gt; sched_dep_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 515 819 #&gt; 2 529 830 #&gt; 3 540 850 #&gt; 4 545 1022 #&gt; 5 600 837 #&gt; 6 558 728 #&gt; 7 600 854 #&gt; 8 600 723 #&gt; 9 600 846 #&gt; 10 600 745 #&gt; # ... with 336,766 more rows # 选出包含 sched 相关的列 select(flights, contains(&quot;sched&quot;)) #&gt; # A tibble: 336,776 x 2 #&gt; sched_dep_time sched_arr_time #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 515 819 #&gt; 2 529 830 #&gt; 3 540 850 #&gt; 4 545 1022 #&gt; 5 600 837 #&gt; 6 558 728 #&gt; 7 600 854 #&gt; 8 600 723 #&gt; 9 600 846 #&gt; 10 600 745 #&gt; # ... with 336,766 more rows # 选出的数据不包含带 sched的列，此外其他都包含 select(flights, -contains(&quot;sched&quot;), everything()) #&gt; # A tibble: 336,776 x 19 #&gt; year month day dep_time dep_delay arr_time arr_delay carrier flight #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 2 830 11 UA 1545 #&gt; 2 2013 1 1 533 4 850 20 UA 1714 #&gt; 3 2013 1 1 542 2 923 33 AA 1141 #&gt; 4 2013 1 1 544 -1 1004 -18 B6 725 #&gt; 5 2013 1 1 554 -6 812 -25 DL 461 #&gt; 6 2013 1 1 554 -4 740 12 UA 1696 #&gt; 7 2013 1 1 555 -5 913 19 B6 507 #&gt; 8 2013 1 1 557 -3 709 -14 EV 5708 #&gt; 9 2013 1 1 557 -3 838 -8 B6 79 #&gt; 10 2013 1 1 558 -2 753 8 AA 301 #&gt; # ... with 336,766 more rows, and 10 more variables: tailnum &lt;chr&gt;, #&gt; # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, #&gt; # minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, sched_dep_time &lt;int&gt;, sched_arr_time &lt;int&gt; 6.5 重命名 rename() 一般用得很少，但有时很刚需。其实它是 select() 的变体： rename(flights, tail_num = tailnum) 6.6 添加新变量 mutate() 与 transmute() # 生成优化版的 flights 数据集 flights_sml &lt;- select(flights, year:day, ends_with(&quot;delay&quot;), distance, air_time) mutate( flights_sml, gain = dep_delay - arr_delay, speed_min = distance / air_time, # 计算出的新数据 speed_sec = speed_min * 60 # 从刚生成的数据中套新数据 ) #&gt; # A tibble: 336,776 x 10 #&gt; year month day dep_delay arr_delay distance air_time gain speed_min #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 2 11 1400 227 -9 6.17 #&gt; 2 2013 1 1 4 20 1416 227 -16 6.24 #&gt; 3 2013 1 1 2 33 1089 160 -31 6.81 #&gt; 4 2013 1 1 -1 -18 1576 183 17 8.61 #&gt; 5 2013 1 1 -6 -25 762 116 19 6.57 #&gt; 6 2013 1 1 -4 12 719 150 -16 4.79 #&gt; 7 2013 1 1 -5 19 1065 158 -24 6.74 #&gt; 8 2013 1 1 -3 -14 229 53 11 4.32 #&gt; 9 2013 1 1 -3 -8 944 140 5 6.74 #&gt; 10 2013 1 1 -2 8 733 138 -10 5.31 #&gt; # ... with 336,766 more rows, and 1 more variable: speed_sec &lt;dbl&gt; # 生成数据中不包含旧数据，应该使用 transmute transmute( flights_sml, gain = dep_delay - arr_delay, speed_min = distance / air_time, # 计算出的新数据 speed_sec = speed_min * 60 # 从刚生成的数据中套新数据 ) #&gt; # A tibble: 336,776 x 3 #&gt; gain speed_min speed_sec #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -9 6.17 370. #&gt; 2 -16 6.24 374. #&gt; 3 -31 6.81 408. #&gt; 4 17 8.61 517. #&gt; 5 19 6.57 394. #&gt; 6 -16 4.79 288. #&gt; 7 -24 6.74 404. #&gt; 8 11 4.32 259. #&gt; 9 5 6.74 405. #&gt; 10 -10 5.31 319. #&gt; # ... with 336,766 more rows 6.7 分组摘要 summarise() 注意关注管道符号：%&gt;% # x %&gt;% f(y) 即为 f(x, y) msleep %&gt;% count(order, sort = TRUE) # 上面的等同于下面的 count(msleep, order, sort = T) 注意单纯的 summarize 并没有太大的用处： summarise( flights, delay = mean(dep_delay, na.rm = TRUE) # mean，取均值，na.rm 忽略空值 ) #&gt; # A tibble: 1 x 1 #&gt; delay #&gt; &lt;dbl&gt; #&gt; 1 12.6 所以我们一般配合 group_by 使用： by_day &lt;- group_by(flights, year, month, day) # 分组细节到年月日 summarise( by_day, delay = mean(dep_delay, na.rm = TRUE) # 组内的 [delay] 标签追加，按照算法分组返回值 ) #&gt; `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the `.groups` #&gt; argument. #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day delay #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 11.5 #&gt; 2 2013 1 2 13.9 #&gt; 3 2013 1 3 11.0 #&gt; 4 2013 1 4 8.95 #&gt; 5 2013 1 5 5.73 #&gt; 6 2013 1 6 7.15 #&gt; 7 2013 1 7 5.42 #&gt; 8 2013 1 8 2.55 #&gt; 9 2013 1 9 2.28 #&gt; 10 2013 1 10 2.84 #&gt; # ... with 355 more rows # 使用管道符 &quot;%&gt;%&quot; 精简代码 group_by(flights, year, month, day) %&gt;% summarise(delay = mean(dep_delay, na.rm = TRUE)) #&gt; `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the `.groups` #&gt; argument. #&gt; # A tibble: 365 x 4 #&gt; # Groups: year, month [12] #&gt; year month day delay #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 11.5 #&gt; 2 2013 1 2 13.9 #&gt; 3 2013 1 3 11.0 #&gt; 4 2013 1 4 8.95 #&gt; 5 2013 1 5 5.73 #&gt; 6 2013 1 6 7.15 #&gt; 7 2013 1 7 5.42 #&gt; 8 2013 1 8 2.55 #&gt; 9 2013 1 9 2.28 #&gt; 10 2013 1 10 2.84 #&gt; # ... with 355 more rows 6.8 其他处理数据功能 算术运算符：+ - * /。它们可以用于向量，会自动帮你做一个 for 循环。 模算术：%/% 求模、 %% 求余。 Log：log()、log2()、log10()，即求对数。这些会在未来建模时常常用到。 偏移量：lag() 值前导、lead() 值滞后，用于将向量的值前导或滞后。如： (x &lt;- 1:10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 lag(x) #&gt; [1] NA 1 2 3 4 5 6 7 8 9 lead(x) #&gt; [1] 2 3 4 5 6 7 8 9 10 NA 累积和滚动聚合：cumsum() 总和、cumprod() 乘积、cummin() 最小值、cummax() 最大值、cummean() 均值。此外 dplyr 也提供累积手段。如果我们需要滚动聚合（即在滚动窗口上计算的总和），请尝试 RcppRoll 包。 (x &lt;- (1:10)) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 cumsum(x) #&gt; [1] 1 3 6 10 15 21 28 36 45 55 cummean(x) #&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.9 分析 flights 数据集 6.9.1 计算目的地相关的图 by_dest &lt;- group_by(flights, dest) # 以 dest 分组 delay &lt;- summarise( by_dest, count = n(), # 计算组内数据数量 dist = mean(distance, na.rm = TRUE), # 计算每组内的 distance 平均值 arr_delay = mean(arr_delay, na.rm = TRUE), # 同理，到达时间 ) # 精简得到想要的数据 delay &lt;- filter(delay, count &gt; 20, dest != &quot;HNL&quot;) # 到达数大于20次，目的地不为 HNL # 尝试画图 ggplot( data = delay, mapping = aes(x = dist, y = arr_delay) # 确定 data 和 mapping 的默认数据 ) + geom_point( aes(size = count), # 添加新的特殊数据 size（此处 mapping 为默认值，可省略声明） alpha = 1 / 3 # 透明度固定 ) + geom_smooth(se = FALSE) # 绘制平滑曲线 #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 6.9.2 获取热门目的地及有关数据 pop_dests &lt;- group_by(flights, dest) %&gt;% filter(n() &gt; 365) %&gt;% distinct(dest) # 筛选只要指定的列 head(pop_dests, 10) # 只展示前十 #&gt; # A tibble: 10 x 1 #&gt; # Groups: dest [10] #&gt; dest #&gt; &lt;chr&gt; #&gt; 1 IAH #&gt; 2 MIA #&gt; 3 BQN #&gt; 4 ATL #&gt; 5 ORD #&gt; 6 FLL #&gt; 7 IAD #&gt; 8 MCO #&gt; 9 PBI #&gt; 10 TPA 6.9.3 绘制飞机延误时长分布图 delays &lt;- flights %&gt;% # 获得处理后的数据 filter(!is.na(dep_delay), !is.na(arr_delay)) %&gt;% # 去除空 NA 数据 group_by(tailnum) %&gt;% # 按航班分组 summarise( # 获取平均值并产生包含 group_by 列和计算的新列 delay = mean(arr_delay, na.rm = TRUE), # 由于之前过滤过了，此处的 na.rm 可以去掉 n = n() # 统计数量，方便绘制直方图 ) delays %&gt;% filter(n &gt; 25) %&gt;% # 数量很小时往往会对数据产生较大影响。这里过滤掉它们 ggplot(mapping = aes(x = n, y = delay)) + geom_point(alpha = 1 / 10) 6.9.4 计算每天最早和最晚的航班 flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) %&gt;% group_by(year, month, day) %&gt;% summarise( first = min(dep_time), last = max(dep_time) ) #&gt; `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;. You can override using the `.groups` #&gt; argument. #&gt; # A tibble: 365 x 5 #&gt; # Groups: year, month [12] #&gt; year month day first last #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 2013 1 1 517 2356 #&gt; 2 2013 1 2 42 2354 #&gt; 3 2013 1 3 32 2349 #&gt; 4 2013 1 4 25 2358 #&gt; 5 2013 1 5 14 2357 #&gt; 6 2013 1 6 16 2355 #&gt; 7 2013 1 7 49 2359 #&gt; 8 2013 1 8 454 2351 #&gt; 9 2013 1 9 2 2252 #&gt; 10 2013 1 10 3 2320 #&gt; # ... with 355 more rows "],["workflow-scripts.html", "Chapter 7 Workflow: scripts 7.1 运行代码 7.2 RStudio 诊断 7.3 使用 Visual studio code 编写 R", " Chapter 7 Workflow: scripts 到目前为止，我们一直在使用 Console 控制台来运行代码。但当我们创建更复杂的 ggplot2 图和 dplyr 管道时，我们会发现它很快就会变得狭窄。为了给自己更多的工作空间，使用脚本编辑器是个好主意。 通过单击 “文件” 菜单，然后选择 “新建文件” ，然后选择 “R 脚本”，或使用键盘快捷键 Cmd/Ctrl + Shift + N 将其打开。现在，我们将看到四个窗格： rstudio-editor 7.1 运行代码 脚本编辑器也是构建复杂的 ggplot2 图或长序列 dplyr 操作的好地方。一个最重要的快捷键：Cmd / Ctrl + Enter。这将在控制台中执行当前 R 表达式。选中代码时执行选中部分，否则它将自动执行光标所在的那一小段代码，然后自动将光标挪到下一段。 除了逐个表达式运行之外，快捷键：Cmd/Ctrl + Shift + S 用于执行整个当前文件。 7.2 RStudio 诊断 脚本编辑器还将在侧边栏中用红色波浪线和红色的错误图标突出显示语法错误： rstudio-diagnostic 将鼠标悬停在对应代码上以查看问题所在： rstudio-diagnostic-tip RStudio 还会让你了解潜在的问题： rstudio-diagnostic-warn 7.3 使用 Visual studio code 编写 R 这是激动人心的 —— 这款号称 “21 世纪最伟大的编辑器” 的通用代码编辑器成功让 R 运作起来了。但我们说，事情往往伴随着代价。在 VSCode 上，你可能需要一些基础去调整好它。它需要的核心是 Radian – A 21 century R console。 合理地使用 VScode，能提高我们的工作效率。而且控制台历史记录、查询、工作区与变量管理、智能装包、强大的帮助系统、缩进与格式化代码等功能它都不曾欠缺。相信聪明的读者应该有着更聪慧的头脑，在选择方面做出更为理智的决定吧。 "],["exploratory-data-analysis.html", "Chapter 8 Exploratory Data Analysis 8.1 绘图分析 diamonds 数据集 8.2 绘图统计 flights 数据集 8.3 绘图统计 diamonds 数据集", " Chapter 8 Exploratory Data Analysis 系统地可视化和转换探索数据，我们称为探索性数据分析或简称 EDA。EDA 是一个迭代循环，包括： 生成有关数据的问题。 通过可视化、转换和建模数据来搜索答案。 使用学到的知识来完善问题本身或生成新的问题。 此外请关注以下数据： 变量：可以测量的数量、质量或属性。 值：测量变量时变量的状态。变量的值可能因测量值而异。 观测值：在相似条件下进行的一组测量，将包含多个值，每个值都与不同的变量相关联。有时也叫数据点。 表格数据：一组值，每个值都与一个变量和一个观测值相关联。 library(tidyverse) 8.1 绘图分析 diamonds 数据集 8.1.1 可视化分布 分类变量的分布一般用条形图，如：统计各种品质钻石的数量并绘图 ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut)) 如果想要数据的话也可以用 dplyr::count() 统计。但事实上，所有 count() 能做的，group_by + summarise 都能： diamonds %&gt;% count(cut_width(carat, 0.5)) # cut_width() 将数据切片分组。注意新的列名叫 cut #&gt; # A tibble: 11 x 2 #&gt; `cut_width(carat, 0.5)` n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 [-0.25,0.25] 785 #&gt; 2 (0.25,0.75] 29498 #&gt; 3 (0.75,1.25] 15977 #&gt; 4 (1.25,1.75] 5313 #&gt; 5 (1.75,2.25] 2002 #&gt; 6 (2.25,2.75] 322 #&gt; 7 (2.75,3.25] 32 #&gt; 8 (3.25,3.75] 5 #&gt; 9 (3.75,4.25] 4 #&gt; 10 (4.25,4.75] 1 #&gt; 11 (4.75,5.25] 1 8.1.2 绘制频率直方图 直方图一般用来检查连续变量的分布，如：统计各种克拉数的数量并绘图 ggplot(data = diamonds) + geom_histogram( mapping = aes(x = carat), binwidth = 0.3 # 将宽度容纳（区间）增加至指定宽度 ) geom_histogram() 生成的是柱形图，但如果你想要叠加多个数据的话，更推荐能生成线条图的 geom_freqpoly()： ggplot(data = diamonds, mapping = aes(x = carat, colour = cut)) + geom_freqpoly(binwidth = 0.1) 想要数据的话使用 dplyr::count() 和 ggplot2::cut_width() 计算： diamonds %&gt;% count(cut_width(carat, 0.5)) #&gt; # A tibble: 11 x 2 #&gt; `cut_width(carat, 0.5)` n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 [-0.25,0.25] 785 #&gt; 2 (0.25,0.75] 29498 #&gt; 3 (0.75,1.25] 15977 #&gt; 4 (1.25,1.75] 5313 #&gt; 5 (1.75,2.25] 2002 #&gt; 6 (2.25,2.75] 322 #&gt; 7 (2.75,3.25] 32 #&gt; 8 (3.25,3.75] 5 #&gt; 9 (3.75,4.25] 4 #&gt; 10 (4.25,4.75] 1 #&gt; 11 (4.75,5.25] 1 8.1.3 异常数据（杂质） 异常值是超出正常范围的观察值。产生原因有时只是单纯的数据输入错误，但同样也很可能表明着新的重要科学。 例如这里用 y 列做研究： ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) 你会发现它们大多收缩成一团，而一些可疑的值明显影响了整个数据。 为了看到那些不寻常发值，我们使用 coord_cartesian() 将区别放大化： ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + coord_cartesian(ylim = c(0, 50)) # 将 y 轴放大化直到区间 0 ~ 50 当然这个函数也是有 xlim 参数的，同理。 有 3 个与众不同的值出现了！分别为 0、30、60。我们把它们提取出来： unusual &lt;- diamonds %&gt;% filter(y &lt; 3 | y &gt; 20) %&gt;% select(price, x, y, z) %&gt;% arrange(y) %&gt;% print() #&gt; # A tibble: 9 x 4 #&gt; price x y z #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 5139 0 0 0 #&gt; 2 6381 0 0 0 #&gt; 3 12800 0 0 0 #&gt; 4 15686 0 0 0 #&gt; 5 18034 0 0 0 #&gt; 6 2130 0 0 0 #&gt; 7 2130 0 0 0 #&gt; 8 2075 5.15 31.8 5.12 #&gt; 9 12210 8.09 58.9 8.06 这些值带着明显的伦理问题和常理性错误。而我们也最好是在没有异常值的情况下进行分析。如果它们对结果的影响很小，并且我们尚且无法弄清楚它们存在的原因，那么用缺失的值（NA）替换它们是合理的。但如果它们对我们的结果有实质性影响，则不应当无缘无故地放弃它们。 我们需要找出导致它们的原因（如数据输入错误），并合理地处理这些异常数据。 8.1.4 处理异常数据 法一：删除含异常值的整行 diamonds_new &lt;- diamonds %&gt;% filter(between(y, 3, 20)) # 新建数据集过滤掉杂质 法二：将异常值替换为 NA （推荐） diamonds_new &lt;- diamonds %&gt;% # 非常类似于 C 语言中的 xx?xx:xx 。如果 y 在 3 到 20 间则保持，否则返回 NA # 此外 dplyr::case_when() 有着近乎相同的功能 mutate(y = ifelse(y &gt; 3 &amp; y &lt; 20, y, NA)) 但事实上，如果数据含有 NA，ggplot 绘图会发出警告并将相应数据剔除不会展示出来： ggplot(data = diamonds_new, mapping = aes(x = x, y = y)) + geom_point() #&gt; Warning: Removed 9 rows containing missing values (geom_point). 我们应该手动移除带 NA 的无效数据： ggplot(data = diamonds_new, mapping = aes(x = x, y = y)) + geom_point(na.rm = TRUE) 8.2 绘图统计 flights 数据集 nycflights13::flights %&gt;% mutate( cancelled = is.na(dep_time), # 如果数据是 NA 就表示航班取消了 sched_hour = sched_dep_time %/% 100, # 国际计时除 100 商得到小时 sched_min = sched_dep_time %% 100, # 国际计时除 100 取余得到分钟 sched_dep_time = sched_hour + sched_min / 60 # 按照我们习惯转换成正常的分钟数 ) %&gt;% # freqpoly 非常适合折线图效果。对应的柱状图是 histogram # binwidth 通常会用来描述线或柱的精度。精度不足的部分会用平均值模糊化替代 ggplot(mapping = aes(sched_dep_time)) + geom_freqpoly(mapping = aes(color = cancelled), binwidth = 1 / 4) 但这样的图表并不友好，因为未取消的航班比取消的多得多而不方便观察分析细节。 8.3 绘图统计 diamonds 数据集 8.3.1 连续变量多类绘图 8.3.1.1 频率多边形 正如前面的频率多边形那样，我们通常需要观察按不同类别的连续变量的分布直方图。所以我们采用频率多边形来展示： ggplot(data = diamonds, mapping = aes(x = price)) + geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) 但不同类别之间的数据差异依然相对明显，一些相对 “小得多” 的类别的形状难以被观察到。使用柱状图可以明显看到各个种类计数差异巨大： ggplot(diamonds) + geom_bar(mapping = aes(x = cut)) 因此我们需要修改 y 轴的内容。我们将不显示计数，而是显示密度（使其标准化），以便每个频率多边形围成的面积正好为 1： ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) 实际结果令人震惊！品质最差钻石却有着最高的平均价格！（UC：明天来上班）这个图中有很多有趣的现象，我们将在后面的学习中继续做深度挖掘。 8.3.1.2 箱形图（箱线图） 箱线图是一种在统计学家中流行的值分布的视觉速记。其元素组成包括： 盒子中间：中位数 盒子两头：25% 和 75%，也称为四分位距（两头距离长度称作 IQR） 盒子两头延伸的细线：从盒子两头算起不超过 IQR 的 1.5 倍的最小和最大值 盒子两头远处的点：超过 IQR 的 1.5 倍的异常值 img ggplot(data = diamonds, mapping = aes(x = cut, y = price)) + geom_boxplot() 箱线图的信息展示会比频率多边形要紧凑得多，更利于我们比较。它支持了一个违反直觉的发现，即质量更好的钻石明显更便宜！ 8.3.2 关于变量排序 reorder() 像 cut 这样的变量可能还有一个较好的默认排序，但事实上我们遇到的很多数据集可能没有这么好，需要重新排序。reorder() 可以帮你做到。如 mpg 数据集的 class： ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() 为了使趋势更容易看到，我们可以根据 hwy 的“值” 重新排序： ggplot(data = mpg) + geom_boxplot(mapping = aes( # reorder 排序，对 class 根据对应的 hwy 值进行排序, median 用来确认函数是否具有返回值 x = reorder(class, hwy, FUN = median), y = hwy )) + coord_flip() # xy 轴交换，方便展示长变量名 8.3.3 两个分类变量 8.3.3.1 交点图 查看颜色与质量的关系： ggplot(data = diamonds_new) + # geom_count 用来通过显示点的大小展示数据大小（次数、频率） geom_count(mapping = aes(x = color, y = cut)) 8.3.3.2 色砖图 diamonds_new %&gt;% count(color, cut) %&gt;% # 这里只能手动计数，但不需要 group_by ggplot(mapping = aes(x = color, y = cut)) + # 注意这里的 color 只是边框颜色 geom_tile(mapping = aes(fill = n), color = &quot;grey50&quot;) 注意仅求数据可以用 count() 实现： diamonds %&gt;% count(color, cut) 8.3.4 两个连续变量 8.3.4.1 二维装箱 可视化两个连续变量之间协变量的一种好方法就是使用绘制散点图。如查看质量与价格的关系： ggplot(data = diamonds) + geom_point(mapping = aes(x = carat, y = price)) 散点图的点开始过度绘制，并密集堆积成均匀黑色的区域（如上所述）。一种解决方法是增加透明度： ggplot(data = diamonds_new) + geom_point(mapping = aes(x = carat, y = price), alpha = 1 / 100) # 对于非常大的数据集，使用透明度可能具有挑战性。一种解决方案是使用二维装箱 # 通过方形小色块（类似平均值效果）来模糊数据 ggplot(data = diamonds_new) + geom_bin2d(mapping = aes(x = carat, y = price)) # 或者使用六边形小块（需要安装包 hexbin） #* install.packages(&quot;hexbin&quot;) ggplot(data = diamonds_new) + geom_hex(mapping = aes(x = carat, y = price)) 8.3.4.2 箱线图装箱 另一种选择是将一个连续变量装箱，使其像分类变量一样工作。所以我们使用 cut_width 分组： ggplot(data = diamonds_new, mapping = aes(x = carat, y = price)) + # cut_width 是 ggplot 包的函数，用来切片配合分组，将前者以后者数值划分 geom_boxplot(mapping = aes(group = cut_width(carat, 0.3))) 或者在每个条柱中显示大致相同的点数。我们使用 cut_number() 分组： ggplot(data = diamonds_new, mapping = aes(x = carat, y = price)) + geom_boxplot(mapping = aes(group = cut_number(carat, 20))) "],["workflow-projects.html", "Chapter 9 Workflow: projects 9.1 运行环境 9.2 工作区 9.3 路径与目录 9.4 RStudio 项目", " Chapter 9 Workflow: projects 9.1 运行环境 使用 R 脚本（和数据文件），可以重新创建环境。从环境中重新创建 R 脚本要困难得多！你要么必须从内存中重新键入大量代码，要么必须仔细挖掘你的 R 脚本执行历史记录。 为了培养这种行为，我强烈建议我们将 RStudio 设置为不要在会话之间保留我们的工作区记录： rstudio-workspace 有一对很棒的键盘快捷键可以协同工作，以确保我们在编辑器中存储了代码的重要部分： Cmd/Ctrl + Shift + F10 重新启动 RStudio。 Cmd/Ctrl + Shift + S 重新运行当前脚本。 9.2 工作区 工作区目录对 R 的文件路径处理上非常重要。这是 R 查找你所要求加载文件和保存执行文件的位置。RStudio 在控制台顶部会显示当前的工作目录： rstudio-wd 使用 getwd() 命令在 R 控制台中打印出来： getwd() #&gt; [1] &quot;D:/Project/R-Project/book&quot; 作为 R 用户，可以让你的任何奇怪的目录成为 R 的工作目录。我们应该很快将要分析的项目组织到目录中，并且在处理项目时，将 R 的工作目录设置为与之关联的目录。 使用 setwd() 从控制台中设置工作目录（不推荐）： setwd(&quot;/path/to/my/CoolProject&quot;) 9.3 路径与目录 路径和目录有点复杂，因为Mac/Linux 和 Windows 两者不太一样： Mac 和 Linux 使用斜杠 “/”，Windows 使用反斜杠 “”。R 可以使用任何一种类型（无论我们当前使用的是什么平台），但在路径中要单个反斜杠，我们需要键入两个反斜杠去等效，所以建议始终使用正斜杠路径，如：plots/diamonds.pdf 绝对路径看起来都不同。在 Windows 中，它们以驱动器号 + 冒号 + 两个反斜杠开头，如 C:\\\\servername；而在 Mac / Linux 中，它们以斜杠开头，如 /users/hadley。所以建议不使用绝对路径，以保证代码的兼容性和可共享性。 ~ 指向的地方也不太相同。它本是通往主目录的便捷方式，但 Windows 并没有这种概念，因此 R 中它指向文档目录。 9.4 RStudio 项目 一个普遍明智的做法是，将与项目关联的所有文件保存在一起，包括输入数据、R 脚本、分析结果和数字。 单击 文件 &gt; 新建项目 来创建它： rstudio-project-1 rstudio-project-2 rstudio-project-3 以后保存文件应该使用如下方式： library(tidyverse) ggplot(diamonds, aes(carat, price)) + geom_hex() ggsave(&quot;diamonds.pdf&quot;) write_csv(diamonds, &quot;diamonds.csv&quot;) "],["wrangle-intro.html", "Chapter 10 Introduction", " Chapter 10 Introduction 数据扭结，以合适的形式将数据导入 R 用于可视化和建模。数据整理非常重要：没有它，你就无法处理自己的数据！数据整理有三个主要部分： data-science-wrangle 在 tibbles 中，你将了解到贯穿全全笔记中使用的 dataframe 的变体：tibble。你将了解它们与常规数据框的不同之处，以及如何 “手动” 构建它们。 在数据导入中，你将了解如何将数据从磁盘获取到 R 中。我们将重点介绍纯文本的矩阵格式，但会为你提供指向有助于处理其他类型的数据的包的指南。 在整洁的数据中，你将了解整洁的数据，这是一种存储数据的一种约定俗成的方式，使转换、可视化和建模更加容易。你将学习基本原则，以及如何将数据转换为整洁的形式。 数据扭结还包括数据转换。接下来我们将重点介绍实践中常用的三种特定类型数据的新技能： 关系数据将为你提供用于处理多个相互关联的数据集的工具。 字符串工具将携手正则表达式，这是一种用于操作字符串的强大工具。 因子是 R 如何存储分类数据的。一般被用于当变量具有一组固定的可能值，或者当你希望使用字符串的非字母排序。 日期和时间工具将为你提供处理日期和日期时间的关键工具。 "],["tibbles.html", "Chapter 11 Tibbles 11.1 创建 tibble 11.2 tibbles VS. data.frame 11.3 tibble 的转换", " Chapter 11 Tibbles 就像我们之前提到的那样，我们常常使用来自 tidyverse 的 tibbles，而不是 R 传统的 data.frame。Tibbles 是一种比 R 自带的 dataframe 更人性化更方便的数据集存储形式。 library(tidyverse) 11.1 创建 tibble 11.1.1 as_tibble() 我们使用 as_tibble() 来转化原有的 dataframe： as_tibble(iris) ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # ... with 140 more rows 11.1.2 tibble() 或者使用 tibble() 直接创建： tibble( x = 1:5, y = 1, z = x^2 + y ) ## # A tibble: 5 x 3 ## x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2 ## 2 2 1 5 ## 3 3 1 10 ## 4 4 1 17 ## 5 5 1 26 11.1.3 tribble() 这种方法真的优雅很多！就像你在书写 markdown 一样 ~ tribble( ~x, ~y, ~z, #--|--|--- &quot;a&quot;, 2, 3.6, &quot;b&quot;, 1, 8.5 ) ## # A tibble: 2 x 3 ## x y z ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a 2 3.6 ## 2 b 1 8.5 将符号或数字放在开头虽然墙裂不推荐，但 tibble 也不会报错： tb &lt;- tibble( `:)` = &quot;smile&quot;, # 注意使用 `` 来囊括 ` ` = &quot;space&quot;, `2000` = &quot;number&quot; ) tb ## # A tibble: 1 x 3 ## `:)` ` ` `2000` ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 smile space number 11.2 tibbles VS. data.frame 11.2.1 控制台打印方面 tibble( a = lubridate::now() + runif(1e3) * 86400, b = lubridate::today() + runif(1e3) * 30, c = 1:1e3, d = runif(1e3), e = sample(letters, 1e3, replace = TRUE) ) ## # A tibble: 1,000 x 5 ## a b c d e ## &lt;dttm&gt; &lt;date&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2022-06-04 02:48:27 2022-06-12 1 0.153 a ## 2 2022-06-04 07:29:15 2022-07-02 2 0.267 d ## 3 2022-06-03 23:46:42 2022-06-29 3 0.894 o ## 4 2022-06-03 22:24:34 2022-06-10 4 0.750 h ## 5 2022-06-04 15:36:02 2022-06-26 5 0.347 v ## 6 2022-06-04 11:23:45 2022-06-04 6 0.180 c ## 7 2022-06-04 00:32:22 2022-06-04 7 0.380 i ## 8 2022-06-04 04:06:08 2022-06-14 8 0.794 u ## 9 2022-06-03 22:17:31 2022-06-10 9 0.406 o ## 10 2022-06-04 17:47:13 2022-06-16 10 0.791 p ## # ... with 990 more rows tibble 对于太多的数据，只会显示前十行，不会让你的控制台被内容淹没；同时会显示每一列的数据类型。这得益于 str() 函数。 tibble 还完美兼容 print() 函数： nycflights13::flights %&gt;% print(n = 10, width = Inf) # Inf 表示无限，即所有指定内容（前十行）都打印 ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## arr_delay carrier flight tailnum origin dest air_time distance hour minute ## &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 11 UA 1545 N14228 EWR IAH 227 1400 5 15 ## 2 20 UA 1714 N24211 LGA IAH 227 1416 5 29 ## 3 33 AA 1141 N619AA JFK MIA 160 1089 5 40 ## 4 -18 B6 725 N804JB JFK BQN 183 1576 5 45 ## 5 -25 DL 461 N668DN LGA ATL 116 762 6 0 ## 6 12 UA 1696 N39463 EWR ORD 150 719 5 58 ## 7 19 B6 507 N516JB EWR FLL 158 1065 6 0 ## 8 -14 EV 5708 N829AS LGA IAD 53 229 6 0 ## 9 -8 B6 79 N593JB JFK MCO 140 944 6 0 ## 10 8 AA 301 N3ALAA LGA ORD 138 733 6 0 ## time_hour ## &lt;dttm&gt; ## 1 2013-01-01 05:00:00 ## 2 2013-01-01 05:00:00 ## 3 2013-01-01 05:00:00 ## 4 2013-01-01 05:00:00 ## 5 2013-01-01 06:00:00 ## 6 2013-01-01 05:00:00 ## 7 2013-01-01 06:00:00 ## 8 2013-01-01 06:00:00 ## 9 2013-01-01 06:00:00 ## 10 2013-01-01 06:00:00 ## # ... with 336,766 more rows 查看数据的另一种办法是使用 view() 函数，会更直观地显示在你的编辑器上。 nycflights13::flights %&gt;% head(10) %&gt;% view() # 请不要尝试展示太多数据！小心的的电脑炸掉（ 11.2.2 读取子元素方面 元数据建立如下： df &lt;- tibble( x = runif(5), y = rnorm(5) ) 按名字读取: df$x ## [1] 0.2920540 0.5917924 0.6708398 0.6261363 0.1283216 df[[&quot;x&quot;]] ## [1] 0.2920540 0.5917924 0.6708398 0.6261363 0.1283216 按序列位置读取： df[[1]] ## [1] 0.2920540 0.5917924 0.6708398 0.6261363 0.1283216 但如果使用管道符的话，我们需要使用 “.”： df %&gt;% .$x ## [1] 0.2920540 0.5917924 0.6708398 0.6261363 0.1283216 df %&gt;% .[[&quot;x&quot;]] ## [1] 0.2920540 0.5917924 0.6708398 0.6261363 0.1283216 11.3 tibble 的转换 上面提到使用 as_tibble() 将 data.frame 转换为 tibble，而 as.data.frame() 函数则是将 tibble 转化为 data.frame： class(as.data.frame(tb)) # class() 函数用于检查数据格式 ## [1] &quot;data.frame&quot; "],["data-import.html", "Chapter 12 Data import 12.1 简单读取文件 12.2 解析向量 12.3 数字类型 12.4 字符类型 12.5 因子类型 12.6 日期时间类型 12.7 解析文件 12.8 写入数据", " Chapter 12 Data import library(tidyverse) 12.1 简单读取文件 文件特征 函数 适用条件 符号分隔 read_csv() 逗号分隔 符号分隔 read_csv2() 分号分隔（常见于用作小数位的国家） 符号分隔 read_tsv() 制表符分隔 符号分隔 read_delim() 任何符号分隔 固定宽度 read_fwf() 固定宽度 固定宽度 fwf_widths() 宽度指定字段 固定宽度 fwf_positions() 位置指定字段 固定宽度 read_table() 固定宽度文件的常见变体，且列用空格分隔 日志 read_log() Apache 风格的日志文件 此外 webreadr 基于 read_log() 构建，并提供更多有用的工具。这些函数都有类似的语法：一旦我们掌握了一个，我们可以轻松地使用其他功能。 csv 文件是最常见的数据存储形式之一。我们将重点关注 read_csv()，其首个参数最为重要，即要读取的文件的路径。 read_csv() 会给出相当丰富的信息，包括行列数、分隔符、各列的数据格式（自动识别）等： heights &lt;- read_csv(&quot;./data/heights.csv&quot;) ## Rows: 1192 Columns: 6 ## -- Column specification ------------------------------------------------------------------ ## Delimiter: &quot;,&quot; ## chr (2): sex, race ## dbl (4): earn, height, ed, age ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. 对于内联表格我们同样可以这样处理： read_csv(&quot;a,b,c 1,2,3 4,5,6&quot;) ## Rows: 2 Columns: 3 ## -- Column specification ------------------------------------------------------------------ ## Delimiter: &quot;,&quot; ## dbl (3): a, b, c ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 2 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 6 如果内容的开头有一些不需要的数据，我们可以跳过开头的内容： read_csv(&quot;The first line of metadata The second line of metadata x,y,z 1,2,3&quot;, skip = 2) ## Rows: 1 Columns: 3 ## -- Column specification ------------------------------------------------------------------ ## Delimiter: &quot;,&quot; ## dbl (3): x, y, z ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 1 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 或者直接跳过以指定字符开头的行（如以 “#” 开头） read_csv(&quot;# A comment I want to skip x,y,z 1,2,3&quot;, comment = &quot;#&quot;) ## Rows: 1 Columns: 3 ## -- Column specification ------------------------------------------------------------------ ## Delimiter: &quot;,&quot; ## dbl (3): x, y, z ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 1 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 有时导入的数据可能没有表头！忽略掉表头，R 会为你加上 “X1”、“X2”… read_csv(&quot;1,2,3\\n4,5,6&quot;, col_names = FALSE) ## Rows: 2 Columns: 3 ## -- Column specification ------------------------------------------------------------------ ## Delimiter: &quot;,&quot; ## dbl (3): X1, X2, X3 ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 2 x 3 ## X1 X2 X3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 6 或者手动加表头： read_csv(&quot;1,2,3\\n4,5,6&quot;, col_names = c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;)) ## Rows: 2 Columns: 3 ## -- Column specification ------------------------------------------------------------------ ## Delimiter: &quot;,&quot; ## dbl (3): x, y, z ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 2 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 6 不只是表头，有时数据也会缺失。对 NA 值的数进行符号标记即可： read_csv(&quot;a,b,c\\n1,2,.&quot;, na = &quot;.&quot;) ## Rows: 1 Columns: 3 ## -- Column specification ------------------------------------------------------------------ ## Delimiter: &quot;,&quot; ## dbl (2): a, b ## lgl (1): c ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 1 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 1 2 NA 12.2 解析向量 在深入了解阅读器如何从磁盘读取文件之前，我们需要先了解 parse_*() 函数。对这些函数传入字符串向量，可以得到数据类型更专一合理的向量，如逻辑、整数或日期： str(parse_logical(c(&quot;TRUE&quot;, &quot;FALSE&quot;, &quot;NA&quot;))) # str() 用于显示 R 对象的内部结构 ## logi [1:3] TRUE FALSE NA str(parse_integer(c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;))) ## int [1:3] 1 2 3 str(parse_date(c(&quot;2010-01-01&quot;, &quot;1979-10-14&quot;))) ## Date[1:2], format: &quot;2010-01-01&quot; &quot;1979-10-14&quot; 我们也可以设置缺省值： parse_integer(c(&quot;1&quot;, &quot;231&quot;, &quot;.&quot;, &quot;456&quot;), na = &quot;.&quot;) ## [1] 1 231 NA 456 解析失败会提示相关警示： x &lt;- parse_integer(c(&quot;123&quot;, &quot;345&quot;, &quot;abc&quot;, &quot;123.45&quot;)) #&gt; Warning: 2 parsing failures. #&gt; row col expected actual #&gt; 3 -- an integer abc #&gt; 4 -- no trailing characters 123.45 之后的读取也会报错： x #&gt; [1] 123 345 NA NA #&gt; attr(,&quot;problems&quot;) #&gt; # A tibble: 2 x 4 #&gt; row col expected actual #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 NA an integer abc #&gt; 2 4 NA no trailing characters 123.45 和提示的一样，我们可以使用 problems() 函数显示错误根源： problems(x) #&gt; # A tibble: 2 x 4 #&gt; row col expected actual #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 NA an integer abc #&gt; 2 4 NA no trailing characters 123.45 12.3 数字类型 不同国家地区使用的分隔符、习惯等都不相同。所以这里有 locale 参数用来处理。如： 小数点标识符（decimal_mark）： parse_double(&quot;1.23&quot;) ## [1] 1.23 parse_double(&quot;1,23&quot;, locale = locale(decimal_mark = &quot;,&quot;)) # 改用 “,” 识别 ## [1] 1.23 数字前后非数字字符： parse_number(&quot;$100&quot;) ## [1] 100 parse_number(&quot;20%&quot;) ## [1] 20 parse_number(&quot;It cost $123.45&quot;) ## [1] 123.45 位数标记（grouping_mark）： parse_number(&quot;$123,456,789&quot;) ## [1] 123456789 parse_number(&quot;123.456.789&quot;, locale = locale(grouping_mark = &quot;.&quot;)) # 常见于欧洲 ## [1] 123456789 parse_number(&quot;123&#39;456&#39;789&quot;, locale = locale(grouping_mark = &quot;&#39;&quot;)) # 常见于瑞士 ## [1] 123456789 12.4 字符类型 貌似 parse_character() 是只会返回输入的无用函数。但事实上，我们有多种方式来表示同一字符串。要了解 R 中如何表示字符串的细节，我们可以使用 charToRaw() 获得字符串的底层表示： charToRaw(&quot;Hadley&quot;) ## [1] 48 61 64 6c 65 79 像这样，从十六进制数字到字符的映射的编码称为 ASCII，也是美国信息交换标准代码。但英语以外的编码就非常复杂了，用不同编码读取数据，他们将完全不同。 如今我们有一个通用标准：UTF-8。UTF-8几乎可以编码当今人类使用的每个字符，以及许多额外的符号。 但旧的非通用标准有时也是需要的： (x1 &lt;- &quot;El Ni\\xf1o was particularly bad this year&quot;) ## [1] &quot;El Ni駉 was particularly bad this year&quot; (x2 &lt;- &quot;\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd&quot;) ## [1] &quot;偙傫偵偪偼&quot; 使用 encoding 来转译它们的编码： parse_character(x1, locale = locale(encoding = &quot;Latin1&quot;)) ## [1] &quot;El Ni&lt;U+00F1&gt;o was particularly bad this year&quot; parse_character(x2, locale = locale(encoding = &quot;Shift-JIS&quot;)) ## [1] &quot;こんにちは&quot; 有时我们并不知道它是什么类型的编码！所幸的是，guess_encodeing() 会帮助我们尝试： guess_encoding(charToRaw(x1)) ## # A tibble: 2 x 2 ## encoding confidence ## &lt;chr&gt; &lt;dbl&gt; ## 1 ISO-8859-1 0.46 ## 2 ISO-8859-9 0.23 guess_encoding(charToRaw(x2)) ## # A tibble: 1 x 2 ## encoding confidence ## &lt;chr&gt; &lt;dbl&gt; ## 1 KOI8-R 0.42 12.5 因子类型 R 使用因子来表示具有一组已知可能值的分类变量。给 parse_factor() 一个已知 levels 的向量，以便在出现意外值时生成警告： fruit &lt;- c(&quot;apple&quot;, &quot;banana&quot;) parse_factor(c(&quot;apple&quot;, &quot;banana&quot;, &quot;bananana&quot;), levels = fruit) #&gt; Warning: 1 parsing failure. #&gt; row col expected actual #&gt; 3 -- value in level set bananana #&gt; [1] apple banana &lt;NA&gt; #&gt; attr(,&quot;problems&quot;) #&gt; # A tibble: 1 x 4 #&gt; row col expected actual #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 3 NA value in level set bananana #&gt; Levels: apple banana 12.6 日期时间类型 我们可以根据想要的日期（自1970-01-01以来的天数）、日期时间（自1970-01-01年以来的秒数）或时间（自午夜以来的秒数），在三个解析器之间进行选择。当在没有任何其他参数的情况下调用时： parse_datetime() 根据 ISO8601 国际标准转换日期时间： parse_datetime(&quot;2010-10-01T2010&quot;) ## [1] &quot;2010-10-01 20:10:00 UTC&quot; # If time is omitted, it will be set to midnight parse_datetime(&quot;20101010&quot;) ## [1] &quot;2010-10-10 UTC&quot; parse_date() 用于转换四位数年份，使用 “-” 或 “/” 都可（但没有分隔符则会报错）： parse_date(&quot;2010-10-01&quot;) ## [1] &quot;2010-10-01&quot; parse_time() 用于转换时分秒（秒和上下午可选）： library(hms) # R 不自带，我们需要调用 hms 包（tidyverse 的 readr 包也有） parse_time(&quot;01:10 am&quot;) ## 01:10:00 parse_time(&quot;20:10:01&quot;) ## 20:10:01 此外日期时间字符串形式可以自己制定： 类型 表示符 备注 示例 年 %Y 4位数字 年 %y 2位数字 00-69 -&gt; 2000-2069 月 %m 2位数字 月 %b 缩写 Jan 月 %B 全称 一月 日 %d 2位数字 日 %e optional leading space 时 %H 0-23小时 时 %I 0-12小时，与 %p 捆绑使用 上下午 %p AM/PM 分 %M 分钟 秒 %S 整数秒 秒 %OS 真正意义的秒 时区 %Z 时区（名称） America/Chicago 标准时区 %z 以 UTC 标准时区做偏移量 +0800 非数字 %. 跳过一个非数字字符 非数字 %* 跳过任意数量的非数字 例如： parse_date(&quot;01/02/15&quot;, &quot;%m/%d/%y&quot;) ## [1] &quot;2015-01-02&quot; parse_date(&quot;01/02/15&quot;, &quot;%d/%m/%y&quot;) ## [1] &quot;2015-02-01&quot; parse_date(&quot;01/02/15&quot;, &quot;%y/%m/%d&quot;) ## [1] &quot;2001-02-15&quot; 如果将 %b 或 %B 与非英语的月份名称一起使用，则需要将 lang 参数设置为 locale()。使用函数 date_names_langs() 查看内置语言列表，或者使用 date_names() 自定义。 parse_date(&quot;1 janvier 2015&quot;, &quot;%d %B %Y&quot;, locale = locale(&quot;fr&quot;)) ## [1] &quot;2015-01-01&quot; 12.7 解析文件 12.7.1 自动匹配 readr 一般读取前 1000 行，并使用一些 “启发式” 的方法（保持适度保守）来确定每列的类型。其中 guess_parser() 返回字符向量的最佳类型猜测，而 parse_guess() 返回用该类型解析的内容： guess_parser(&quot;2010-10-01&quot;) ## [1] &quot;date&quot; guess_parser(&quot;15:01&quot;) ## [1] &quot;time&quot; guess_parser(c(&quot;TRUE&quot;, &quot;FALSE&quot;)) ## [1] &quot;logical&quot; guess_parser(c(&quot;1&quot;, &quot;5&quot;, &quot;9&quot;)) ## [1] &quot;double&quot; guess_parser(c(&quot;12,352,561&quot;)) ## [1] &quot;number&quot; str(parse_guess(&quot;2010-10-10&quot;)) ## Date[1:1], format: &quot;2010-10-10&quot; 这种 “启发式” 尝试以下每种类型，并在找到满足匹配项时停止： - 逻辑值：仅包含 “F”、“T”、“FALSE” 或 “TRUE”。 - 整数：仅包含数字字符（可能还有 “-”）。 - 小数：仅包含有效的小数（可能还有 4.5e-5 等数字）。 - 数字：包含有效的小数类型（可能还有分组标记）。 - 时间：与默认的 time_format 匹配。 - 日期：与默认的 date_format 匹配。 - 日期时间：任何满足 ISO8601 格式的日期时间。如果这些规则都不适用，那么该列将保持字符串向量。 12.7.2 自动匹配遇到的问题 在学习这里的时候发现问题已经无法复现。此处已经不再报错 challenge &lt;- read_csv(readr_example(&quot;challenge.csv&quot;)) #&gt; ── Column specification ─────────────────────────────────────────── #&gt; cols( #&gt; x = col_double(), #&gt; y = col_logical() #&gt; ) #&gt; Warning: 1000 parsing failures. #&gt; row col expected actual file #&gt; 1001 y 1/0/T/F/TRUE/FALSE 2015-01-16 &#39;/Users/runner/work/_temp/… #&gt; 1002 y 1/0/T/F/TRUE/FALSE 2018-05-18 &#39;/Users/runner/work/_temp/… #&gt; 1003 y 1/0/T/F/TRUE/FALSE 2015-09-05 &#39;/Users/runner/work/_temp/… #&gt; 1004 y 1/0/T/F/TRUE/FALSE 2012-11-28 &#39;/Users/runner/work/_temp/… #&gt; 1005 y 1/0/T/F/TRUE/FALSE 2020-01-13 &#39;/Users/runner/work/_temp/… #&gt; .... ... .................. .......... .........................… #&gt; See problems(...) for more details. 我们决定对错误进行定位： problems(challenge) #&gt; # A tibble: 1,000 x 5 #&gt; row col expected actual file #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1001 y 1/0/T/F/TRUE/F… 2015-01… &#39;/Users/runner/work/_temp/… #&gt; 2 1002 y 1/0/T/F/TRUE/F… 2018-05… &#39;/Users/runner/work/_temp/… #&gt; 3 1003 y 1/0/T/F/TRUE/F… 2015-09… &#39;/Users/runner/work/_temp/… #&gt; 4 1004 y 1/0/T/F/TRUE/F… 2012-11… &#39;/Users/runner/work/_temp/… #&gt; 5 1005 y 1/0/T/F/TRUE/F… 2020-01… &#39;/Users/runner/work/_temp/… #&gt; 6 1006 y 1/0/T/F/TRUE/F… 2016-04… &#39;/Users/runner/work/_temp/… #&gt; # … with 994 more rows 嗯…怎么看了跟没看似的。tail() 函数用来查看表头或表尾： tail(challenge) #&gt; # A tibble: 6 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;lgl&gt; #&gt; 1 0.805 NA #&gt; 2 0.164 NA #&gt; 3 0.472 NA #&gt; 4 0.718 NA #&gt; 5 0.270 NA #&gt; 6 0.608 NA 这表明我们需要手动对数据进行解析： challenge &lt;- read_csv( readr_example(&quot;challenge.csv&quot;), col_types = cols( # 对列类型进行手动声明 x = col_double(), # 第一列为 x，小数类型 y = col_logical() # 第二列为 y，逻辑值类型 ) ) ## Warning: One or more parsing issues, see `problems()` for details challenge &lt;- read_csv( readr_example(&quot;challenge.csv&quot;), col_types = cols( x = col_double(), y = col_date() ) ) tail(challenge) ## # A tibble: 6 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 0.805 2019-11-21 ## 2 0.164 2018-03-29 ## 3 0.472 2014-08-04 ## 4 0.718 2015-08-16 ## 5 0.270 2020-02-04 ## 6 0.608 2019-01-06 col_types 是有必要的，这至少能确保它生成的数据更为可靠一些。 12.7.3 其他的匹配解决策略 上面提到的自动解析出错只是因为默认的 1000 行不够用而已。哪怕只是多解析一行： challenge2 &lt;- read_csv(readr_example(&quot;challenge.csv&quot;), guess_max = 1001) ## Rows: 2000 Columns: 2 ## -- Column specification ------------------------------------------------------------------ ## Delimiter: &quot;,&quot; ## dbl (1): x ## date (1): y ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. challenge2 ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows 你看。问题解决了呢。 另外一种思路是将向量声明为默认字符类型向量，这可能使你的定位更容易一些： challenge2 &lt;- read_csv(readr_example(&quot;challenge.csv&quot;), col_types = cols(.default = col_character()) ) 这里用简单的数据集演示 type_convert() 的效果： df &lt;- tribble( ~x, ~y, &quot;1&quot;, &quot;1.21&quot;, &quot;2&quot;, &quot;2.32&quot;, &quot;3&quot;, &quot;4.56&quot; ) df ## # A tibble: 3 x 2 ## x y ## &lt;chr&gt; &lt;chr&gt; ## 1 1 1.21 ## 2 2 2.32 ## 3 3 4.56 type_convert(df) ## ## -- Column specification ------------------------------------------------------------------ ## cols( ## x = col_double(), ## y = col_double() ## ) ## # A tibble: 3 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.21 ## 2 2 2.32 ## 3 3 4.56 可以看到 “启发性” 转换到底转换成了什么类型。 12.8 写入数据 12.8.1 csv 格式 write_csv(challenge, &quot;./data/challenge.csv&quot;) 很简单，不是吗？小心事情还没结束。你看，数据类型就这么丢了： challenge ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows write_csv(challenge, &quot;./data/challenge-2.csv&quot;) read_csv(&quot;./data/challenge-2.csv&quot;) ## Rows: 2000 Columns: 2 ## -- Column specification ------------------------------------------------------------------ ## Delimiter: &quot;,&quot; ## dbl (1): x ## date (1): y ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows 12.8.2 rds 格式 为了解决这个问题，我们提出了新的函数：write_rds() 和 read_rds() 基于 R 的基本函数 readRDS() 和 saveRDS()。注意这些数据会以被 R 称为 RDS 格式的自定义二进制格式存储数据： write_rds(challenge, &quot;./data/challenge.rds&quot;) read_rds(&quot;./data/challenge.rds&quot;) ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows 表现非常好，但 rds 格式不流行也不通用。 12.8.3 feather 格式 feather 包也实现了一种快速的二进制文件格式，可以跨编程语言共享： library(feather) ## Warning: 程辑包&#39;feather&#39;是用R版本4.1.3 来建造的 write_feather(challenge, &quot;./data/challenge.feather&quot;) read_feather(&quot;./data/challenge.feather&quot;) ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows 12.8.4 其他格式 其他的一些常见格式也支持。事实上所有已知格式，在社区包的帮助下，通常都能解决。下面是一些常见格式： haven：读取 SPSS、Stata 和 SAS 文件。 readxl：读取 excel 文件（包括.xls和.xlsx）。 DBI：DBI 和一些特定数据库的后端（如 RMySQL、RSQLite、RPostgreSQL 等）。 "],["tidy-data.html", "Chapter 13 Tidy data 13.1 对 table1 数据分析 13.2 对 table2 数据整理 13.3 对 table3 数据整理 13.4 对 table4a &amp; table4b 数据整理 13.5 对 table5 数据整理 13.6 对 stocks 和 treatment 的缺失数据处理 13.7 对 who 数据整理", " Chapter 13 Tidy data 一个好的数据集应该：变量在列中，观察结果在行中，值储存在单元格中；不整洁的数据，我们可以用 tidyr 包中的 pivot_longer() 和 pivot_wider() 辅助修正 library(tidyverse) 13.1 对 table1 数据分析 table1 数据集中 cases 为增长人数（单位：万）。这份数据展现得很不错，我们可以轻松绘制想要的图像。 table1 #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 ggplot(table1, aes(year, cases)) + geom_line(aes(group = country, colour = country)) + geom_point(aes(colour = country)) 13.2 对 table2 数据整理 行中不应该出现将 cases 和 population 放在一起的现象。它们应该作为筛选变量，方便后续对 “新增” “目前总人数” 这个两个变量进行分析，即 type 拆分为列，count 跟随到新列： table2 #&gt; # A tibble: 12 x 4 #&gt; country year type count #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 cases 745 #&gt; 2 Afghanistan 1999 population 19987071 #&gt; 3 Afghanistan 2000 cases 2666 #&gt; 4 Afghanistan 2000 population 20595360 #&gt; 5 Brazil 1999 cases 37737 #&gt; 6 Brazil 1999 population 172006362 #&gt; 7 Brazil 2000 cases 80488 #&gt; 8 Brazil 2000 population 174504898 #&gt; 9 China 1999 cases 212258 #&gt; 10 China 1999 population 1272915272 #&gt; 11 China 2000 cases 213766 #&gt; 12 China 2000 population 1280428583 table2 %&gt;% pivot_wider(names_from = type, values_from = count) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 13.3 对 table3 数据整理 行中不应该出现将 cases 和 population 放在一起的现象，需要手动拆分： table3 #&gt; # A tibble: 6 x 3 #&gt; country year rate #&gt; * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745/19987071 #&gt; 2 Afghanistan 2000 2666/20595360 #&gt; 3 Brazil 1999 37737/172006362 #&gt; 4 Brazil 2000 80488/174504898 #&gt; 5 China 1999 212258/1272915272 #&gt; 6 China 2000 213766/1280428583 # 默认情况下，将在看到非字母数字字符（即不是数字或字母的字符）的位置拆分值 table3 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;)) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 # convert 可以自动将数据的格式进行转化。如这里的 cases 和 population 都应该是 int 类型数据 table3 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), convert = TRUE) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 # 分隔符也可以手动设置 table3 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 # 设置为数字表示分割位置，如这里分割为世纪 + 两位数年 table3 %&gt;% separate(year, into = c(&quot;century&quot;, &quot;year&quot;), sep = 2) #&gt; # A tibble: 6 x 4 #&gt; country century year rate #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 19 99 745/19987071 #&gt; 2 Afghanistan 20 00 2666/20595360 #&gt; 3 Brazil 19 99 37737/172006362 #&gt; 4 Brazil 20 00 80488/174504898 #&gt; 5 China 19 99 212258/1272915272 #&gt; 6 China 20 00 213766/1280428583 13.4 对 table4a &amp; table4b 数据整理 列中不应该出现将 1999 和 2000 分开的现象。它们应该作为筛选变量，方便后续对 “年份” 这个总变量进行分析，即旧变量合并为 year，值合并为 cases： table4a_new &lt;- table4a %&gt;% pivot_longer( c(`1999`, `2000`), # 指定修改列。注意这里变量是以数字开头，所以有必要用 `` 引用（当然数字开头是不规范的） names_to = &quot;year&quot;, # 上述变量名汇总到 year 上 values_to = &quot;cases&quot; # 上述对应数值汇总到 cases 上 ) table4b_new &lt;- table4b %&gt;% pivot_longer( c(`1999`, `2000`), names_to = &quot;year&quot;, values_to = &quot;population&quot; ) # 最后合并两个表的数据内容 #* dplyr::left_join() left_join(table4a_new, table4b_new) #&gt; Joining, by = c(&quot;country&quot;, &quot;year&quot;) #&gt; # A tibble: 6 x 4 #&gt; country year cases population #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 13.5 对 table5 数据整理 我们需要手动拆分 cases 和 population 同时要将年份数据进行合并： table5 %&gt;% # 注意如果不声明 sep，默认加间隔符号 “_”！ unite(year_4cs, century, year, sep = &quot;&quot;, na.rm = TRUE) %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;), sep = &quot;/&quot;) #&gt; # A tibble: 6 x 4 #&gt; country year_4cs cases population #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Afghanistan 1999 745 19987071 #&gt; 2 Afghanistan 2000 2666 20595360 #&gt; 3 Brazil 1999 37737 172006362 #&gt; 4 Brazil 2000 80488 174504898 #&gt; 5 China 1999 212258 1272915272 #&gt; 6 China 2000 213766 1280428583 13.6 对 stocks 和 treatment 的缺失数据处理 stocks &lt;- tibble( year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016), qtr = c(1, 2, 3, 4, 2, 3, 4), return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66) ) new_stocks &lt;- stocks %&gt;% # 拆分成按年作列 pivot_wider(names_from = year, values_from = return) %&gt;% # 重新整理回去。注意表格是怎么整理的 pivot_longer( cols = c(`2015`, `2016`), names_to = &quot;year&quot;, values_to = &quot;return&quot;, values_drop_na = TRUE # 这会对含 NA 的数据行剔除隐藏 ) %&gt;% print() #&gt; # A tibble: 6 x 3 #&gt; qtr year return #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 2015 1.88 #&gt; 2 2 2015 0.59 #&gt; 3 2 2016 0.92 #&gt; 4 3 2015 0.35 #&gt; 5 3 2016 0.17 #&gt; 6 4 2016 2.66 new_stocks %&gt;% complete(year, qtr) # 这会把所有隐藏的 NA 数据重新找回 #&gt; # A tibble: 8 x 3 #&gt; year qtr return #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2015 1 1.88 #&gt; 2 2015 2 0.59 #&gt; 3 2015 3 0.35 #&gt; 4 2015 4 NA #&gt; 5 2016 1 NA #&gt; 6 2016 2 0.92 #&gt; 7 2016 3 0.17 #&gt; 8 2016 4 2.66 treatment &lt;- tribble( ~person, ~treatment, ~response, &quot;Derrick Whitmore&quot;, 1, 7, NA, 2, 10, NA, 3, 9, &quot;Katherine Burke&quot;, 1, 4 ) treatment %&gt;% fill(person) # 对 treatment 的 person 列进行补全处理，碰到 NA 时会将 NA 改为上一个不是 NA 的数据 #&gt; # A tibble: 4 x 3 #&gt; person treatment response #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Derrick Whitmore 1 7 #&gt; 2 Derrick Whitmore 2 10 #&gt; 3 Derrick Whitmore 3 9 #&gt; 4 Katherine Burke 1 4 13.7 对 who 数据整理 who 是一个流行病统计数据集。 who #&gt; # A tibble: 7,240 x 60 #&gt; country iso2 iso3 year new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544 #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Afghani~ AF AFG 1980 NA NA NA NA #&gt; 2 Afghani~ AF AFG 1981 NA NA NA NA #&gt; 3 Afghani~ AF AFG 1982 NA NA NA NA #&gt; 4 Afghani~ AF AFG 1983 NA NA NA NA #&gt; 5 Afghani~ AF AFG 1984 NA NA NA NA #&gt; 6 Afghani~ AF AFG 1985 NA NA NA NA #&gt; 7 Afghani~ AF AFG 1986 NA NA NA NA #&gt; 8 Afghani~ AF AFG 1987 NA NA NA NA #&gt; 9 Afghani~ AF AFG 1988 NA NA NA NA #&gt; 10 Afghani~ AF AFG 1989 NA NA NA NA #&gt; # ... with 7,230 more rows, and 52 more variables: new_sp_m4554 &lt;int&gt;, #&gt; # new_sp_m5564 &lt;int&gt;, new_sp_m65 &lt;int&gt;, new_sp_f014 &lt;int&gt;, #&gt; # new_sp_f1524 &lt;int&gt;, new_sp_f2534 &lt;int&gt;, new_sp_f3544 &lt;int&gt;, #&gt; # new_sp_f4554 &lt;int&gt;, new_sp_f5564 &lt;int&gt;, new_sp_f65 &lt;int&gt;, #&gt; # new_sn_m014 &lt;int&gt;, new_sn_m1524 &lt;int&gt;, new_sn_m2534 &lt;int&gt;, #&gt; # new_sn_m3544 &lt;int&gt;, new_sn_m4554 &lt;int&gt;, new_sn_m5564 &lt;int&gt;, #&gt; # new_sn_m65 &lt;int&gt;, new_sn_f014 &lt;int&gt;, new_sn_f1524 &lt;int&gt;, ... who1 &lt;- who %&gt;% pivot_longer( cols = new_sp_m014:newrel_f65, # 将病症的种类转换成变量（key） names_to = &quot;key&quot;, values_to = &quot;cases&quot;, # 将数据转换成 cases 列 values_drop_na = TRUE # 删除 NA 数据 ) who1 #&gt; # A tibble: 76,046 x 6 #&gt; country iso2 iso3 year key cases #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 new_sp_m014 0 #&gt; 2 Afghanistan AF AFG 1997 new_sp_m1524 10 #&gt; 3 Afghanistan AF AFG 1997 new_sp_m2534 6 #&gt; 4 Afghanistan AF AFG 1997 new_sp_m3544 3 #&gt; 5 Afghanistan AF AFG 1997 new_sp_m4554 5 #&gt; 6 Afghanistan AF AFG 1997 new_sp_m5564 2 #&gt; 7 Afghanistan AF AFG 1997 new_sp_m65 0 #&gt; 8 Afghanistan AF AFG 1997 new_sp_f014 5 #&gt; 9 Afghanistan AF AFG 1997 new_sp_f1524 38 #&gt; 10 Afghanistan AF AFG 1997 new_sp_f2534 36 #&gt; # ... with 76,036 more rows count(who1, key, sort = TRUE) # 对不同病症人数统计 #&gt; # A tibble: 56 x 2 #&gt; key n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 new_sp_m4554 3223 #&gt; 2 new_sp_m3544 3219 #&gt; 3 new_sp_m5564 3218 #&gt; 4 new_sp_m1524 3209 #&gt; 5 new_sp_m65 3209 #&gt; 6 new_sp_m2534 3206 #&gt; 7 new_sp_f4554 3204 #&gt; 8 new_sp_f2534 3200 #&gt; 9 new_sp_f3544 3199 #&gt; 10 new_sp_f65 3197 #&gt; # ... with 46 more rows 对病症名称进行分析得知： 前三个字母：是否包含新的或旧的结核病例 中间两个字母：结核病的类型 rel：复发病例 ep：肺外结核病例 sn：无法通过肺涂片诊断的肺结核病例（涂片阴性） sp：可通过肺涂片诊断的肺结核病例（涂片阳性） 第六个字母：结核病患者的性别。其中 m 为男性，f 为女性 最后的数字：年龄组 014：0 ~ 14 岁 1524：15 ~ 24 岁 2534：25 ~ 34 岁 3544：35 ~ 44 岁 4554：45 ~ 54 岁 5564：55 ~ 64岁 65：65 岁或以上 who2 &lt;- who1 %&gt;% # 使用 stringr 的 str_replace 可以进行简单的替换（当然切割时使用位置切割也可以） mutate(key = stringr::str_replace(key, &quot;newrel&quot;, &quot;new_rel&quot;)) %&gt;% # 通过字符串 “_” 分割为是否包含新病例、结核病类型和性别年龄 separate(key, c(&quot;new&quot;, &quot;type&quot;, &quot;sexage&quot;), sep = &quot;_&quot;) %&gt;% # 通过位置继续分割性别和年龄 separate(sexage, c(&quot;sex&quot;, &quot;age&quot;), sep = 1) who2 #&gt; # A tibble: 76,046 x 9 #&gt; country iso2 iso3 year new type sex age cases #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan AF AFG 1997 new sp m 014 0 #&gt; 2 Afghanistan AF AFG 1997 new sp m 1524 10 #&gt; 3 Afghanistan AF AFG 1997 new sp m 2534 6 #&gt; 4 Afghanistan AF AFG 1997 new sp m 3544 3 #&gt; 5 Afghanistan AF AFG 1997 new sp m 4554 5 #&gt; 6 Afghanistan AF AFG 1997 new sp m 5564 2 #&gt; 7 Afghanistan AF AFG 1997 new sp m 65 0 #&gt; 8 Afghanistan AF AFG 1997 new sp f 014 5 #&gt; 9 Afghanistan AF AFG 1997 new sp f 1524 38 #&gt; 10 Afghanistan AF AFG 1997 new sp f 2534 36 #&gt; # ... with 76,036 more rows 深度观察，我们会发现数据还有进一步的优化空间： count(who2, new) # 可以发现这个数据集的 “是否包含新病例” 值其实全部都是 “new”，所以是不必要的数据 #&gt; # A tibble: 1 x 2 #&gt; new n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 new 76046 # 同时 “iso2” 和 “iso3” 是国家缩写，也是不需要的数据 who3 &lt;- who2 %&gt;% select(-new, -iso2, -iso3) who3 #&gt; # A tibble: 76,046 x 6 #&gt; country year type sex age cases #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Afghanistan 1997 sp m 014 0 #&gt; 2 Afghanistan 1997 sp m 1524 10 #&gt; 3 Afghanistan 1997 sp m 2534 6 #&gt; 4 Afghanistan 1997 sp m 3544 3 #&gt; 5 Afghanistan 1997 sp m 4554 5 #&gt; 6 Afghanistan 1997 sp m 5564 2 #&gt; 7 Afghanistan 1997 sp m 65 0 #&gt; 8 Afghanistan 1997 sp f 014 5 #&gt; 9 Afghanistan 1997 sp f 1524 38 #&gt; 10 Afghanistan 1997 sp f 2534 36 #&gt; # ... with 76,036 more rows "],["relational-data.html", "Chapter 14 Relational data 14.1 理解合并数据概念 14.2 理解多种数据合并方式 14.3 设置操作 14.4 合并 nycflights 数据并分析", " Chapter 14 Relational data 一对表格之间总是存在定义关系。要处理关系数据，我们需要与一对表一起工作的动词。有三家族动词设计用于处理关系数据： 突变连接，它从另一个数据帧的匹配观测中向一个数据帧添加新变量。 过滤连接，根据它们是否与另一个表中的观察结果匹配，从一个数据帧过滤观测结果。 集合操作，将观察视为集合元素。 library(tidyverse) library(nycflights13) 14.1 理解合并数据概念 14.1.1 类型1：没有重复问题 x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 3, &quot;x3&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 4, &quot;y3&quot; ) 内联（inner-join）：只观察共同包含的数据（交集）。事实上因为会丢掉不匹配的数据，所以不便于分析。 inner_join(x, y, by = &quot;key&quot;) #&gt; # A tibble: 2 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 外联（left-join、right-join、full-join）：共三种连接方式语句。 left_join(x, y, by = &quot;key&quot;) # 左连接，保留左侧丢掉右侧不匹配的数据 #&gt; # A tibble: 3 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 3 x3 &lt;NA&gt; right_join(x, y, by = &quot;key&quot;) # 右连接，保留右侧丢掉左侧不匹配的数据 #&gt; # A tibble: 3 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 4 &lt;NA&gt; y3 full_join(x, y, by = &quot;key&quot;) # 全连接，保留全部数据，哪怕不互相匹配 #&gt; # A tibble: 4 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 3 x3 &lt;NA&gt; #&gt; 4 4 &lt;NA&gt; y3 匹配演算（semi_join、anti_join）：事实上匹配并不会做数据合并，只是把左侧数据做筛选。 semi_join(x, y, by = &quot;key&quot;) # 半连接，对左侧数据筛选出右侧数据能匹配的数据 #&gt; # A tibble: 2 x 2 #&gt; key val_x #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 1 x1 #&gt; 2 2 x2 anti_join(x, y, by = &quot;key&quot;) # 反连接，对左侧数据排除掉右侧数据能匹配的数据 #&gt; # A tibble: 1 x 2 #&gt; key val_x #&gt; &lt;dbl&gt; &lt;chr&gt; #&gt; 1 3 x3 14.1.2 类型2：一边有重复问题 x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 2, &quot;x3&quot;, 1, &quot;x4&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot; ) 事实上下面两种模式结果相同： left_join(x, y, by = &quot;key&quot;) # 左边所有列都从右边寻求 #&gt; # A tibble: 4 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 2 x3 y2 #&gt; 4 1 x4 y1 right_join(x, y, by = &quot;key&quot;) # 右边所有列都从左边寻求（一对多时全保留） #&gt; # A tibble: 4 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 2 x3 y2 #&gt; 4 1 x4 y1 14.1.3 类型3：两边都有重复问题 x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 2, &quot;x3&quot;, 3, &quot;x4&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 2, &quot;y3&quot;, 3, &quot;y4&quot; ) 左边某列对应到右边出现多个结果时会新增列去对应： left_join(x, y, by = &quot;key&quot;) #&gt; # A tibble: 6 x 3 #&gt; key val_x val_y #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 1 x1 y1 #&gt; 2 2 x2 y2 #&gt; 3 2 x2 y3 #&gt; 4 2 x3 y2 #&gt; 5 2 x3 y3 #&gt; 6 3 x4 y4 14.2 理解多种数据合并方式 事实上，四大 join 相关依赖包 dplyr，我们也可以用 r 原生自带的 base::merge 实现： dplyr 语句 对应的 merge 语句 解释 inner_join(x, y) merge(x, y) 匹配不上的均不保留 left_join(x, y) merge(x, y, all.x = TRUE) 保留所有的 x right_join(x, y) merge(x, y, all.y = TRUE), 保留所有的 y full_join(x, y) merge(x, y, all.x = TRUE, all.y = TRUE) 保留所有的 x 和 y 14.3 设置操作 intersect、union 和 setdiff 用于对不同表格的差异进行挖掘： df1 &lt;- tribble( ~x, ~y, 1, 1, 2, 1 ) df2 &lt;- tribble( ~x, ~y, 1, 1, 1, 2 ) intersect(df1, df2) # 返回两者共同的数据集 #&gt; # A tibble: 1 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 union(df1, df2) # 合并两个数据集的数据（相同的只做一次记录） #&gt; # A tibble: 3 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 #&gt; 2 2 1 #&gt; 3 1 2 setdiff(df1, df2) # 返回前者观察到的后者所没有的差异部分 #&gt; # A tibble: 1 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 1 setdiff(df2, df1) #&gt; # A tibble: 1 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2 14.4 合并 nycflights 数据并分析 仔细观察 nycflights 不难发现，里面包含 airlines、airports、planes 和 weather，以及我们常用的 flights 数据集。 airlines 允许您从其缩写代码中查找完整的运营商名称： airlines #&gt; # A tibble: 16 x 2 #&gt; carrier name #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 9E Endeavor Air Inc. #&gt; 2 AA American Airlines Inc. #&gt; 3 AS Alaska Airlines Inc. #&gt; 4 B6 JetBlue Airways #&gt; 5 DL Delta Air Lines Inc. #&gt; 6 EV ExpressJet Airlines Inc. #&gt; 7 F9 Frontier Airlines Inc. #&gt; 8 FL AirTran Airways Corporation #&gt; 9 HA Hawaiian Airlines Inc. #&gt; 10 MQ Envoy Air #&gt; 11 OO SkyWest Airlines Inc. #&gt; 12 UA United Air Lines Inc. #&gt; 13 US US Airways Inc. #&gt; 14 VX Virgin America #&gt; 15 WN Southwest Airlines Co. #&gt; 16 YV Mesa Airlines Inc. airports 提供有关每个机场的信息，由 faa 机场代码标识： airports #&gt; # A tibble: 1,458 x 8 #&gt; faa name lat lon alt tz dst tzone #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 04G Lansdowne Airport 41.1 -80.6 1044 -5 A America/~ #&gt; 2 06A Moton Field Municipal Airport 32.5 -85.7 264 -6 A America/~ #&gt; 3 06C Schaumburg Regional 42.0 -88.1 801 -6 A America/~ #&gt; 4 06N Randall Airport 41.4 -74.4 523 -5 A America/~ #&gt; 5 09J Jekyll Island Airport 31.1 -81.4 11 -5 A America/~ #&gt; 6 0A9 Elizabethton Municipal Airport 36.4 -82.2 1593 -5 A America/~ #&gt; 7 0G6 Williams County Airport 41.5 -84.5 730 -5 A America/~ #&gt; 8 0G7 Finger Lakes Regional Airport 42.9 -76.8 492 -5 A America/~ #&gt; 9 0P2 Shoestring Aviation Airfield 39.8 -76.6 1000 -5 U America/~ #&gt; 10 0S9 Jefferson County Intl 48.1 -123. 108 -8 A America/~ #&gt; # ... with 1,448 more rows planes 提供有关每个平面的信息，由其 tailnum 标识： planes #&gt; # A tibble: 3,322 x 9 #&gt; tailnum year type manufacturer model engines seats speed engine #&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 N10156 2004 Fixed wing multi~ EMBRAER EMB-~ 2 55 NA Turbo~ #&gt; 2 N102UW 1998 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 3 N103US 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 4 N104UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 5 N10575 2002 Fixed wing multi~ EMBRAER EMB-~ 2 55 NA Turbo~ #&gt; 6 N105UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 7 N107US 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 8 N108UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 9 N109UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; 10 N110UW 1999 Fixed wing multi~ AIRBUS INDU~ A320~ 2 182 NA Turbo~ #&gt; # ... with 3,312 more rows weather 则给出了每个纽约机场每小时的天气： weather #&gt; # A tibble: 26,115 x 15 #&gt; origin year month day hour temp dewp humid wind_dir wind_speed #&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 EWR 2013 1 1 1 39.0 26.1 59.4 270 10.4 #&gt; 2 EWR 2013 1 1 2 39.0 27.0 61.6 250 8.06 #&gt; 3 EWR 2013 1 1 3 39.0 28.0 64.4 240 11.5 #&gt; 4 EWR 2013 1 1 4 39.9 28.0 62.2 250 12.7 #&gt; 5 EWR 2013 1 1 5 39.0 28.0 64.4 260 12.7 #&gt; 6 EWR 2013 1 1 6 37.9 28.0 67.2 240 11.5 #&gt; 7 EWR 2013 1 1 7 39.0 28.0 64.4 240 15.0 #&gt; 8 EWR 2013 1 1 8 39.9 28.0 62.2 250 10.4 #&gt; 9 EWR 2013 1 1 9 39.9 28.0 62.2 260 15.0 #&gt; 10 EWR 2013 1 1 10 41 28.0 59.6 260 13.8 #&gt; # ... with 26,105 more rows, and 5 more variables: wind_gust &lt;dbl&gt;, #&gt; # precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;, time_hour &lt;dttm&gt; 它们的关系图如下： relational-nycflights 我们首先对数据集进行精简： flights_smaller &lt;- flights %&gt;% select(year:day, hour, origin, dest, tailnum, carrier) 由于 carrier 没有补全，所以我们决定联合 airlines 数据集进行选择性合并： flights_smaller %&gt;% select(-c(origin, dest)) %&gt;% # 根据别的数据集在右侧补全数据，依据 / 重叠数据为 carrier left_join(airlines, by = &quot;carrier&quot;) #&gt; # A tibble: 336,776 x 7 #&gt; year month day hour tailnum carrier name #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 2013 1 1 5 N14228 UA United Air Lines Inc. #&gt; 2 2013 1 1 5 N24211 UA United Air Lines Inc. #&gt; 3 2013 1 1 5 N619AA AA American Airlines Inc. #&gt; 4 2013 1 1 5 N804JB B6 JetBlue Airways #&gt; 5 2013 1 1 6 N668DN DL Delta Air Lines Inc. #&gt; 6 2013 1 1 5 N39463 UA United Air Lines Inc. #&gt; 7 2013 1 1 6 N516JB B6 JetBlue Airways #&gt; 8 2013 1 1 6 N829AS EV ExpressJet Airlines Inc. #&gt; 9 2013 1 1 6 N593JB B6 JetBlue Airways #&gt; 10 2013 1 1 6 N3ALAA AA American Airlines Inc. #&gt; # ... with 336,766 more rows 当然我们也可以使用 mutate + match 实现同样效果： flights_smaller %&gt;% select(-c(origin, dest)) %&gt;% mutate( # 从 airlines 的 name 向量获取数据，赋值到新列 “name” name = airlines$name[match( # 获取的数据通过 match 控制 # 通过 filghts 的 carrier 匹配数据，返回对应 airlines 的 carrier carrier, airlines$carrier )] ) #&gt; # A tibble: 336,776 x 7 #&gt; year month day hour tailnum carrier name #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 2013 1 1 5 N14228 UA United Air Lines Inc. #&gt; 2 2013 1 1 5 N24211 UA United Air Lines Inc. #&gt; 3 2013 1 1 5 N619AA AA American Airlines Inc. #&gt; 4 2013 1 1 5 N804JB B6 JetBlue Airways #&gt; 5 2013 1 1 6 N668DN DL Delta Air Lines Inc. #&gt; 6 2013 1 1 5 N39463 UA United Air Lines Inc. #&gt; 7 2013 1 1 6 N516JB B6 JetBlue Airways #&gt; 8 2013 1 1 6 N829AS EV ExpressJet Airlines Inc. #&gt; 9 2013 1 1 6 N593JB B6 JetBlue Airways #&gt; 10 2013 1 1 6 N3ALAA AA American Airlines Inc. #&gt; # ... with 336,766 more rows 而如果要与 weather 并接： flights_smaller %&gt;% left_join(weather) # 如果不写 by，则为默认 NULL，会将左边所有列往右边对应一遍，相当于下面代码： #&gt; Joining, by = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;) #&gt; # A tibble: 336,776 x 18 #&gt; year month day hour origin dest tailnum carrier temp dewp humid #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 5 EWR IAH N14228 UA 39.0 28.0 64.4 #&gt; 2 2013 1 1 5 LGA IAH N24211 UA 39.9 25.0 54.8 #&gt; 3 2013 1 1 5 JFK MIA N619AA AA 39.0 27.0 61.6 #&gt; 4 2013 1 1 5 JFK BQN N804JB B6 39.0 27.0 61.6 #&gt; 5 2013 1 1 6 LGA ATL N668DN DL 39.9 25.0 54.8 #&gt; 6 2013 1 1 5 EWR ORD N39463 UA 39.0 28.0 64.4 #&gt; 7 2013 1 1 6 EWR FLL N516JB B6 37.9 28.0 67.2 #&gt; 8 2013 1 1 6 LGA IAD N829AS EV 39.9 25.0 54.8 #&gt; 9 2013 1 1 6 JFK MCO N593JB B6 37.9 27.0 64.3 #&gt; 10 2013 1 1 6 LGA ORD N3ALAA AA 39.9 25.0 54.8 #&gt; # ... with 336,766 more rows, and 7 more variables: wind_dir &lt;dbl&gt;, #&gt; # wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, pressure &lt;dbl&gt;, #&gt; # visib &lt;dbl&gt;, time_hour &lt;dttm&gt; # left_join(weather, by = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;)) 事实上 “by =” 可以省略。如果筛选变量填入了用等于连接的向量，则是左右都指定了列： flights_smaller %&gt;% # flighs_smaller 的 dest 列与 airports 的 faa 列比较、对应和连接 left_join(airports, c(&quot;dest&quot; = &quot;faa&quot;)) #&gt; # A tibble: 336,776 x 15 #&gt; year month day hour origin dest tailnum carrier name lat lon alt #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 5 EWR IAH N14228 UA Georg~ 30.0 -95.3 97 #&gt; 2 2013 1 1 5 LGA IAH N24211 UA Georg~ 30.0 -95.3 97 #&gt; 3 2013 1 1 5 JFK MIA N619AA AA Miami~ 25.8 -80.3 8 #&gt; 4 2013 1 1 5 JFK BQN N804JB B6 &lt;NA&gt; NA NA NA #&gt; 5 2013 1 1 6 LGA ATL N668DN DL Harts~ 33.6 -84.4 1026 #&gt; 6 2013 1 1 5 EWR ORD N39463 UA Chica~ 42.0 -87.9 668 #&gt; 7 2013 1 1 6 EWR FLL N516JB B6 Fort ~ 26.1 -80.2 9 #&gt; 8 2013 1 1 6 LGA IAD N829AS EV Washi~ 38.9 -77.5 313 #&gt; 9 2013 1 1 6 JFK MCO N593JB B6 Orlan~ 28.4 -81.3 96 #&gt; 10 2013 1 1 6 LGA ORD N3ALAA AA Chica~ 42.0 -87.9 668 #&gt; # ... with 336,766 more rows, and 3 more variables: tz &lt;dbl&gt;, dst &lt;chr&gt;, #&gt; # tzone &lt;chr&gt; 分析绘图机场在美国的分布图和到达此处的飞机的延误整体状况： avg_dest_delays &lt;- flights %&gt;% group_by(dest) %&gt;% # 新的列 delay 取值为各目的地的 arr_delay（到达延误）的平均值 summarise(delay = mean(arr_delay, na.rm = TRUE)) %&gt;% # 注意可能存在 NA 值，需要剔除 # 注意向量内左侧数据其实打不打引号都是可以的，但右侧必须打 inner_join(airports, by = c(dest = &quot;faa&quot;)) # 其中 faa 为机场代码 avg_dest_delays #&gt; # A tibble: 101 x 9 #&gt; dest delay name lat lon alt tz dst tzone #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 ABQ 4.38 Albuquerque International S~ 35.0 -107. 5355 -7 A Amer~ #&gt; 2 ACK 4.85 Nantucket Mem 41.3 -70.1 48 -5 A Amer~ #&gt; 3 ALB 14.4 Albany Intl 42.7 -73.8 285 -5 A Amer~ #&gt; 4 ANC -2.5 Ted Stevens Anchorage Intl 61.2 -150. 152 -9 A Amer~ #&gt; 5 ATL 11.3 Hartsfield Jackson Atlanta ~ 33.6 -84.4 1026 -5 A Amer~ #&gt; 6 AUS 6.02 Austin Bergstrom Intl 30.2 -97.7 542 -6 A Amer~ #&gt; 7 AVL 8.00 Asheville Regional Airport 35.4 -82.5 2165 -5 A Amer~ #&gt; 8 BDL 7.05 Bradley Intl 41.9 -72.7 173 -5 A Amer~ #&gt; 9 BGR 8.03 Bangor Intl 44.8 -68.8 192 -5 A Amer~ #&gt; 10 BHM 16.9 Birmingham Intl 33.6 -86.8 644 -6 A Amer~ #&gt; # ... with 91 more rows avg_dest_delays %&gt;% # lat 和 lon 为机场的经度和纬度信息，颜色代表平均延迟时长 ggplot(mapping = aes(lon, lat, colour = delay)) + borders(&quot;state&quot;) + # 这一句话是在加入美国地图背板 geom_point() + # 显示机场位置分布 coord_quickmap() # 保持地图横纵比，防止实际图片拉伸导致的地图变形 分析合并出发地的延误状况： airport_locations &lt;- airports %&gt;% select(faa, lat, lon) flights %&gt;% select(year:day, hour, origin, dest) %&gt;% # 注意这样 origin 和 dest 都由对应的经纬度坐标数据，存在命名冲突 # 实际运行时，运行到下面的 left_join 会发现，dplyr 会自动给旧列名加上 “.x”，新列名 “.y” # left_join( # airport_locations, # by = c(&quot;dest&quot; = &quot;faa&quot;) # ) # 所以我们使用 suffix 覆盖这个默认行为设置的后缀 left_join( airport_locations, by = c(&quot;dest&quot; = &quot;faa&quot;), suffix = c(&quot;_origin&quot;, &quot;_dest&quot;) ) #&gt; # A tibble: 336,776 x 8 #&gt; year month day hour origin dest lat lon #&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2013 1 1 5 EWR IAH 30.0 -95.3 #&gt; 2 2013 1 1 5 LGA IAH 30.0 -95.3 #&gt; 3 2013 1 1 5 JFK MIA 25.8 -80.3 #&gt; 4 2013 1 1 5 JFK BQN NA NA #&gt; 5 2013 1 1 6 LGA ATL 33.6 -84.4 #&gt; 6 2013 1 1 5 EWR ORD 42.0 -87.9 #&gt; 7 2013 1 1 6 EWR FLL 26.1 -80.2 #&gt; 8 2013 1 1 6 LGA IAD 38.9 -77.5 #&gt; 9 2013 1 1 6 JFK MCO 28.4 -81.3 #&gt; 10 2013 1 1 6 LGA ORD 42.0 -87.9 #&gt; # ... with 336,766 more rows "],["model-intro.html", "Chapter 15 Introduction 15.1 认知", " Chapter 15 Introduction 现在我们已经配备了强大的编程工具，终于可以回到建模了。 data-science-model 模型的目标是提供数据集的简单低维摘要。理想情况下，该模型将捕获真正的 “信号”（即由感兴趣现象产生的模式），并忽略 “噪声”（即我们不感兴趣的随机变化）。 在模型基础知识中，我们将了解模型如何工作，重点介绍重要的线性模型系列。 在模型构建中，我们将学习如何使用模型在实际数据中提取已知模式。 在许多模型中，我们将学习如何使用许多简单模型来帮助理解复杂的数据集。注意学习时多加结合建模和编程工具。 15.1 认知 传统的来说，建模的重点是推理，或确认假设是正确的。因此我们需要形成两个必要的观念： 每个观测值既可以用于探索，也可以用于确认，而不能两者兼而有之。 我们可以根据需要多次使用观测值进行探索，但只能使用一次进行确认。一旦使用观察结果两次，我们就算已经从确认切换到了探索。 "],["model-basics.html", "Chapter 16 Model basics 16.1 对 sim1 模型研究 16.2 对 sim2 模型研究 16.3 对 sim3（分类变量）模型研究 16.4 对 sim4（连续且相互作用）模型研究 16.5 对 sim5（模型转换）模型研究 16.6 其他常见线性模型", " Chapter 16 Model basics 模型由两部分组成： - 定义一系列模型，这些模型表示要捕获的精确但通用的模式。 - 通过从最接近数据集中查找模型来生成拟合模型。这将采用通用模型系列，并使其具体化。 library(tidyverse) library(modelr) options(na.action = na.warn) 16.1 对 sim1 模型研究 16.1.1 简单建立 sim1 模型 ggplot(sim1, aes(x, y)) + geom_point() 由图可以发现，x 变量和 y 变量可能有明显线性关系。 random_models &lt;- tibble( # 随机生成 250 个上限 -20 下限 40 的 a1 向量 a1 = runif(n = 250, min = -20, max = 40), # 同理随机生成 250 个上限 -5 下限 5 的 a2 向量 a2 = runif(250, -5, 5) ) 如果用随机生成数据的话，模型会看起来非常糟糕： ggplot() + geom_abline( data = random_models, mapping = aes(intercept = a1, slope = a2), # intercept：截距，slope：斜率 alpha = 1 / 4 ) + geom_point( data = sim1, mapping = aes(x, y) ) 我们希望有直线 y = a2*x + a1 来概括这个数据集的特征。所以我们创造了 model1： model1 &lt;- function(a, data) { # 注意我们传入的 data 是一个数据集。这个设计的函数会针对数据集里的数据反复代入计算，最终返回一个向量 a[1] + data$x * a[2] } 试图用 a1 = 7 和 a2 = 1.5 数据来分析 sim1。这样我们得到了理想模型下对应 y 的值 model1(c(7, 1.5), sim1) #&gt; [1] 8.5 8.5 8.5 10.0 10.0 10.0 11.5 11.5 11.5 13.0 13.0 13.0 14.5 14.5 14.5 #&gt; [16] 16.0 16.0 16.0 17.5 17.5 17.5 19.0 19.0 19.0 20.5 20.5 20.5 22.0 22.0 22.0 验证或者求得回归曲线的拟合度使我们通常采用方差，度量随机变量和其数学期望（即均值）之间的偏离程度。所以我们新建了函数来获得方差： measure_distance &lt;- function(mod, data) { diff &lt;- data$y - model1(mod, data) # diff 为 data 中实际 y 值与 model1 得到的理想 y 值的差 sqrt(mean(diff^2)) # 返回所有 diff 平方的均值进行的开方（方差） } # 试图用 a1 = 7 和 a2 = 1.5 数据求得关于 sim1 的方差 measure_distance(c(7, 1.5), sim1) #&gt; [1] 2.665212 由于我们这里仅用来研究 sim1 数据集，所以这里新建函数用来提交给 sim1，方便后面 map2_dbl 处理： sim1_dist &lt;- function(a1, a2) { measure_distance(c(a1, a2), sim1) # nolint } # 通过 mutate 新增计算得到的列 dist 并赋值回去（方差） models &lt;- random_models %&gt;% mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist)) models #&gt; # A tibble: 250 x 3 #&gt; a1 a2 dist #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 27.1 -0.371 12.0 #&gt; 2 -19.9 4.79 12.2 #&gt; 3 -14.7 1.61 21.5 #&gt; 4 -9.05 -4.94 55.5 #&gt; 5 -16.2 1.43 24.0 #&gt; 6 -17.1 -1.63 42.9 #&gt; 7 24.3 -0.823 9.53 #&gt; 8 13.3 -2.42 20.3 #&gt; 9 38.6 -2.70 16.1 #&gt; 10 33.1 0.512 21.0 #&gt; # ... with 240 more rows 注意这里的 map2_dbl 会返回离散程度较小的，即拟合程度最高的。例如： df &lt;- data.frame( x = c(1, 2, 5), y = c(5, 4, 8) ) # 这个包的 map2_dbl 表达式相当于 pmin(df$x, df$y) purrr::map2_dbl(df$x, df$y, min) #&gt; [1] 1 2 5 最后将实际得到的模型简单直观地展示出来： ggplot(sim1, aes(x, y)) + geom_point(size = 2, colour = &quot;grey30&quot;) + geom_abline( aes(intercept = a1, slope = a2, colour = -dist), # 由 dist 反向上色，即越精确颜色越鲜亮 data = filter(models, rank(dist) &lt;= 10) # 不是所有线条都需要显示，这里选择 dist 排名前 10 ) # 将 a1 和 a2 用图表示出来（同样上色），这里选择 dist 排名前 10 来高亮显示（叠加） ggplot(models, aes(a1, a2)) + geom_point( data = filter(models, rank(dist) &lt;= 10), # 先画高亮部分 size = 4, colour = &quot;red&quot; ) + geom_point(aes(colour = -dist)) 事实上除了用 runif 创建随机模型外，我们还常常使用标准步长的规整矩阵数据模型来验算已知的回归模型： grid_models &lt;- expand.grid( # expand.grid 用于于快速创建数据集（data frame格式） a1 = seq(-5, 20, length = 25), # seq 用于快速生成序列，参数分别代表起始、结束和序列长 a2 = seq(1, 3, length = 25) ) %&gt;% mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist)) ggplot(grid_models, aes(a1, a2)) + geom_point( data = filter(grid_models, rank(dist) &lt;= 10), size = 4, colour = &quot;red&quot; ) + geom_point(aes(colour = -dist)) 同样，我们把拟合出的回归模型放到原始数据集对照，事实告诉我们拟合的效果非常好： ggplot(sim1, aes(x, y)) + geom_point(size = 2, colour = &quot;grey30&quot;) + geom_abline( aes(intercept = a1, slope = a2, colour = -dist), data = filter(grid_models, rank(dist) &lt;= 10) ) 当然这对 a1、a2 数据是我们根据矩阵数据集拟合得到的。我们现在可以通过大致拟合度，继续细化数据。这样已知细化下去，我们终究得到拟合度极高的数据。 所以我们提出了一个名为牛顿-拉夫森搜索的数字最小化工具。牛顿-拉夫森工具的思想很简单：你选择一个起点，环顾四周最陡峭的斜坡。然后，你沿着斜坡滑了一点，然后一遍又一遍地重复，直到你不能再低了。 在 R 中，我们可以使用 optim() 做到这一点： best &lt;- optim( par = c(0, 0), # 要优化的参数的初始值 fn = measure_distance, # 要最小化（或最大化）的函数，所以 par 参数是要进行最小化的参数向量。它应该返回标量结果 data = sim1 ) 注意 optm() 将返回一个 list，其中 par 为找到的最佳参数向量，value 为参数向量对应的返回值： best$par #&gt; [1] 4.222248 2.051204 我们画图验证一下刚刚得到的 a1 和 a2。相应的，它的拟合程度也相当完美： ggplot(sim1, aes(x, y)) + geom_point(size = 2, colour = &quot;grey30&quot;) + geom_abline(intercept = best$par[1], slope = best$par[2], colour = &quot;blue&quot;) 线性模型的一般形式为 y = a_1 + a_2 * x_1 + a_3 * x_2 + … + a_n * x_(n - 1)。在 R 里有一个专门为拟合线性模型而设计的工具 lm()。 lm() 用一种特殊的方式来指定模型，即公式。公式例如 y ~ x，lm() 将自动转换为 y = a_1 + a_2 * x 这样的函数： sim1_mod &lt;- lm(y ~ x, data = sim1) # 结果与预期完全一致 coef(sim1_mod) # coef() 是一个通用函数，用于从建模函数返回的对象中提取模型系数 #&gt; (Intercept) x #&gt; 4.220822 2.051533 16.1.2 对 sim1 模型可视化观察分析 现在我们将通过查看模型的预测来专注于理解模型。每种类型的预测模型都需要进行预测。查看模型未捕获的内容（即从数据中减去预测值后留下的所谓残差）也很有用。我们可以用来研究剩余的更微妙的趋势。 16.1.2.1 分析预测数据 为了模型的预测，我们先创建网格，其最简单的方法是使用 data_grid() 函数： grid &lt;- sim1 %&gt;% # 相当于对 sim1 定制对应的 x 数据集 data_grid(x) grid #&gt; # A tibble: 10 x 1 #&gt; x #&gt; &lt;int&gt; #&gt; 1 1 #&gt; 2 2 #&gt; 3 3 #&gt; 4 4 #&gt; 5 5 #&gt; 6 6 #&gt; 7 7 #&gt; 8 8 #&gt; 9 9 #&gt; 10 10 接下来我们开始预测。请注意 sim1_mod 来自之前 lm() 函数生成的代码： #&gt; sim1_mod &lt;- lm(y ~ x, data = sim1) predictions &lt;- grid %&gt;% add_predictions(sim1_mod) predictions #&gt; # A tibble: 10 x 2 #&gt; x pred #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1 6.27 #&gt; 2 2 8.32 #&gt; 3 3 10.4 #&gt; 4 4 12.4 #&gt; 5 5 14.5 #&gt; 6 6 16.5 #&gt; 7 7 18.6 #&gt; 8 8 20.6 #&gt; 9 9 22.7 #&gt; 10 10 24.7 最后绘制预测结果： ggplot(sim1, aes(x)) + geom_point(aes(y = y)) + geom_line(aes(y = pred), data = predictions, colour = &quot;red&quot;, size = 1) 16.1.2.2 分析残差 残差是我们的预测值与实际值之间的距离： residuals &lt;- sim1 %&gt;% # 注意这里使用的参数是 sim1，因为我们需要原始数据集才能发现残差 add_residuals(sim1_mod) # 用法与 add_predictions() 非常相似 residuals #&gt; # A tibble: 30 x 3 #&gt; x y resid #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 4.20 -2.07 #&gt; 2 1 7.51 1.24 #&gt; 3 1 2.13 -4.15 #&gt; 4 2 8.99 0.665 #&gt; 5 2 10.2 1.92 #&gt; 6 2 11.3 2.97 #&gt; 7 3 7.36 -3.02 #&gt; 8 3 10.5 0.130 #&gt; 9 3 10.5 0.136 #&gt; 10 4 12.4 0.00763 #&gt; # ... with 20 more rows 最后绘制残差关于 x 的图： ggplot(residuals, aes(resid)) + # geom_freqpoly 即频率多边形，非常适合模糊化地绘制表现一个向量的数据的大小和出现次数 geom_freqpoly(binwidth = 0.5) # 或者加入数据 x 来看到更多的数据。很容易发现它的分布非常完美： ggplot(residuals, aes(x, resid)) + geom_ref_line(h = 0) + # 调整基线为 0 而不是最小 geom_point(aes(colour = -abs(resid))) 16.2 对 sim2 模型研究 16.2.1 关于 model_matrix() 要想提取关键自定义变量的值，我们可以使用 model_matrix() 函数。如： df &lt;- tribble( ~y, ~x1, ~x2, 4, 2, 5, 5, 1, 6 ) model_matrix(df, y ~ x1) #&gt; # A tibble: 2 x 2 #&gt; `(Intercept)` x1 #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2 #&gt; 2 1 1 # 如果添加其他变量： model_matrix(df, y ~ x1 + x2) #&gt; # A tibble: 2 x 3 #&gt; `(Intercept)` x1 x2 #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 2 5 #&gt; 2 1 1 6 # R 将截距添加到模型的方式是直接填充名为截距的列（当然这个列填充前的值是没有意义的）。 # 默认添加。如果不需要，使用 “-1” 命令显式删除它： model_matrix(df, y ~ x1 + x2 - 1) #&gt; # A tibble: 2 x 2 #&gt; x1 x2 #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 5 #&gt; 2 1 6 对于分类变量，尤其是分类为字符的：想象一下，你有一个 tibble 数据集，其中性别可以是男性或女性。将其转换为初始数据是没有意义的，因为不是数字 —— 你不能简单地计算它！ df &lt;- tribble( ~sex, ~response, &quot;male&quot;, 1, &quot;female&quot;, 2, &quot;male&quot;, 1 ) # 可以看到函数会自动将自变量的名名为 “列” “某种值”，其数据用来表示该列数据是否是指定的 “某种值”： model_matrix(df, response ~ sex) #&gt; # A tibble: 3 x 2 #&gt; `(Intercept)` sexmale #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 #&gt; 2 1 0 #&gt; 3 1 1 对于 sim2，我们可以先使用 ggplot() 进行可视化观察： ggplot(sim2) + geom_point(aes(x, y)) 同理我们可以对 sim2 数据集也这样将字符串转化为初始数据并预测： mod2 &lt;- lm(y ~ x, data = sim2) # 产生理想线性回归模型 注意回归模型中每个 x 的分类对应一个 “斜率”。也就是说，一个 x 的 某值在模型上只会对应一个值，即平均值： grid2 &lt;- sim2 %&gt;% data_grid(x) %&gt;% # 产生初始数据 add_predictions(mod2) # 依据初始数据对模型进行预测 grid2 #&gt; # A tibble: 4 x 2 #&gt; x pred #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 a 1.15 #&gt; 2 b 8.12 #&gt; 3 c 6.13 #&gt; 4 d 1.91 我们对理想模型与原始数据叠加进行可视化： ggplot(sim2, aes(x)) + geom_point(aes(y = y)) + geom_point(data = grid2, aes(y = pred), colour = &quot;red&quot;, size = 4) 16.3 对 sim3（分类变量）模型研究 sim3 同时包含 x1 的数值和 x2 的字母分类： ggplot(sim3, aes(x1, y)) + geom_point(aes(colour = x2)) 由于并不知道 x1 和 x2 同时影响了 y 的值，我们假设了两个模型： mod1 &lt;- lm(y ~ x1 + x2, data = sim3) mod2 &lt;- lm(y ~ x1 * x2, data = sim3) 使用 “+” 来阐述变量之间的关系时，模型将独立计算每个初始数据的效应。如 y ~ x1 + x2 被转换为 y = a_0 + a_1 * x1 + a_2 * x2。 但使用 * 来阐述时，函数将结合两者的数据去初始化模型。如 y ~ x1 * x2 被转换为 y = a_0 + a_1 * x1 + a_2 * x2 + a_12 * x1 * x2。 注意一旦使用 *，所有模型的参数都会包含在模型中。“实践出真知”，我们决定尝试同时使用两个模型计算出结果去拟合原始数据并观察： grid3 &lt;- sim3 %&gt;% data_grid(x1, x2) %&gt;% # 由于初始值有两个，这里就需要填入两个变量来产生初始数据 # 同时从两个模型一起运算使用 gather_prediction()，相反的，我们也有 spread_prediction() gather_predictions(mod1, mod2) # 会在生成的 tibble 中第一列声明使用的哪个模型得到的预期数据 grid3 #&gt; # A tibble: 80 x 4 #&gt; model x1 x2 pred #&gt; &lt;chr&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 mod1 1 a 1.67 #&gt; 2 mod1 1 b 4.56 #&gt; 3 mod1 1 c 6.48 #&gt; 4 mod1 1 d 4.03 #&gt; 5 mod1 2 a 1.48 #&gt; 6 mod1 2 b 4.37 #&gt; 7 mod1 2 c 6.28 #&gt; 8 mod1 2 d 3.84 #&gt; 9 mod1 3 a 1.28 #&gt; 10 mod1 3 b 4.17 #&gt; # ... with 70 more rows 最后我们将得到的数据画图分析： ggplot(sim3, aes(x1, y, colour = x2)) + geom_point() + geom_line(data = grid3, aes(y = pred)) + facet_wrap(~model) # 切图分组 哪种模型更适合此数据？我们可以看看残差： sim3_resid &lt;- sim3 %&gt;% # 多个模型获得残差与得到预期值样，也有 gather_residuals() gather_residuals(mod1, mod2) ggplot(sim3_resid, aes(x1, resid, colour = x2)) + geom_point() + # geom_ref_line(h = 0) + # 调整基线为 0 而不是最小（效果不好已注释掉） # 这里我们按照模型和 x2 的值切图，因为它可以更容易地看到每个组中的情况 facet_grid(model ~ x2) 可以看到，mod2 的拟合度更好，残差更接近 0。 16.4 对 sim4（连续且相互作用）模型研究 按照之前的方法，我们建立两个模型： mod1 &lt;- lm(y ~ x1 + x2, data = sim4) mod2 &lt;- lm(y ~ x1 * x2, data = sim4) grid4 &lt;- sim4 %&gt;% data_grid( # 以 x1 / x2 的最大和最小为界限，生成包含五个数据的等差数列 x1 = seq_range(x1, 5), x2 = seq_range(x2, 5) ) %&gt;% gather_predictions(mod1, mod2) %&gt;% # 对两个模型求取预期结果并合并 print() #&gt; # A tibble: 50 x 4 #&gt; model x1 x2 pred #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 mod1 -1 -1 0.996 #&gt; 2 mod1 -1 -0.5 -0.395 #&gt; 3 mod1 -1 0 -1.79 #&gt; 4 mod1 -1 0.5 -3.18 #&gt; 5 mod1 -1 1 -4.57 #&gt; 6 mod1 -0.5 -1 1.91 #&gt; 7 mod1 -0.5 -0.5 0.516 #&gt; 8 mod1 -0.5 0 -0.875 #&gt; 9 mod1 -0.5 0.5 -2.27 #&gt; 10 mod1 -0.5 1 -3.66 #&gt; # ... with 40 more rows grid4 #&gt; # A tibble: 50 x 4 #&gt; model x1 x2 pred #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 mod1 -1 -1 0.996 #&gt; 2 mod1 -1 -0.5 -0.395 #&gt; 3 mod1 -1 0 -1.79 #&gt; 4 mod1 -1 0.5 -3.18 #&gt; 5 mod1 -1 1 -4.57 #&gt; 6 mod1 -0.5 -1 1.91 #&gt; 7 mod1 -0.5 -0.5 0.516 #&gt; 8 mod1 -0.5 0 -0.875 #&gt; 9 mod1 -0.5 0.5 -2.27 #&gt; 10 mod1 -0.5 1 -3.66 #&gt; # ... with 40 more rows 16.4.1 关于 seq_range() 实际使用上，就像 group_by 与 summarize 一样，seq_range 常常绑定 data_grid 使用： # seq_range 真的可以很轻易地生成等差数列： seq_range(c(0.0123, 0.923423), n = 5) #&gt; [1] 0.0123000 0.2400808 0.4678615 0.6956423 0.9234230 # pretty 参数还可以让数据更简化 seq_range(c(0.0123, 0.923423), n = 5, pretty = TRUE) #&gt; [1] 0.0 0.2 0.4 0.6 0.8 1.0 # trim 参数用于收缩范围，使得生成的序列更接近中值 (x1 &lt;- rcauchy(100)) # 生成具有柯西分布特性的随机数 #&gt; [1] 0.37849942 0.44266379 2.89324358 -2.08088618 -1.44943673 #&gt; [6] -2.20141768 0.48763563 0.06053673 -0.34547167 1.54967746 #&gt; [11] 2.45417964 -0.71862985 2.25166882 -2.69033734 2.94280108 #&gt; [16] 0.88206715 0.25533147 0.03745532 -3.20565520 -9.95730730 #&gt; [21] 5.70401148 -5.49230726 -0.50719679 -0.23293966 -1.75248642 #&gt; [26] -1.00071082 0.56652327 -2.73793151 -1.10175267 -0.41912018 #&gt; [31] -0.60861620 0.16150921 0.56124941 -0.45867224 -0.50199098 #&gt; [36] 0.78504379 -0.28653760 -5.89963242 1.42517432 0.87680483 #&gt; [41] -6.13491754 -0.87173195 -0.79237609 -4.52253340 -1.12752137 #&gt; [46] 1.72887631 0.37556421 0.88723916 0.84529964 -0.67040600 #&gt; [51] 1.05186586 0.21892046 -4.87354144 -1.15681483 -2.52782621 #&gt; [56] -0.17524861 -9.62257620 -0.19936256 -0.08427578 3.07717174 #&gt; [61] 0.29474209 -0.84902151 2.21325963 2.19264451 -1.10397565 #&gt; [66] 3.00974117 -0.19666272 0.06534479 1.21010247 -0.13372261 #&gt; [71] -7.19093894 1.44554118 -3.16343580 -2.80559708 3.09999463 #&gt; [76] 8.81890667 0.62587022 0.39642420 -6.11981282 -0.64621301 #&gt; [81] 0.63983803 -3.44654906 -2.71916960 -15.06460538 -1.47298365 #&gt; [86] 1.33027976 0.24647460 0.65864952 -0.63953793 -2.99020675 #&gt; [91] -0.07367945 3.32352778 1.25266609 0.08086302 51.21369976 #&gt; [96] 2.86715011 -2.07605331 -0.82565346 -2.40441591 3.54189345 seq_range(x1, n = 5) #&gt; [1] -15.064605 1.504971 18.074547 34.644123 51.213700 seq_range(x1, n = 5, trim = 0.10) # 收缩指定范围头尾 10% #&gt; [1] -6.1205681 -3.8126332 -1.5046984 0.8032364 3.1111713 seq_range(x1, n = 5, trim = 0.25) # 收缩指定范围头尾 25% #&gt; [1] -3.0984749 -1.7645398 -0.4306048 0.9033303 2.2372654 seq_range(x1, n = 5, trim = 0.50) # 收缩指定范围头尾 50% #&gt; [1] -1.4553235 -0.8719625 -0.2886015 0.2947594 0.8781204 # 与之相反，expand 参数会扩增范围 x2 &lt;- c(0, 1) seq_range(x2, n = 5) #&gt; [1] 0.00 0.25 0.50 0.75 1.00 seq_range(x2, n = 5, expand = 0.10) #&gt; [1] -0.050 0.225 0.500 0.775 1.050 seq_range(x2, n = 5, expand = 0.25) #&gt; [1] -0.1250 0.1875 0.5000 0.8125 1.1250 seq_range(x2, n = 5, expand = 0.50) #&gt; [1] -0.250 0.125 0.500 0.875 1.250 16.4.2 对 sim4 模型可视化绘图 和之前一样，我们对 sim4 的两个模型进行可视化绘图。 ggplot(grid4, aes(x1, x2)) + geom_tile(aes(fill = pred)) + # 这种砖块图非常便于观察拟合度 facet_wrap(~model) x1 与 x2 似乎存在某种明显的关系！我们尝试继续深入观察： p &lt;- list() p[[1]] &lt;- ggplot(grid4, aes(x1, pred, colour = x2, group = x2)) + geom_line() + facet_wrap(~model) p[[2]] &lt;- ggplot(grid4, aes(x2, pred, colour = x1, group = x1)) + geom_line() + facet_wrap(~model) library(grid) grid.newpage() # 新建布局包 pushViewport(viewport(layout = grid.layout(2, 1))) # 设置 2x1 布局 print(p[[1]], vp = viewport(layout.pos.row = 1, layout.pos.col = 1)) print(p[[2]], vp = viewport(layout.pos.row = 2, layout.pos.col = 1)) 可以看到有明显的相互作用关系！为了预测 y，我们需要同时考虑 x1 和 x2 的值。 16.5 对 sim5（模型转换）模型研究 因为包不自带 sim5，这里我们只能自己建（恼 sim5 &lt;- tibble( x = seq(0, 3.5 * pi, length = 50), y = 4 * sin(x) + rnorm(length(x)) # 随机生成与 x 向量长度相同的向量并加上 4 倍 sin(x) ) sim5 #&gt; # A tibble: 50 x 2 #&gt; x y #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 1.32 #&gt; 2 0.224 -1.20 #&gt; 3 0.449 2.21 #&gt; 4 0.673 3.65 #&gt; 5 0.898 4.23 #&gt; 6 1.12 1.44 #&gt; 7 1.35 2.44 #&gt; 8 1.57 4.30 #&gt; 9 1.80 2.16 #&gt; 10 2.02 3.22 #&gt; # ... with 40 more rows 16.5.1 关于 I() 和 model_matrix()（续） 我们还可以在模型公式内随意转换。例如，log(y) ~ sqrt(x1) + x2 将转换为 log(y) = a_1 + a_2 * sqrt(x1) + a_3 * x2。 如果转换涉及 +、*、^ 或 -，则我们需要将其包装在 I() 函数中，这样 R 就不会将其视为模型规范的一部分。例如，y ~ x + I(x ^ 2) 翻译为 y = a_1 + a_2 * x + a_3 * x^2。如果上述情况忘记了 I() 指定成 y ~ x ^ 2 + x，R 将视为 y ~ x * x + x。 x * x 表示 x 与自身的相互作用，这与 x 效果相同。R 会自动删除冗余变量，会直接转换成 y = a_1 + a_2 * x。这很糟糕，毕竟这并不是你想要的效果。所以一定要注意避免！ 而对于自己创立的模型，我们可以使用 model_matrix() 来准确查看拟合的方程： tb &lt;- tribble( ~y, ~x, 1, 1, 2, 2, 3, 3 ) model_matrix(tb, y ~ x^2 + x) #&gt; # A tibble: 3 x 2 #&gt; `(Intercept)` x #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 #&gt; 2 1 2 #&gt; 3 1 3 model_matrix(tb, y ~ I(x^2) + x) #&gt; # A tibble: 3 x 3 #&gt; `(Intercept)` `I(x^2)` x #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 1 1 #&gt; 2 1 4 2 #&gt; 3 1 9 3 16.5.2 关于 poly() 转换模型非常有用，因为我们可以使用它们来近似非线性函数。微积分课上我们学过泰勒定理，它告诉我们可以用无限的多项式和来近似任何平滑曲线函数。 这意味着我们也可以使用多项式函数通过拟合。 手动键入该序列很繁琐复杂，而 R 提供了一个函数：poly() model_matrix(tb, y ~ poly(x, 2)) # 注意这个 “2” 是 degree 参数，表示多项式的最高次数 #&gt; # A tibble: 3 x 3 #&gt; `(Intercept)` `poly(x, 2)1` `poly(x, 2)2` #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 -7.07e- 1 0.408 #&gt; 2 1 -7.85e-17 -0.816 #&gt; 3 1 7.07e- 1 0.408 16.5.3 关于 ns() 注意 poly 生成的多项式函数同泰勒函数一样，出现了一个相对棘手的问题：在数据范围之外，多项式总是迅速接近无穷大。 所以我们剔除了另一种更安全的替代方案，即样条回归：splines::ns() library(splines) model_matrix(tb, y ~ ns(x, 2)) #&gt; # A tibble: 3 x 3 #&gt; `(Intercept)` `ns(x, 2)1` `ns(x, 2)2` #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 0 0 #&gt; 2 1 0.566 -0.211 #&gt; 3 1 0.344 0.771 尝试可视化！我们建立了不同次数的 5 个模型： mod1 &lt;- lm(y ~ ns(x, 1), data = sim5) mod2 &lt;- lm(y ~ ns(x, 2), data = sim5) mod3 &lt;- lm(y ~ ns(x, 3), data = sim5) mod4 &lt;- lm(y ~ ns(x, 4), data = sim5) mod5 &lt;- lm(y ~ ns(x, 5), data = sim5) grid &lt;- sim5 %&gt;% data_grid(x = seq_range(x, n = 50, expand = 0.1)) %&gt;% # 向外扩张 10% 生成矩阵 # .pred 参数用来修改生成期望值列的列名 gather_predictions(mod1, mod2, mod3, mod4, mod5, .pred = &quot;y&quot;) ggplot(sim5, aes(x, y)) + geom_point() + geom_line(data = grid, colour = &quot;red&quot;) + facet_wrap(~model) # 以 model 分组 就像我们在数学中学习的泰勒公式一样，项的次数越高，其拟合性往往越好。mod5 的拟合度就明显大于其他模型。 16.5.4 NA 值（缺少值）问题 如果你的数据你还有 NA 值的话，R 当然会提示你错误！ df &lt;- tribble( ~x, ~y, 1, 2.2, 2, NA, 3, 3.5, 4, 8.3, NA, 10 ) # mod &lt;- lm(y ~ x, data = df) #&gt; Warning: Dropping 2 rows with missing values # 加上 “na.action = na.exclude” 表示不包含 NA 值计算： mod &lt;- lm(y ~ x, data = df, na.action = na.exclude) # 这样这个模型就只有 3 种观测值可用了： nobs(mod) # nobs() 用于查看可观测次数 #&gt; [1] 3 16.6 其他常见线性模型 本章只关注线性类型的模型，它们假设形式为 y = a_1 * x1 + a_2 * x2 + ... + a_n * xn。同样，对于线性模型的残差，它可能还有一些特性，如还可能具有正态分布。有许多模型以各种有趣的方式扩展线性模型，相对常用的有以下几种： 广义线性模型（Generalised Linear Models），如 stats::glm()。 线性模型的数据通常是连续的，并且其残差具有正态分布。该模型对线性模型进行了扩展，甚至囊括了非连续响应（例如二进制数据或计数）。而其工作原理是基于可能性的统计去定义距离度量。 有关广义线性模型（GLM）的实际运作参考：https://zhuanlan.zhihu.com/p/110387248 广义加性模型（Generalised Additive Models），如 mgcv::gam()。它扩展广义线性模型以包含任意光滑函数，这意味着我们可以编写诸如 y ~ s(x) 这样的公式。这样的模型公式将使用 y = f(x) 和 letgam，即 gam() 去估计该函数是什么样的。 有关广义加性模型（GAM）的实际运作参考：https://zhuanlan.zhihu.com/p/53001283 惩罚线性模型（Penalised Linear Models），如 glmnet::glmnet()。 该模型使得在 “惩处” 一个复杂模型的距离中添加一个 “惩处” 项（由参数向量和原点之间的距离决定）。这往往使模型可以更好地推广到来自同一人群的新数据集。 稳健线性模型（Robust linear models），如 MASS::rlm()。 该模型用于调整与模型预期距离非常远的点的权重，使得模型对于异常值问题不那么敏感。但其代价则是在没有异常值时通常不如其他模型的拟合效果那么强。 有关稳健线性模型（RLM）的实际运作参考：https://zhuanlan.zhihu.com/p/398805690 树模型（Trees），如 rpart::rpart()。 这种模型则是以与线性模型完全不同的方式去解决问题，适合分段恒定模型，并将数据拆分多个成足够小的部分。树模型本身并不出色，但当被随机森林（Random Forests），像是 randomForest::randomForest()，或是梯度提升机（Gradient Boosting Machines），像是 xgboost::xgboost() 等多种模型聚合使用时，树模型会变得非常强大。 有关随机森林（RF）的实际运作参考：https://zhuanlan.zhihu.com/p/125505067 有关梯度提升机（GBM）的实际运作参考：https://zhuanlan.zhihu.com/p/36011508 "],["model-building.html", "Chapter 17 Model building 17.1 分析 diamonds 品质与价格反常的原因 17.2 分析 flights 每日航班数量变化因素 17.3 关于计算变量 17.4 有关模型的更多信息", " Chapter 17 Model building 上一章我们侧重于模拟数据集。本章将重点介绍真实数据，以及如何构建模型以便理解数据。我们可以将数据划分为模式和残差模型。注意模型建立有时不尽人意，有时建立得很好但你不知道为什么。 如果你遇到了任何困惑 —— 请不要畏惧重新开始！换个全新思路可能对你非常有用。 library(tidyverse) library(modelr) options(na.action = na.warn) library(nycflights13) library(lubridate) 17.1 分析 diamonds 品质与价格反常的原因 还记得我们之前研究的奇怪现象吗？品质越差的钻石，价格越高。不只是质量，在颜色、纯净度方面都是这样表现的： ggplot(diamonds, aes(cut, price)) + geom_boxplot() ggplot(diamonds, aes(color, price)) + geom_boxplot() ggplot(diamonds, aes(clarity, price)) + geom_boxplot() 注意最差的钻石颜色是 J（微黄色），最差的纯净度是 I1（肉眼可见的杂物）。 17.1.1 重量与价格 ggplot(diamonds, aes(carat, price)) + geom_hex(bins = 50) 我们决定对数据进行过滤处理： diamonds_new &lt;- diamonds %&gt;% filter(carat &lt;= 2.5) %&gt;% # 质量小于 2.5 mutate(lprice = log2(price), lcarat = log2(carat)) # 对价格和质量取对数（基数为 2 的对数） ggplot(diamonds_new, aes(lcarat, lprice)) + geom_hex(bins = 50) 通过转化，它们的关系变成了明显漂亮的线性化！我们试着创建模型去拟合它： mod_diamonds &lt;- lm(lprice ~ lcarat, data = diamonds_new) grid &lt;- diamonds_new %&gt;% data_grid(carat = seq_range(carat, 20)) %&gt;% # 创建矩阵 mutate(lcarat = log2(carat)) %&gt;% # 矩阵生成的 carat 也需要取对数 add_predictions(mod_diamonds, &quot;lprice&quot;) %&gt;% # 预测 mutate(price = 2^lprice) # 将价格还原回去 最后绘制数据图： ggplot(diamonds_new, aes(carat, price)) + geom_hex(bins = 50) + geom_line(data = grid, colour = &quot;red&quot;, size = 1) 这告诉我们一些关于这些数据的有趣信息：如果我们相信我们创造的模型，那么大钻石比预期的要便宜得多。 我们来分析残差的数据： diamonds_new &lt;- diamonds_new %&gt;% add_residuals(mod_diamonds, &quot;lresid&quot;) # 注意这里分析得到的数据是取过对数的 ggplot(diamonds_new, aes(lcarat, lresid)) + geom_hex(bins = 50) 我们决定舍弃掉价格变量，因为 lrisid 变量可能有其他参考价值： ggplot(diamonds_new, aes(cut, lresid)) + geom_boxplot() ggplot(diamonds_new, aes(color, lresid)) + geom_boxplot() ggplot(diamonds_new, aes(clarity, lresid)) + geom_boxplot() 现在我们看到了所期望的结果：钻石品质越高，其相对价格也越高。 17.1.2 推广出更复杂的模型 既然价格对数与质量对数、颜色、质量和品质都有重要关系，那我们不妨把它们都加入模型： mod_diamond_new &lt;- lm( lprice ~ lcarat + color + cut + clarity, data = diamonds_new ) grid &lt;- diamonds_new %&gt;% # 用 data_grid() 来创建数据越来越麻烦了。 # 好在我们有一个叫 “.model” 的参数帮我们完成： data_grid(cut, .model = mod_diamond_new) %&gt;% add_predictions(mod_diamond_new) grid #&gt; # A tibble: 5 x 5 #&gt; cut lcarat color clarity pred #&gt; &lt;ord&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Fair -0.515 G VS2 11.2 #&gt; 2 Good -0.515 G VS2 11.3 #&gt; 3 Very Good -0.515 G VS2 11.4 #&gt; 4 Premium -0.515 G VS2 11.4 #&gt; 5 Ideal -0.515 G VS2 11.4 ggplot(grid, aes(cut, pred)) + geom_point() 如果模型需要我们未显式提供的变量，data_grid() 将自动使用 “典型值” 填充它们。对于连续变量，它使用中位数，分类变量使用最常见的值（如果存在并列，则使用或值）。 diamonds_new &lt;- diamonds_new %&gt;% # 新的 lrisid 添加了颜色、质量和品质关系 add_residuals(mod_diamond_new, &quot;lresid_new&quot;) ggplot(diamonds_new, aes(lcarat, lresid_new)) + geom_hex(bins = 50) 我们会发现有一些钻石数据的残差相当大 —— 尤其是因为取对数的关系，残差为 2 表示钻石的价格是我们预期的 4 倍。单独查看异常值通常很有用： diamonds_new %&gt;% filter(abs(lresid_new) &gt; 1) %&gt;% # 残差绝对值大于 1 add_predictions(mod_diamond_new) %&gt;% # 对这些数据生成期望值对数 mutate(pred = round(2^pred)) %&gt;% # 对期望值反对数并取整 select(price, pred, carat:table, x:z) %&gt;% # 重新选取需要的数据 arrange(price) # 按照价格排列 #&gt; # A tibble: 16 x 11 #&gt; price pred carat cut color clarity depth table x y z #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1013 264 0.25 Fair F SI2 54.4 64 4.3 4.23 2.32 #&gt; 2 1186 284 0.25 Premium G SI2 59 60 5.33 5.28 3.12 #&gt; 3 1186 284 0.25 Premium G SI2 58.8 60 5.33 5.28 3.12 #&gt; 4 1262 2644 1.03 Fair E I1 78.2 54 5.72 5.59 4.42 #&gt; 5 1415 639 0.35 Fair G VS2 65.9 54 5.57 5.53 3.66 #&gt; 6 1415 639 0.35 Fair G VS2 65.9 54 5.57 5.53 3.66 #&gt; 7 1715 576 0.32 Fair F VS2 59.6 60 4.42 4.34 2.61 #&gt; 8 1776 412 0.29 Fair F SI1 55.8 60 4.48 4.41 2.48 #&gt; 9 2160 314 0.34 Fair F I1 55.8 62 4.72 4.6 2.6 #&gt; 10 2366 774 0.3 Very Good D VVS2 60.6 58 4.33 4.35 2.63 #&gt; 11 3360 1373 0.51 Premium F SI1 62.7 62 5.09 4.96 3.15 #&gt; 12 3807 1540 0.61 Good F SI2 62.5 65 5.36 5.29 3.33 #&gt; 13 3920 1705 0.51 Fair F VVS2 65.4 60 4.98 4.9 3.23 #&gt; 14 4368 1705 0.51 Fair F VVS2 60.7 66 5.21 5.11 3.13 #&gt; 15 10011 4048 1.01 Fair D SI2 64.6 58 6.25 6.2 4.02 #&gt; 16 10470 23622 2.46 Premium E SI2 59.7 59 8.82 8.76 5.25 似乎没有什么出人意料的数据，但可能值得花时间考虑，这是否表明我们的模型存在问题，或者数据中存在错误。 17.2 分析 flights 每日航班数量变化因素 按照天来看，这是一个包含 365 项的简单数据集： daily &lt;- flights %&gt;% # 同理我们还有 make_datetime，作用是将日期各因素拼接，并返回 “日期” 格式数据 mutate(date = make_date(year, month, day)) %&gt;% group_by(date) %&gt;% summarise(n = n()) daily #&gt; # A tibble: 365 x 2 #&gt; date n #&gt; &lt;date&gt; &lt;int&gt; #&gt; 1 2013-01-01 842 #&gt; 2 2013-01-02 943 #&gt; 3 2013-01-03 914 #&gt; 4 2013-01-04 915 #&gt; 5 2013-01-05 720 #&gt; 6 2013-01-06 832 #&gt; 7 2013-01-07 933 #&gt; 8 2013-01-08 899 #&gt; 9 2013-01-09 902 #&gt; 10 2013-01-10 932 #&gt; # ... with 355 more rows ggplot(daily, aes(date, n)) + geom_line() 不难发现，航班书总是呈现出周期性变化。我们接下来按星期几划分。 17.2.1 星期几对航班的影响 daily &lt;- daily %&gt;% # 对指定的日期来返回星期几（label 配置项为是否要用当地语言表示,默认 FALSE 用数字表示） mutate(wday = wday(date, label = TRUE)) ggplot(daily, aes(wday, n)) + # 注意这里默认周末排最前 geom_boxplot() 双休日的航班相对要少些，因为大多数旅行都是商务旅行。这种影响在周六尤为明显：你有时可能会在周日离开去参加周一上午的会议，但你很少在周六离开，因为你更愿意在家和家人们在一起。 消除这种影响最简单的方法是使用模型矫正。首先，我们拟合模型，并将其预测覆盖在原始数据上来可视化： mod_wday &lt;- lm(n ~ wday, data = daily) grid &lt;- daily %&gt;% data_grid(wday) %&gt;% add_predictions(mod_wday, &quot;n&quot;) ggplot(daily, aes(wday, n)) + geom_boxplot() + geom_point(data = grid, colour = &quot;red&quot;, size = 4) 这样，我们就把问题转化为分析残差： daily &lt;- daily %&gt;% add_residuals(mod_wday) daily %&gt;% ggplot(aes(date, resid)) + geom_ref_line(h = 0) + # 基线调整到 0 而不是最小 geom_line() 现在，通过星期几预估模型，我们发现航班数量仍然明显偏离了预期航班数量。虽然现在我们已经消除了大部分大的每周效应，但我们仍然可以看到一些更微妙的变化：有没有一种可能，我是说可能，这个模型的变化不只是单纯的被星期几？ 从6月份开始，我们的模型很是失败。为一周中的每一天绘制一条线，使原因更容易看到： ggplot(daily, aes(date, resid, colour = wday)) + geom_ref_line(h = 0) + geom_line() 有些线条仍然在乱飞！尤其是周六的航班数量：夏季的航班比我们预期的要多，秋季的航班则少得多。之后我们会着重分析。 这里将偏离过大的 “异常” 数据单独取出仔细研究： daily %&gt;% filter(resid &lt; -100) #&gt; # A tibble: 11 x 4 #&gt; date n wday resid #&gt; &lt;date&gt; &lt;int&gt; &lt;ord&gt; &lt;dbl&gt; #&gt; 1 2013-01-01 842 周二 -109. #&gt; 2 2013-01-20 786 周日 -105. #&gt; 3 2013-05-26 729 周日 -162. #&gt; 4 2013-07-04 737 周四 -229. #&gt; 5 2013-07-05 822 周五 -145. #&gt; 6 2013-09-01 718 周日 -173. #&gt; 7 2013-11-28 634 周四 -332. #&gt; 8 2013-11-29 661 周五 -306. #&gt; 9 2013-12-24 761 周二 -190. #&gt; 10 2013-12-25 719 周三 -244. #&gt; 11 2013-12-31 776 周二 -175. 请注意这些日期并不是巧合。从美国公共假日角度来看，我们会发现这些数据包含元旦、美国独立日（7月4日）、感恩节和圣诞节。 而除上述个别突出的数据以外，也有一些整体性的趋势： daily %&gt;% ggplot(aes(date, resid)) + geom_ref_line(h = 0) + geom_line(colour = &quot;grey50&quot;) + geom_smooth(se = FALSE, span = 0.20) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 冬季（12月至3月）的航班相对较少，而夏季（5月至9月）的航班明显更多。尽管我们只有一年的数据，没有更好地佐证这个观点。但我们可以通过思考获取潜在的解释。 17.2.2 季节性周六效应 之前我们发现仅周六在周预测模型对于全年数据中，出现明显偏差。这里专门提取进行研究： daily %&gt;% filter(wday == &quot;周六&quot;) %&gt;% # 如果是英语作为 R 的语言设置的话：filter(wday == &quot;Sat&quot;) %&gt;% ggplot(aes(date, n)) + geom_point() + geom_line() + # 对 x 轴的缩放比例进行调整，其中数据类型为 date scale_x_date( name = &quot;月份&quot;, # 比例尺名称 date_breaks = &quot;1 month&quot;, # 间隔为一个月 date_labels = &quot;%b&quot; # 指定展示规范为仅显示月 ) 同样是周六，不同的周六反馈的数据差异巨大！很难不会引起怀疑 —— 这是由暑假引起的： 当地人们通常在夏天去度假，也不介意选择周六度假。选择这个时间段度假，很可能是因为孩子们正好在放暑假。所以我们有理由推测暑假是从6月初到8月下旬。 实际查询数据我们得到，该州在2013年的暑假安排是6月26日至9月9日。但为什么春季的周六航班比秋季多？调研得知计划秋天度假的家庭实在不太常见，因为感恩节和圣诞节假期真的已经足够长。 让我们创建一个大致包含三个学校学期的 “term” 变量，并用一个函数来验证我们的推论： term &lt;- function(date) { # cut 会切割我们本有的数据集，break 确认切割点位 cut(date, breaks = ymd(20130101, 20130605, 20130825, 20140101), # 创建日期向量 labels = c(&quot;spring&quot;, &quot;summer&quot;, &quot;fall&quot;) # 切割后类别的命名标签 ) } # 通过切割获取学期标签 daily &lt;- daily %&gt;% mutate(term = term(date)) daily %&gt;% filter(wday == &quot;周六&quot;) %&gt;% ggplot(aes(date, n, colour = term)) + geom_point(alpha = 1 / 3) + geom_line() + scale_x_date(name = &quot;月份&quot;, date_breaks = &quot;1 month&quot;, date_labels = &quot;%b&quot;) 不同季节学期之间的断层非常明显！学生一旦处于暑假，周六出行度假的数量就会居高不下。 我们试着把这个规律推广到其他星期几： daily %&gt;% ggplot(aes(wday, n, colour = term)) + geom_boxplot() 每个星期几都呈现这样的趋势：春季数据多变（由于节日，春季开头与结尾差异较大）、夏季（数据）航班偏多。周六用于暑假度假的趋势也很明显。 既然同时存在两个因素，我们不妨建立两个模型进行对比： mod_wday &lt;- lm(n ~ wday, data = daily) mod_wday_term &lt;- lm(n ~ wday * term, data = daily) daily %&gt;% gather_residuals(without_term = mod_wday, with_term = mod_wday_term) %&gt;% ggplot(aes(date, resid, colour = model)) + geom_ref_line(h = 0) + geom_line(alpha = 0.75) 其实这里就已经表现出来了，包含 term 的模型的预期效果明显优于不包含的。接下来我们将模型与实际数据对应上： grid &lt;- daily %&gt;% data_grid(wday, term) %&gt;% gather_predictions( without_term = mod_wday, with_term = mod_wday_term, .pred = &quot;n&quot; ) ggplot(daily, aes(wday, n)) + geom_boxplot() + geom_point(data = grid, colour = &quot;red&quot;) + facet_grid(term ~ model) 我们的模型总是在走向一个我们所期望的 “寻常态”，但很不幸元数据有许多非常突出的异常值，以至于我们的预测值与理想值相去甚远。所以我们提出了新函数 MASS::rlm() 来合理处理异常值。 mod_wday_term_rlm &lt;- MASS::rlm(n ~ wday * term, data = daily) # 用法与 lm() 真的很类似 daily %&gt;% gather_residuals(mod_wday_term_rlm, mod_wday_term) %&gt;% ggplot(aes(date, resid)) + geom_hline(yintercept = 0, size = 2, colour = &quot;white&quot;) + geom_line(aes(colour = model), alpha = 0.7) 新的模型可能更容易看到长期趋势和异常值。 17.2.3 针对一年中的不同时间点 我们可以使用一个更为灵活的模型，用来捕获我们感兴趣的内容。一个简单的线性趋势是不够的，我们可以尝试使用自然样条来拟合全年的平滑曲线： library(splines) # 便于使用自然样条函数 ns() mod &lt;- MASS::rlm(n ~ wday * ns(date, 5), data = daily) # 最高 5 次方 daily %&gt;% data_grid( wday, # 针对列 wday 生成新的无重复数据的基础数据列 date = seq_range(date, n = 20) # 将 date 范围等距切割出 20 个点位 ) %&gt;% add_predictions(mod) %&gt;% ggplot(aes(date, pred, colour = wday)) + geom_line() + geom_point() 17.3 关于计算变量 在我们试验多个模型和可视化效果时，最好将变量的创建捆绑到一个函数中，如： compute_vars &lt;- function(data) { data %&gt;% mutate( term = term(date), wday = wday(date, label = TRUE) ) } # 或者将转换直接放在模型公式中： wday2 &lt;- function(x) wday(x, label = TRUE) mod3 &lt;- lm(n ~ wday2(date) * term(date), data = daily) 这两种方法都是合理的。但如果要画图或检查变量，显式转换可能更好。但请不要随意使用返回多个列的转换（如样条曲线）。 17.4 有关模型的更多信息 我们只是触及了建模表层的一些东西，也获得了一些简单通用的工具，用于改善自己的数据分析。 从简单开始是可以的！但正如所看到的那样，即使是非常简单的模型，也会对你梳理变量之间相互作用的能力产生巨大的影响。 下面有一些很棒的书籍；建模确实值得一本书，所以我强烈建议你至少读其中的任意一本： Statistical Modeling: A Fresh Approach by Danny Kaplan  书本官网（已挂，但保有 Archive 历史版本）  电子版购买（亚马逊）  在线阅读 本书温和地（。？）介绍了建模，我们可以在其中并行构建直觉，数学工具和一些关于 R 的小技巧。同时这本书取代了传统的 “统计学导论” 课程，提供了一个全新的与数据科学相关的课程。 An Introduction to Statistical Learning by Gareth James, Daniela Witten, Trevor Hastie  作者官网 | 书本官网  电子版下载：PDF | EPUB  教学资源文件下载 本书介绍了一系列现代建模技术，统称为统计学习。 要更深入地了解模型背后的数学原理，则请阅读： The Elements of Statistical Learning by Trevor Hastie, Robert Tibshirani, and Jerome Friedman（电子版下载：一代版本 | 二代版本） Applied Predictive Modeling by Max Kuhn and Kjell Johnson  书本官网  电子版购买（亚马逊） 本书更多是配套于 caret 包，为应对现实生活中的预测建模挑战提供了相当丰富的实用工具。 一个可能对你有用的下载集合：Trevor Hastie - Publications (su.domains) "],["introduction-1.html", "Chapter 18 Introduction", " Chapter 18 Introduction 到目前为止，我们已经学习了许多将数据输入 R 的工具，并将其整理成方便分析的格式，然后通过转换、可视化和建模来了这些数据。然而如果你不会分享的话，这一切都只是孤芳自赏！你需要传达你的结果。 data-science-communicate 在 R Markdown 中，我们将深入学习 R Markdown 这种集成文本、代码和结果的工具。我们可以在笔记本模式下使用 R Markdown 进行分析师对分析师的沟通，也可以在报告模式下使用分析师对决策者的沟通。 在 Graphics for communication 中，我们将学习如何将探索性图形转换为解释性图形，这些图形可以辅助新手（门外汉）尽可能快速轻松地了解正在发生的事情。 在 R Markdown 格式 中，我们将学习使用 R Markdown 生成其他格式的文档，包括仪表盘、网站和电子书。 我们将学习到 R Markdown 工作流程，从中将了解 “分析笔记本”，以及系统如何记录我们的成功和失败，以便从中学习总结。 "],["404.html", "404 Not Found", " 404 Not Found 找不到您要找的页面（可能被移动或重命名）。 您可能需要尝试使用搜索功能查找页面的新位置，或使用内容表查找所需的页面。 "]]
